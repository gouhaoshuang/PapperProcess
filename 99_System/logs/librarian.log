2026-01-18 15:44:37,398 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:44:37,459 [INFO] ============================================================
2026-01-18 15:44:37,459 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:44:37,459 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:44:37,459 [INFO] ============================================================
2026-01-18 15:44:37,462 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:44:37,462 [INFO] å‘ç° 2 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:44:37,462 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:44:37,462 [INFO] ----------------------------------------
2026-01-18 15:44:37,462 [INFO] [1/2] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:44:37,464 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:44:37,464 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:44:37,464 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:44:37,464 [INFO] ----------------------------------------
2026-01-18 15:44:37,464 [INFO] [2/2] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:44:37,465 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:44:37,465 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:44:37,465 [INFO] ============================================================
2026-01-18 15:44:37,465 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:44:37,466 [INFO]   æˆåŠŸ: 0
2026-01-18 15:44:37,466 [INFO]   å¤±è´¥: 2
2026-01-18 15:44:37,466 [INFO]   è·³è¿‡: 0
2026-01-18 15:44:37,466 [INFO] ============================================================
2026-01-18 15:49:39,709 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:49:39,731 [INFO] ============================================================
2026-01-18 15:49:39,731 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:49:39,731 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:49:39,731 [INFO] ============================================================
2026-01-18 15:49:39,733 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:49:39,734 [INFO] å‘ç° 2 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:49:39,734 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:49:39,734 [INFO] ----------------------------------------
2026-01-18 15:49:39,734 [INFO] [1/2] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:49:39,735 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:49:39,735 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:49:39,735 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:49:39,735 [INFO] ----------------------------------------
2026-01-18 15:49:39,735 [INFO] [2/2] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:49:39,736 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:49:39,736 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:49:39,736 [INFO] ============================================================
2026-01-18 15:49:39,736 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:49:39,737 [INFO]   æˆåŠŸ: 0
2026-01-18 15:49:39,737 [INFO]   å¤±è´¥: 2
2026-01-18 15:49:39,737 [INFO]   è·³è¿‡: 0
2026-01-18 15:49:39,737 [INFO] ============================================================
2026-01-18 15:49:43,634 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:49:43,657 [INFO] ============================================================
2026-01-18 15:49:43,657 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:49:43,657 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:49:43,658 [INFO] ============================================================
2026-01-18 15:49:43,661 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:49:43,661 [INFO] å‘ç° 2 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:49:43,661 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:49:43,661 [INFO] ----------------------------------------
2026-01-18 15:49:43,661 [INFO] [1/2] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:49:43,662 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:49:43,663 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:49:43,663 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:49:43,663 [INFO] ----------------------------------------
2026-01-18 15:49:43,663 [INFO] [2/2] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:49:43,664 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:49:43,664 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:49:43,664 [INFO] ============================================================
2026-01-18 15:49:43,664 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:49:43,664 [INFO]   æˆåŠŸ: 0
2026-01-18 15:49:43,664 [INFO]   å¤±è´¥: 2
2026-01-18 15:49:43,664 [INFO]   è·³è¿‡: 0
2026-01-18 15:49:43,664 [INFO] ============================================================
2026-01-18 15:50:38,923 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:50:38,944 [INFO] ============================================================
2026-01-18 15:50:38,944 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:50:38,944 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:50:38,944 [INFO] ============================================================
2026-01-18 15:50:38,946 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:50:38,946 [INFO] å‘ç° 2 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:50:38,947 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:50:38,947 [INFO] ----------------------------------------
2026-01-18 15:50:38,947 [INFO] [1/2] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:50:38,948 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:50:38,948 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:50:38,948 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:50:38,948 [INFO] ----------------------------------------
2026-01-18 15:50:38,948 [INFO] [2/2] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:50:38,948 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:50:38,949 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:50:38,949 [INFO] ============================================================
2026-01-18 15:50:38,949 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:50:38,949 [INFO]   æˆåŠŸ: 0
2026-01-18 15:50:38,949 [INFO]   å¤±è´¥: 2
2026-01-18 15:50:38,949 [INFO]   è·³è¿‡: 0
2026-01-18 15:50:38,949 [INFO] ============================================================
2026-01-18 15:51:01,302 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:51:01,327 [INFO] ============================================================
2026-01-18 15:51:01,327 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:51:01,327 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:51:01,327 [INFO] ============================================================
2026-01-18 15:51:01,329 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:51:01,330 [INFO] å‘ç° 2 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:51:01,330 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:51:01,330 [INFO] ----------------------------------------
2026-01-18 15:51:01,330 [INFO] [1/2] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:51:01,331 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:51:01,331 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:51:01,332 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:51:01,332 [INFO] ----------------------------------------
2026-01-18 15:51:01,332 [INFO] [2/2] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:51:01,332 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:51:01,333 [ERROR] å¤„ç†å¤±è´¥: æœªè®¾ç½®ç¯å¢ƒå˜é‡: GOOGLE_API_KEY
è¯·è®¾ç½®: set GOOGLE_API_KEY=your_api_key
2026-01-18 15:51:01,333 [INFO] ============================================================
2026-01-18 15:51:01,333 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:51:01,333 [INFO]   æˆåŠŸ: 0
2026-01-18 15:51:01,333 [INFO]   å¤±è´¥: 2
2026-01-18 15:51:01,333 [INFO]   è·³è¿‡: 0
2026-01-18 15:51:01,334 [INFO] ============================================================
2026-01-18 15:56:49,107 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:56:49,159 [INFO] ============================================================
2026-01-18 15:56:49,159 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:56:49,160 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:56:49,160 [INFO] ============================================================
2026-01-18 15:56:49,162 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:56:49,162 [INFO] å‘ç° 3 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:56:49,162 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:56:49,162 [INFO] ----------------------------------------
2026-01-18 15:56:49,162 [INFO] [1/3] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:56:49,163 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:56:49,164 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:56:57,875 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 15:56:59,798 [INFO]   â†’ åˆ†ç±»: OnDeviceInferenceOptimization (ğŸ†• æ–°å»º)
2026-01-18 15:56:59,798 [INFO]   â†’ æ ‡ç­¾: ['SparseAttention', 'NPUAcceleration', 'HardwareAwareOptimization', 'QuantizationSensitivity']
2026-01-18 15:56:59,799 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 15:56:59,799 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä¼˜åŒ–LLMæ¨ç†ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹NPUçš„ä¼˜åŒ–ï¼Œä»¥å‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ï¼Œæé«˜æ•ˆç‡å’Œç”¨æˆ·ä½“éªŒã€‚è¿™æ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶æ–¹å‘ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ªæ–°çš„ç±»åˆ«æ¥æ›´å¥½åœ°ç»„ç»‡ç›¸å…³è®ºæ–‡ã€‚
2026-01-18 15:56:59,799 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 15:56:59,799 [INFO] ----------------------------------------
2026-01-18 15:56:59,800 [INFO] [2/3] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:56:59,800 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:57:01,340 [INFO]   â†’ åˆ†ç±»: EnergyEfficientInference (ğŸ†• æ–°å»º)
2026-01-18 15:57:01,341 [INFO]   â†’ æ ‡ç­¾: ['Energy Efficiency', 'LLM Decoding', 'Dynamic Core Selection', 'MNN', 'On-Device Inference']
2026-01-18 15:57:01,342 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 15:57:01,343 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨ç§»åŠ¨è®¾å¤‡ä¸ŠLLMæ¨ç†çš„èƒ½æ•ˆé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŠ¨æ€é€‰æ‹©ä½åŠŸè€—CPUæ ¸å¿ƒçš„æ–¹æ¡ˆï¼Œä»¥é™ä½è§£ç è¿‡ç¨‹ä¸­çš„èƒ½è€—ï¼Œè¿™å±äºèƒ½æ•ˆä¼˜åŒ–é¢†åŸŸã€‚
2026-01-18 15:57:01,343 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 15:57:01,344 [INFO] ----------------------------------------
2026-01-18 15:57:01,344 [INFO] [3/3] å¤„ç†: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper
2026-01-18 15:57:01,346 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 15:57:02,897 [INFO]   â†’ åˆ†ç±»: OnDeviceInferenceOptimization (ğŸ†• æ–°å»º)
2026-01-18 15:57:02,897 [INFO]   â†’ æ ‡ç­¾: ['GPU Acceleration', 'On-Device Inference', 'Generative AI', 'Cross-Platform Compatibility']
2026-01-18 15:57:02,897 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 15:57:02,898 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šä¼˜åŒ–å¤§å‹ç”Ÿæˆæ¨¡å‹çš„æ¨ç†æ€§èƒ½ï¼Œç‰¹åˆ«æ˜¯åˆ©ç”¨GPUåŠ é€Ÿï¼Œå¹¶è§£å†³äº†è·¨GPU APIå¼€å‘å’Œå…¼å®¹æ€§é—®é¢˜ï¼Œå±äºè®¾å¤‡ç«¯æ¨ç†ä¼˜åŒ–è¿™ä¸€ç»†åˆ†é¢†åŸŸã€‚
2026-01-18 15:57:02,898 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 15:57:02,898 [INFO] ============================================================
2026-01-18 15:57:02,898 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 15:57:02,898 [INFO]   æˆåŠŸ: 3
2026-01-18 15:57:02,899 [INFO]   å¤±è´¥: 0
2026-01-18 15:57:02,899 [INFO]   è·³è¿‡: 0
2026-01-18 15:57:02,899 [INFO] ============================================================
2026-01-18 15:59:54,236 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 15:59:54,260 [INFO] ============================================================
2026-01-18 15:59:54,260 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 15:59:54,260 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 15:59:54,261 [INFO] ============================================================
2026-01-18 15:59:54,263 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:59:54,264 [INFO] å‘ç° 3 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 15:59:54,264 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 15:59:54,264 [INFO] ----------------------------------------
2026-01-18 15:59:54,264 [INFO] [1/3] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 15:59:54,266 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 15:59:54,266 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 15:59:56,298 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 15:59:58,107 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 15:59:58,107 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUä¼˜åŒ–', 'å¼‚æ„è®¡ç®—', 'ç«¯ä¾§æ¨ç†']
2026-01-18 15:59:58,107 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 15:59:58,108 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œé€šè¿‡ç®—æ³•å’Œç³»ç»ŸååŒè®¾è®¡ï¼Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ï¼Œå±äºNPUåŠ é€Ÿçš„èŒƒç•´ã€‚
2026-01-18 15:59:58,108 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 15:59:58,109 [INFO] ----------------------------------------
2026-01-18 15:59:58,109 [INFO] [2/3] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 15:59:58,110 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 15:59:59,335 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 15:59:59,335 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯LLM', 'èƒ½è€—ä¼˜åŒ–', 'CPUæ ¸å¿ƒé€‰æ‹©', 'MNNæ¡†æ¶', 'åŠ¨æ€è°ƒæ•´']
2026-01-18 15:59:59,336 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 15:59:59,336 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨ç§»åŠ¨ç«¯LLMæ¨ç†çš„èƒ½æ•ˆé—®é¢˜ï¼Œå¹¶æå‡ºäº†ä¸€ç§åŠ¨æ€é€‰æ‹©ä½åŠŸè€—CPUæ ¸å¿ƒçš„æ–¹æ¡ˆæ¥é™ä½èƒ½è€—ã€‚
2026-01-18 15:59:59,336 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 15:59:59,336 [INFO] ----------------------------------------
2026-01-18 15:59:59,337 [INFO] [3/3] å¤„ç†: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper
2026-01-18 15:59:59,337 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 16:00:00,595 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:00:00,597 [INFO]   â†’ æ ‡ç­¾: ['GPUåŠ é€Ÿ', 'ç”Ÿæˆå¼AI', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'æ¨ç†å¼•æ“ä¼˜åŒ–']
2026-01-18 16:00:00,598 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:00:00,598 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯GPUä¸ŠåŠ é€Ÿå¤§å‹ç”Ÿæˆå¼AIæ¨¡å‹çš„æ¨ç†ï¼Œå±äºç«¯ä¾§æ¨ç†åŠ é€Ÿçš„èŒƒç•´ã€‚
2026-01-18 16:00:00,599 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:00:00,600 [INFO] ============================================================
2026-01-18 16:00:00,600 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:00:00,601 [INFO]   æˆåŠŸ: 3
2026-01-18 16:00:00,601 [INFO]   å¤±è´¥: 0
2026-01-18 16:00:00,602 [INFO]   è·³è¿‡: 0
2026-01-18 16:00:00,602 [INFO] ============================================================
2026-01-18 16:00:28,313 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:00:28,340 [INFO] ============================================================
2026-01-18 16:00:28,340 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:00:28,340 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:00:28,340 [INFO] ============================================================
2026-01-18 16:00:28,342 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:00:28,342 [INFO] å‘ç° 3 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:00:28,342 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:00:28,342 [INFO] ----------------------------------------
2026-01-18 16:00:28,342 [INFO] [1/3] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:00:28,343 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:00:28,343 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:00:30,342 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 16:00:32,675 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:00:32,675 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUä¼˜åŒ–', 'å¼‚æ„è®¡ç®—', 'ç«¯ä¾§æ¨ç†åŠ é€Ÿ']
2026-01-18 16:00:32,675 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:00:32,676 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œå¹¶æå‡ºäº†é’ˆå¯¹NPUçš„ä¼˜åŒ–æ–¹æ³•ï¼Œä»¥å‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ã€‚
2026-01-18 16:00:32,676 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:00:32,676 [INFO] ----------------------------------------
2026-01-18 16:00:32,676 [INFO] [2/3] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 16:00:32,677 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 16:00:34,039 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 16:00:34,039 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯LLM', 'èƒ½è€—ä¼˜åŒ–', 'CPUæ ¸å¿ƒé€‰æ‹©', 'åŠ¨æ€è°ƒæ•´', 'MNNæ¡†æ¶']
2026-01-18 16:00:34,039 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:00:34,039 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨ç§»åŠ¨ç«¯LLMæ¨ç†çš„èƒ½æ•ˆé—®é¢˜ï¼Œå¹¶æå‡ºäº†é€šè¿‡åŠ¨æ€é€‰æ‹©ä½åŠŸè€—CPUæ ¸å¿ƒæ¥é™ä½èƒ½è€—çš„æ–¹æ³•ï¼Œå±äºèƒ½æ•ˆä¼˜åŒ–é¢†åŸŸã€‚
2026-01-18 16:00:34,039 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:00:34,039 [INFO] ----------------------------------------
2026-01-18 16:00:34,039 [INFO] [3/3] å¤„ç†: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper
2026-01-18 16:00:34,040 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 16:00:35,347 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:00:35,347 [INFO]   â†’ æ ‡ç­¾: ['GPUåŠ é€Ÿ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'è·¨å¹³å°å…¼å®¹']
2026-01-18 16:00:35,348 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:00:35,348 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯GPUä¸ŠåŠ é€Ÿå¤§æ¨¡å‹çš„æ¨ç†ï¼Œé€šè¿‡ä¼˜åŒ–æ¡†æ¶å®ç°æ›´å¤æ‚æ¨¡å‹çš„éƒ¨ç½²å’Œæ€§èƒ½æå‡ã€‚
2026-01-18 16:00:35,348 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:00:35,348 [INFO] ============================================================
2026-01-18 16:00:35,348 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:00:35,348 [INFO]   æˆåŠŸ: 3
2026-01-18 16:00:35,348 [INFO]   å¤±è´¥: 0
2026-01-18 16:00:35,349 [INFO]   è·³è¿‡: 0
2026-01-18 16:00:35,349 [INFO] ============================================================
2026-01-18 16:00:54,718 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:00:54,739 [INFO] ============================================================
2026-01-18 16:00:54,739 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:00:54,739 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:00:54,739 [INFO] ============================================================
2026-01-18 16:00:54,741 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:00:54,741 [INFO] å‘ç° 3 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:00:54,741 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:00:54,741 [INFO] ----------------------------------------
2026-01-18 16:00:54,741 [INFO] [1/3] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:00:54,742 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:00:54,742 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:00:56,676 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 16:00:58,628 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:00:58,628 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUä¼˜åŒ–', 'ç«¯ä¾§æ¨ç†', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:00:58,628 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:00:58,628 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œé€šè¿‡ç®—æ³•å’Œç³»ç»ŸååŒè®¾è®¡ï¼Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ï¼Œæå‡æ€§èƒ½ã€‚
2026-01-18 16:00:58,628 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:00:58,628 [INFO] ----------------------------------------
2026-01-18 16:00:58,628 [INFO] [2/3] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 16:00:58,629 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 16:01:00,218 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 16:01:00,218 [INFO]   â†’ æ ‡ç­¾: ['èƒ½æ•ˆä¼˜åŒ–', 'ç§»åŠ¨ç«¯æ¨ç†', 'åŠ¨æ€æ ¸å¿ƒé€‰æ‹©', 'LLMè§£ç ']
2026-01-18 16:01:00,218 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:01:00,218 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨ç§»åŠ¨ç«¯LLMæ¨ç†çš„èƒ½æ•ˆé—®é¢˜ï¼Œå¹¶æå‡ºäº†é€šè¿‡åŠ¨æ€é€‰æ‹©ä½åŠŸè€—CPUæ ¸å¿ƒæ¥é™ä½èƒ½è€—çš„æ–¹æ³•ã€‚
2026-01-18 16:01:00,218 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:01:00,218 [INFO] ----------------------------------------
2026-01-18 16:01:00,218 [INFO] [3/3] å¤„ç†: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper
2026-01-18 16:01:00,219 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 16:01:01,467 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:01:01,467 [INFO]   â†’ æ ‡ç­¾: ['GPUåŠ é€Ÿ', 'æ¨¡å‹ä¼˜åŒ–', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'æ¨ç†å¼•æ“']
2026-01-18 16:01:01,467 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:01:01,467 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯GPUä¸ŠåŠ é€Ÿå¤§æ¨¡å‹çš„æ¨ç†ï¼Œå±äºç«¯ä¾§æ¨ç†åŠ é€Ÿçš„èŒƒç•´ã€‚
2026-01-18 16:01:01,467 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:01:01,468 [INFO] ============================================================
2026-01-18 16:01:01,468 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:01:01,468 [INFO]   æˆåŠŸ: 3
2026-01-18 16:01:01,468 [INFO]   å¤±è´¥: 0
2026-01-18 16:01:01,468 [INFO]   è·³è¿‡: 0
2026-01-18 16:01:01,468 [INFO] ============================================================
2026-01-18 16:02:41,341 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:02:41,361 [INFO] ============================================================
2026-01-18 16:02:41,361 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:02:41,362 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:02:41,362 [INFO] ============================================================
2026-01-18 16:02:41,364 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:02:41,364 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:02:41,364 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:02:41,364 [INFO] ----------------------------------------
2026-01-18 16:02:41,364 [INFO] [1/1] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:02:41,366 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:02:41,366 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:02:43,397 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 16:02:45,224 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:02:45,224 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUè®¡ç®—å›¾åˆ†æ¡¶', 'å¤´é—´æµæ°´çº¿', 'ç«¯ä¾§æ¨ç†']
2026-01-18 16:02:45,225 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:02:45,225 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œé€šè¿‡ç®—æ³•å’Œç³»ç»ŸååŒè®¾è®¡ï¼Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ï¼Œå±äºNPUåŠ é€Ÿçš„èŒƒç•´ã€‚
2026-01-18 16:02:45,225 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:02:45,225 [INFO] ============================================================
2026-01-18 16:02:45,226 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:02:45,226 [INFO]   æˆåŠŸ: 1
2026-01-18 16:02:45,226 [INFO]   å¤±è´¥: 0
2026-01-18 16:02:45,226 [INFO]   è·³è¿‡: 0
2026-01-18 16:02:45,226 [INFO] ============================================================
2026-01-18 16:03:19,501 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:03:19,527 [INFO] ============================================================
2026-01-18 16:03:19,527 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:03:19,528 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:03:19,528 [INFO] ============================================================
2026-01-18 16:03:19,531 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:03:19,531 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:03:19,531 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:03:19,531 [INFO] ----------------------------------------
2026-01-18 16:03:19,531 [INFO] [1/1] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:03:19,533 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:03:19,533 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:03:21,690 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 16:03:23,606 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:03:23,606 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUä¼˜åŒ–', 'å¼‚æ„è®¡ç®—', 'ç«¯ä¾§æ¨ç†']
2026-01-18 16:03:23,607 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:03:23,607 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œé€šè¿‡ç®—æ³•å’Œç³»ç»ŸååŒè®¾è®¡ï¼Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ï¼Œæé«˜æ¨ç†æ•ˆç‡ã€‚
2026-01-18 16:03:23,607 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:03:23,607 [INFO] ============================================================
2026-01-18 16:03:23,607 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:03:23,607 [INFO]   æˆåŠŸ: 1
2026-01-18 16:03:23,607 [INFO]   å¤±è´¥: 0
2026-01-18 16:03:23,607 [INFO]   è·³è¿‡: 0
2026-01-18 16:03:23,607 [INFO] ============================================================
2026-01-18 16:03:54,327 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:03:54,351 [INFO] ============================================================
2026-01-18 16:03:54,352 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:03:54,352 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:03:54,352 [INFO] ============================================================
2026-01-18 16:03:54,354 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:03:54,354 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:03:54,354 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:03:54,355 [INFO] ----------------------------------------
2026-01-18 16:03:54,355 [INFO] [1/1] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:03:54,356 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:03:54,356 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:03:56,453 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-2.0-flash
2026-01-18 16:03:58,275 [INFO]   â†’ åˆ†ç±»: NPUåŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:03:58,275 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUä¼˜åŒ–', 'ç«¯ä¾§æ¨ç†', 'å¼‚æ„è®¡ç®—', 'é‡åŒ–']
2026-01-18 16:03:58,275 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:03:58,276 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨åœ¨ç§»åŠ¨ç«¯NPUä¸ŠåŠ é€ŸLLMæ¨ç†ï¼Œå¹¶æå‡ºäº†é’ˆå¯¹NPUçš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¾‹å¦‚è®¡ç®—å›¾åˆ†æ¡¶å’Œæµæ°´çº¿æŠ€æœ¯ã€‚
2026-01-18 16:03:58,276 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:03:58,276 [INFO] ============================================================
2026-01-18 16:03:58,276 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:03:58,276 [INFO]   æˆåŠŸ: 1
2026-01-18 16:03:58,276 [INFO]   å¤±è´¥: 0
2026-01-18 16:03:58,277 [INFO]   è·³è¿‡: 0
2026-01-18 16:03:58,277 [INFO] ============================================================
2026-01-18 16:04:56,808 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:04:56,828 [INFO] ============================================================
2026-01-18 16:04:56,828 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:04:56,828 [INFO] æ¨¡å¼: é¢„è§ˆæ¨¡å¼ (Dry Run)
2026-01-18 16:04:56,828 [INFO] ============================================================
2026-01-18 16:04:56,831 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:04:56,832 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:04:56,832 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:04:56,833 [INFO] ----------------------------------------
2026-01-18 16:04:56,833 [INFO] [1/1] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:04:56,834 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:04:56,835 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:04:59,101 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 16:05:24,257 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ³¨æ„åŠ› (ğŸ†• æ–°å»º)
2026-01-18 16:05:24,258 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUåŠ é€Ÿ', 'ç«¯ä¾§æ¨ç†', 'ç³»ç»Ÿç®—æ³•ååŒè®¾è®¡', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:05:24,258 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:05:24,258 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†shadowAttnï¼Œä¸€ç§é’ˆå¯¹ç§»åŠ¨ç«¯NPUä¼˜åŒ–çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€‚å®ƒé€šè¿‡ç³»ç»Ÿä¸ç®—æ³•çš„ååŒè®¾è®¡ï¼Œåˆ©ç”¨NPUè¿›è¡Œå…ˆå¯¼è®¡ç®—ä»¥è¯†åˆ«é‡è¦tokenï¼Œä»è€Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶æ˜¾è‘—å‡å°‘è®¡ç®—é‡ï¼Œè§£å†³å› é‡åŒ–æ•æ„Ÿæ€§å¯¼è‡´çš„NPUå›é€€é—®é¢˜ã€‚
2026-01-18 16:05:24,258 [INFO]   [DRY RUN] è·³è¿‡å®é™…æ“ä½œ
2026-01-18 16:05:24,259 [INFO] ============================================================
2026-01-18 16:05:24,259 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:05:24,259 [INFO]   æˆåŠŸ: 1
2026-01-18 16:05:24,259 [INFO]   å¤±è´¥: 0
2026-01-18 16:05:24,259 [INFO]   è·³è¿‡: 0
2026-01-18 16:05:24,259 [INFO] ============================================================
2026-01-18 16:18:49,647 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 0
2026-01-18 16:18:49,689 [INFO] ============================================================
2026-01-18 16:18:49,689 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:18:49,690 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 16:18:49,690 [INFO] ============================================================
2026-01-18 16:18:49,693 [INFO] å…±æ‰«æåˆ° 18 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:18:49,693 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:18:49,693 [INFO] ç°æœ‰ç±»åˆ« (0): []
2026-01-18 16:18:49,693 [INFO] ----------------------------------------
2026-01-18 16:18:49,693 [INFO] [1/1] å¤„ç†: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs
2026-01-18 16:18:49,695 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:18:49,695 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:18:57,455 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 16:19:22,104 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ³¨æ„åŠ› (ğŸ†• æ–°å»º)
2026-01-18 16:19:22,104 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUåŠ é€Ÿ', 'ç«¯ä¾§å¤§æ¨¡å‹', 'ç³»ç»Ÿç®—æ³•ååŒè®¾è®¡', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:19:22,105 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:19:22,105 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºshadowAttnçš„æœºåˆ¶ï¼Œæ ¸å¿ƒåœ¨äºé€šè¿‡ç¨€ç–è®¡ç®—ï¼ˆSparse Attentionï¼‰æ¥ä¼˜åŒ–ç«¯ä¾§å¤§æ¨¡å‹æ¨ç†ï¼Œä¸“é—¨è§£å†³æ³¨æ„åŠ›ç®—å­åœ¨NPUä¸Šçš„é‡åŒ–æ•æ„Ÿæ€§é—®é¢˜ï¼Œä»è€Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–ã€‚
2026-01-18 16:19:22,109 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç¨€ç–æ³¨æ„åŠ›
2026-01-18 16:19:22,110 [INFO] å½’æ¡£å®Œæˆ: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs -> ç¨€ç–æ³¨æ„åŠ›/shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module
2026-01-18 16:19:22,110 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ³¨æ„åŠ›/shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module
2026-01-18 16:19:22,110 [INFO] ============================================================
2026-01-18 16:19:22,111 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:19:22,111 [INFO]   æˆåŠŸ: 1
2026-01-18 16:19:22,111 [INFO]   å¤±è´¥: 0
2026-01-18 16:19:22,111 [INFO]   è·³è¿‡: 0
2026-01-18 16:19:22,111 [INFO] ============================================================
2026-01-18 16:20:06,283 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 1
2026-01-18 16:20:06,303 [INFO] ============================================================
2026-01-18 16:20:06,303 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:20:06,304 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 16:20:06,304 [INFO] ============================================================
2026-01-18 16:20:06,306 [INFO] å…±æ‰«æåˆ° 17 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:20:06,306 [INFO] å‘ç° 17 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:20:06,306 [INFO] ç°æœ‰ç±»åˆ« (1): ['ç¨€ç–æ³¨æ„åŠ›']
2026-01-18 16:20:06,306 [INFO] ----------------------------------------
2026-01-18 16:20:06,306 [INFO] [1/17] å¤„ç†: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection
2026-01-18 16:20:06,307 [INFO]   æ ‡é¢˜: MNN-AECS: Energy Optimization for LLM Decoding on Mobile Dev...
2026-01-18 16:20:08,253 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 16:20:26,500 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ†• æ–°å»º)
2026-01-18 16:20:26,500 [INFO]   â†’ æ ‡ç­¾: ['ç«¯ä¾§æ¨ç†', 'èƒ½æ•ˆä¼˜åŒ–', 'CPUæ ¸å¿ƒè°ƒåº¦', 'ç§»åŠ¨ç«¯LLM', 'ç³»ç»Ÿçº§ä¼˜åŒ–']
2026-01-18 16:20:26,500 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:20:26,501 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºè§£å†³ç§»åŠ¨ç«¯LLMæ¨ç†çš„èƒ½è€—é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŠ¨æ€é€‰æ‹©ä½åŠŸè€—CPUæ ¸å¿ƒçš„ç­–ç•¥ï¼ˆAECSï¼‰ä»¥æå‡èƒ½æ•ˆï¼Œè¿™ä¸ç°æœ‰çš„'ç¨€ç–æ³¨æ„åŠ›'åˆ†ç±»ä¸ç¬¦ï¼Œå±äºä¸“é—¨çš„èƒ½æ•ˆä¼˜åŒ–é¢†åŸŸã€‚
2026-01-18 16:20:26,503 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: èƒ½æ•ˆä¼˜åŒ–
2026-01-18 16:20:26,504 [INFO] å½’æ¡£å®Œæˆ: (arxiv)MNN-AECS_Energy Optimization for LLM Decoding on Mobile Devices via Adaptive Core Selection -> èƒ½æ•ˆä¼˜åŒ–/MNN-AECS_Adaptive_Energy-Centric_Core_Selection_for_On-Device_LLM_Inference
2026-01-18 16:20:26,504 [INFO]   âœ“ å½’æ¡£è‡³: èƒ½æ•ˆä¼˜åŒ–/MNN-AECS_Adaptive_Energy-Centric_Core_Selection_for_On-Device_LLM_Inference
2026-01-18 16:20:28,005 [INFO] ----------------------------------------
2026-01-18 16:20:28,005 [INFO] [2/17] å¤„ç†: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper
2026-01-18 16:20:28,007 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 16:20:43,812 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ†• æ–°å»º)
2026-01-18 16:20:43,812 [INFO]   â†’ æ ‡ç­¾: ['GPUåŠ é€Ÿ', 'æ¨ç†æ¡†æ¶', 'ç”Ÿæˆå¼AI', 'è·¨å¹³å°', 'ç«¯ä¾§éƒ¨ç½²']
2026-01-18 16:20:43,813 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:20:43,813 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºML Driftçš„æ¨ç†æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ç§»åŠ¨ç«¯GPUåŠ é€Ÿå¤§è§„æ¨¡ç”Ÿæˆå¼AIæ¨¡å‹çš„æ¨ç†ï¼Œé‡ç‚¹åœ¨äºç³»ç»Ÿçº§çš„æ€§èƒ½æå‡å’Œè·¨å¹³å°å…¼å®¹æ€§ï¼Œè€Œéç‰¹å®šçš„ç®—æ³•ä¼˜åŒ–ï¼ˆå¦‚ç¨€ç–æ³¨æ„åŠ›ï¼‰æˆ–å•çº¯çš„èƒ½è€—é™ä½ã€‚
2026-01-18 16:20:43,825 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç«¯ä¾§æ¨ç†åŠ é€Ÿ
2026-01-18 16:20:43,826 [INFO] å½’æ¡£å®Œæˆ: (cvpr-workshop)Tang_Scaling_On-Device_GPU_Inference_for_Large_Generative_Models_CVPRW_2025_paper -> ç«¯ä¾§æ¨ç†åŠ é€Ÿ/ML_Drift
2026-01-18 16:20:43,826 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§æ¨ç†åŠ é€Ÿ/ML_Drift
2026-01-18 16:20:45,327 [INFO] ----------------------------------------
2026-01-18 16:20:45,327 [INFO] [3/17] å¤„ç†: (MobiHoc)Resource Allocation for Stable LLM Training in Mobile Edge Computing
2026-01-18 16:20:45,328 [INFO]   æ ‡é¢˜: 5.1 The performance of the proposed collaborative training m...
2026-01-18 16:21:25,682 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 16:21:25,682 [INFO]   â†’ æ ‡ç­¾: ['ååŒè®­ç»ƒ', 'è¾¹ç¼˜è®¡ç®—', 'å‚æ•°é«˜æ•ˆå¾®è°ƒ', 'èµ„æºåˆ†é…', 'ç§»åŠ¨ç«¯LLM']
2026-01-18 16:21:25,682 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:21:25,682 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡çš„æ ¸å¿ƒç›®æ ‡æ˜¯é€šè¿‡ç§»åŠ¨ç«¯ä¸è¾¹ç¼˜æœåŠ¡å™¨çš„ååŒè®­ç»ƒæ¡†æ¶åŠèµ„æºåˆ†é…ï¼Œæœ€å°åŒ–æ€»èƒ½è€—å’Œå»¶è¿Ÿã€‚è™½ç„¶æ¶‰åŠè®­ç»ƒä»»åŠ¡ï¼Œä½†å…¶ä¸»è¦è´¡çŒ®åœ¨äºè§£å†³è®¡ç®—å—é™ä¸‹çš„èƒ½æ•ˆå’Œæ—¶å»¶é—®é¢˜ï¼Œå®Œå…¨ç¬¦åˆ'èƒ½æ•ˆä¼˜åŒ–'ç±»åˆ«çš„å®šä¹‰ã€‚
2026-01-18 16:21:25,684 [INFO] å½’æ¡£å®Œæˆ: (MobiHoc)Resource Allocation for Stable LLM Training in Mobile Edge Computing -> èƒ½æ•ˆä¼˜åŒ–/(MobiHoc)Resource_Allocation_for_Stable_LLM_Training_in_Mobile_Edge_Computing
2026-01-18 16:21:25,684 [INFO]   âœ“ å½’æ¡£è‡³: èƒ½æ•ˆä¼˜åŒ–/(MobiHoc)Resource_Allocation_for_Stable_LLM_Training_in_Mobile_Edge_Computing
2026-01-18 16:21:27,185 [INFO] ----------------------------------------
2026-01-18 16:21:27,185 [INFO] [4/17] å¤„ç†: (system)Performance and efficiency gains of npu-based servers over gpus for ai model inference
2026-01-18 16:21:27,186 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (system)Performance and efficiency gains of npu-based servers over gpus for ai model inference.md
2026-01-18 16:21:27,186 [INFO]   æ ‡é¢˜: Performance and Efficiency Gains of NPUâ€‘Based Servers over G...
2026-01-18 16:21:55,678 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 16:21:55,678 [INFO]   â†’ æ ‡ç­¾: ['NPUåŠ é€Ÿ', 'æ€§èƒ½åŸºå‡†æµ‹è¯•', 'èƒ½è€—åˆ†æ', 'vLLMä¼˜åŒ–', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:21:55,678 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:21:55,678 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡é€šè¿‡å¯¹æ¯”NPUå’ŒGPUæœåŠ¡å™¨åœ¨å¤šç§AIä»»åŠ¡ä¸‹çš„è¡¨ç°ï¼Œé‡ç‚¹çªå‡ºäº†NPUåœ¨ä¿æŒé«˜ååé‡çš„åŒæ—¶æ˜¾è‘—é™ä½åŠŸè€—ï¼ˆ35-70%ï¼‰å¹¶æå‡èƒ½æ•ˆï¼ˆ92%ï¼‰çš„èƒ½åŠ›ï¼Œå®Œå…¨ç¬¦åˆèƒ½æ•ˆä¼˜åŒ–çš„èŒƒç•´ã€‚
2026-01-18 16:21:55,688 [INFO] å½’æ¡£å®Œæˆ: (system)Performance and efficiency gains of npu-based servers over gpus for ai model inference -> èƒ½æ•ˆä¼˜åŒ–/Performance_and_Efficiency_Gains_of_NPU-Based_Servers_over_GPUs_for_AI_Model_Inference
2026-01-18 16:21:55,688 [INFO]   âœ“ å½’æ¡£è‡³: èƒ½æ•ˆä¼˜åŒ–/Performance_and_Efficiency_Gains_of_NPU-Based_Servers_over_GPUs_for_AI_Model_Inference
2026-01-18 16:21:57,189 [INFO] ----------------------------------------
2026-01-18 16:21:57,189 [INFO] [5/17] å¤„ç†: 4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation
2026-01-18 16:21:57,190 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation\\4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation.md'
2026-01-18 16:21:58,690 [INFO] ----------------------------------------
2026-01-18 16:21:58,691 [INFO] [6/17] å¤„ç†: Accelerating Mobile Language Model via Speculative Decoding and NPU-Coordinated Execution
2026-01-18 16:21:58,693 [INFO]   æ ‡é¢˜: Accelerating Mobile Language Model via Speculative Decoding ...
2026-01-18 16:22:18,504 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:22:18,504 [INFO]   â†’ æ ‡ç­¾: ['æŠ•æœºè§£ç ', 'ç§»åŠ¨ç«¯æ¨ç†', 'ç¡¬ä»¶è°ƒåº¦', 'NPUåŠ é€Ÿ', 'ä¸Šä¸‹æ–‡æ„ŸçŸ¥']
2026-01-18 16:22:18,504 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:22:18,504 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†sd.npuæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç§»åŠ¨è®¾å¤‡ä¸ŠLLMé€tokenç”Ÿæˆçš„é«˜å»¶è¿Ÿå’Œç¡¬ä»¶åˆ©ç”¨ç‡ä½çš„é—®é¢˜ï¼Œé€šè¿‡æŠ•æœºè§£ç å’ŒåŠ¨æ€ç¡¬ä»¶è°ƒåº¦æ¥åŠ é€Ÿç«¯ä¾§æ–‡æœ¬ç”Ÿæˆï¼Œå®Œå…¨ç¬¦åˆç«¯ä¾§æ¨ç†åŠ é€Ÿçš„å®šä¹‰ã€‚
2026-01-18 16:22:18,506 [INFO] å½’æ¡£å®Œæˆ: Accelerating Mobile Language Model via Speculative Decoding and NPU-Coordinated Execution -> ç«¯ä¾§æ¨ç†åŠ é€Ÿ/sd.npu_A_Mobile_Inference_Framework_for_Context-Aware_Text_Generation
2026-01-18 16:22:18,506 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§æ¨ç†åŠ é€Ÿ/sd.npu_A_Mobile_Inference_Framework_for_Context-Aware_Text_Generation
2026-01-18 16:22:20,007 [INFO] ----------------------------------------
2026-01-18 16:22:20,008 [INFO] [7/17] å¤„ç†: Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding
2026-01-18 16:22:20,009 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding.md
2026-01-18 16:22:20,009 [INFO]   æ ‡é¢˜: Collaborative Large Language Model Inference via Resource-Aw...
2026-01-18 16:23:02,100 [INFO]   â†’ åˆ†ç±»: æŠ•æœºè§£ç  (ğŸ†• æ–°å»º)
2026-01-18 16:23:02,101 [INFO]   â†’ æ ‡ç­¾: ['æŠ•æœºè§£ç ', 'ç§»åŠ¨è¾¹ç¼˜è®¡ç®—', 'ååŒæ¨ç†', 'å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ', 'èµ„æºåˆ†é…']
2026-01-18 16:23:02,101 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:23:02,101 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºä¸€ç§åœ¨ç§»åŠ¨è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰ç¯å¢ƒä¸‹çš„å¹¶è¡ŒæŠ•æœºè§£ç æ¡†æ¶ã€‚è™½ç„¶ç›®æ ‡æ˜¯åŠ é€Ÿæ¨ç†ï¼Œä½†å…¶æŠ€æœ¯è·¯å¾„ï¼ˆç«¯äº‘ååŒã€æŠ•æœºé‡‡æ ·ï¼‰ä¸çº¯ç²¹çš„'ç«¯ä¾§æ¨ç†åŠ é€Ÿ'ï¼ˆé€šå¸¸æŒ‡æ¨¡å‹å‹ç¼©æˆ–ç«¯ä¾§ç®—å­ä¼˜åŒ–ï¼‰æœ‰æ˜¾è‘—åŒºåˆ«ï¼Œä¸”'æŠ•æœºè§£ç 'æ˜¯ç§»åŠ¨ç«¯LLMä¼˜åŒ–çš„ä¸€ä¸ªé‡è¦ä¸”ç‹¬ç«‹çš„ç ”ç©¶å­é¢†åŸŸã€‚
2026-01-18 16:23:02,112 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: æŠ•æœºè§£ç 
2026-01-18 16:23:02,113 [INFO] å½’æ¡£å®Œæˆ: Collaborative Large Language Model Inference via Resource-Aware Parallel Speculative Decoding -> æŠ•æœºè§£ç /Joint_User_Association_and_Resource_Allocation_for_Parallel_Speculative_Decoding_in_MEC_Systems
2026-01-18 16:23:02,113 [INFO]   âœ“ å½’æ¡£è‡³: æŠ•æœºè§£ç /Joint_User_Association_and_Resource_Allocation_for_Parallel_Speculative_Decoding_in_MEC_Systems
2026-01-18 16:23:03,614 [INFO] ----------------------------------------
2026-01-18 16:23:03,615 [INFO] [8/17] å¤„ç†: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency
2026-01-18 16:23:03,615 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency.md
2026-01-18 16:23:03,616 [INFO]   æ ‡é¢˜: Dissecting the Impact of Mobile DVFS Governors on LLM Infere...
2026-01-18 16:23:24,863 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 16:23:24,863 [INFO]   â†’ æ ‡ç­¾: ['åŠ¨æ€ç”µå‹é¢‘ç‡è°ƒæ•´', 'ç§»åŠ¨ç«¯å¤§æ¨¡å‹', 'èƒ½æ•ˆç®¡ç†', 'ååŒè°ƒåº¦', 'ç¡¬ä»¶è°ƒé¢‘å™¨']
2026-01-18 16:23:24,863 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:23:24,863 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å…³æ³¨ç§»åŠ¨è®¾å¤‡ä¸ŠLLMæ¨ç†è¿‡ç¨‹ä¸­çš„èƒ½æ•ˆé—®é¢˜ã€‚å®ƒæŒ‡å‡ºäº†ç°æœ‰CPUã€GPUå’Œå†…å­˜è°ƒé¢‘å™¨ï¼ˆGovernorsï¼‰ç‹¬ç«‹å·¥ä½œå¯¼è‡´çš„ä½æ•ˆï¼Œå¹¶æå‡ºäº†FUSEï¼ˆä¸€ç§ç»Ÿä¸€çš„èƒ½æ•ˆæ„ŸçŸ¥è°ƒé¢‘å™¨ï¼‰æ¥åè°ƒç¡¬ä»¶é¢‘ç‡ï¼Œä»è€Œåœ¨ç›¸åŒèƒ½è€—ä¸‹ä¼˜åŒ–æ¨ç†å»¶è¿Ÿã€‚è¿™å®Œå…¨ç¬¦åˆèƒ½æ•ˆä¼˜åŒ–çš„èŒƒç•´ã€‚
2026-01-18 16:23:24,873 [INFO] å½’æ¡£å®Œæˆ: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency -> èƒ½æ•ˆä¼˜åŒ–/FUSE_A_Unified_Energy-Aware_Governor_for_Optimizing_the_Energy_Efficiency_of_LLM_Inference_on_Mobile
2026-01-18 16:23:24,873 [INFO]   âœ“ å½’æ¡£è‡³: èƒ½æ•ˆä¼˜åŒ–/FUSE_A_Unified_Energy-Aware_Governor_for_Optimizing_the_Energy_Efficiency_of_LLM_Inference_on_Mobile
2026-01-18 16:23:26,374 [INFO] ----------------------------------------
2026-01-18 16:23:26,376 [INFO] [9/17] å¤„ç†: EdgeLLM_ Fast On-Device LLM Inference With Speculative Decoding
2026-01-18 16:23:26,379 [INFO]   æ ‡é¢˜: <span id="page-0-0"></span>EdgeLLM: Fast On-Device LLM Infer...
2026-01-18 16:23:44,274 [INFO]   â†’ åˆ†ç±»: æŠ•æœºè§£ç  (ğŸ“ ç°æœ‰)
2026-01-18 16:23:44,274 [INFO]   â†’ æ ‡ç­¾: ['æŠ•æœºè§£ç ', 'ç§»åŠ¨ç«¯æ¨ç†', 'åŠ¨æ€åˆ†æ”¯éªŒè¯', 'è®¡ç®—IOæµæ°´çº¿', 'å†…å­˜å—é™']
2026-01-18 16:23:44,275 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 16:23:44,275 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ˜ç¡®æŒ‡å‡ºEdgeLLMç³»ç»Ÿæ˜¯åŸºäºæŠ•æœºè§£ç ï¼ˆspeculative decodingï¼‰æ„å»ºçš„ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°ç‚¹ï¼ˆé«˜æ•ˆåˆ†æ”¯å¯¼èˆªã€è‡ªé€‚åº”å›é€€ç­–ç•¥ã€è®¡ç®—-IOæµæ°´çº¿ï¼‰å‡æ—¨åœ¨ä¼˜åŒ–æŠ•æœºè§£ç åœ¨ç§»åŠ¨ç«¯å†…å­˜å—é™åœºæ™¯ä¸‹çš„æ€§èƒ½ã€‚
2026-01-18 16:23:44,277 [INFO] å½’æ¡£å®Œæˆ: EdgeLLM_ Fast On-Device LLM Inference With Speculative Decoding -> æŠ•æœºè§£ç /EdgeLLM_An_Efficient_On-Device_LLM_Inference_System
2026-01-18 16:23:44,277 [INFO]   âœ“ å½’æ¡£è‡³: æŠ•æœºè§£ç /EdgeLLM_An_Efficient_On-Device_LLM_Inference_System
2026-01-18 16:23:45,778 [INFO] ----------------------------------------
2026-01-18 16:23:45,778 [INFO] [10/17] å¤„ç†: Efficient Deployment of Vision-Language Models on Mobile Devices_ A Case Study on OnePlus 13R
2026-01-18 16:23:45,779 [INFO]   æ ‡é¢˜: Efficient Deployment of Vision-Language Models on Mobile Dev...
2026-01-18 16:24:18,806 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:24:18,807 [INFO]   â†’ æ ‡ç­¾: ['è§†è§‰è¯­è¨€æ¨¡å‹', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'æ€§èƒ½è¯„æµ‹', 'ç¡¬ä»¶åˆ©ç”¨ç‡', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:24:18,807 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:24:18,808 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦è°ƒç ”å’Œè¯„æµ‹äº†ç§»åŠ¨ç«¯è§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„éƒ¨ç½²æ¡†æ¶ï¼ˆå¦‚llama.cpp, MLC-Impï¼‰ï¼Œæ·±å…¥åˆ†æäº†CPUã€GPUå’ŒNPUçš„ç¡¬ä»¶åˆ©ç”¨ç‡åŠæ¨ç†ç“¶é¢ˆï¼Œæ—¨åœ¨è§£å†³ç«¯ä¾§éƒ¨ç½²çš„è®¡ç®—é™åˆ¶é—®é¢˜ï¼Œç¬¦åˆç«¯ä¾§æ¨ç†åŠ é€Ÿçš„ç ”ç©¶èŒƒç•´ã€‚
2026-01-18 16:24:18,819 [INFO] å½’æ¡£å®Œæˆ: Efficient Deployment of Vision-Language Models on Mobile Devices_ A Case Study on OnePlus 13R -> ç«¯ä¾§æ¨ç†åŠ é€Ÿ/A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices
2026-01-18 16:24:18,819 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§æ¨ç†åŠ é€Ÿ/A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices
2026-01-18 16:24:20,320 [INFO] ----------------------------------------
2026-01-18 16:24:20,321 [INFO] [11/17] å¤„ç†: Elastic On-Device LLM Service
2026-01-18 16:24:20,324 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Elastic On-Device LLM Service.md
2026-01-18 16:24:20,324 [INFO]   æ ‡é¢˜: Elastic On-Device LLM Service...
2026-01-18 16:24:43,194 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:24:43,194 [INFO]   â†’ æ ‡ç­¾: ['ç«¯ä¾§å¤§æ¨¡å‹', 'åŠ¨æ€æ¨ç†', 'ç¥ç»å…ƒé‡æ’åº', 'SLOæ„ŸçŸ¥', 'æ¨¡å‹å¼¹æ€§']
2026-01-18 16:24:43,195 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:24:43,195 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ElastiLMï¼Œä¸€ç§é’ˆå¯¹ç§»åŠ¨è®¾å¤‡çš„LLMæœåŠ¡ï¼Œæ—¨åœ¨é€šè¿‡åŠ¨æ€è°ƒæ•´æ¨¡å‹å¤§å°å’Œæç¤ºè¯é•¿åº¦æ¥æ»¡è¶³ä¸åŒçš„æ¨ç†å»¶è¿Ÿç›®æ ‡ï¼ˆSLOï¼‰ã€‚è¿™ç›´æ¥è§£å†³äº†ç«¯ä¾§èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ¨ç†é€Ÿåº¦å’Œå“åº”æ—¶é—´é—®é¢˜ï¼Œå±äºç«¯ä¾§æ¨ç†åŠ é€Ÿçš„èŒƒç•´ã€‚
2026-01-18 16:24:43,198 [INFO] å½’æ¡£å®Œæˆ: Elastic On-Device LLM Service -> ç«¯ä¾§æ¨ç†åŠ é€Ÿ/ElastiLM
2026-01-18 16:24:43,198 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§æ¨ç†åŠ é€Ÿ/ElastiLM
2026-01-18 16:24:44,698 [INFO] ----------------------------------------
2026-01-18 16:24:44,699 [INFO] [12/17] å¤„ç†: Large language models on mobile devices Measurements, analysis, and insights
2026-01-18 16:24:44,701 [INFO]   æ ‡é¢˜: Large Language Models on Mobile Devices: Measurements, Analy...
2026-01-18 16:25:19,575 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§æ¨ç†åŠ é€Ÿ (ğŸ“ ç°æœ‰)
2026-01-18 16:25:19,576 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯å¤§æ¨¡å‹', 'æ€§èƒ½è¯„æµ‹', 'æ¨ç†å»¶è¿Ÿ', 'å†…å­˜å ç”¨', 'ç«¯ä¾§éƒ¨ç½²']
2026-01-18 16:25:19,576 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:25:19,577 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦ç ”ç©¶åœ¨èµ„æºå—é™çš„ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²LLMçš„å¯è¡Œæ€§ï¼Œé€šè¿‡å¯¹22ä¸ªæ¨¡å‹åœ¨ä¸åŒè®¾å¤‡å’Œæ‰§è¡Œå¼•æ“ä¸Šçš„å»¶è¿Ÿã€å†…å­˜åŠå‡†ç¡®ç‡è¿›è¡Œç»¼åˆè¯„æµ‹ï¼Œæ—¨åœ¨æ­ç¤ºç«¯ä¾§æ¨ç†çš„ç°çŠ¶å¹¶æŒ‡å¼•åŠ é€Ÿä¼˜åŒ–çš„æ–¹å‘ï¼Œå› æ­¤å½’å…¥ç«¯ä¾§æ¨ç†åŠ é€Ÿç±»åˆ«ã€‚
2026-01-18 16:25:19,579 [INFO] å½’æ¡£å®Œæˆ: Large language models on mobile devices Measurements, analysis, and insights -> ç«¯ä¾§æ¨ç†åŠ é€Ÿ/Comprehensive_Measurement_Study_of_LLMs_on_Mobile_Devices
2026-01-18 16:25:19,580 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§æ¨ç†åŠ é€Ÿ/Comprehensive_Measurement_Study_of_LLMs_on_Mobile_Devices
2026-01-18 16:25:21,081 [INFO] ----------------------------------------
2026-01-18 16:25:21,081 [INFO] [13/17] å¤„ç†: Llmcad_ Fast and scalable on-device large language model inference
2026-01-18 16:25:21,083 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Llmcad_ Fast and scalable on-device large language model inference.md
2026-01-18 16:25:21,084 [INFO]   æ ‡é¢˜: LLMCad: Fast and Scalable On-device Large Language Model Inf...
2026-01-18 16:25:40,612 [INFO]   â†’ åˆ†ç±»: æŠ•æœºè§£ç  (ğŸ“ ç°æœ‰)
2026-01-18 16:25:40,612 [INFO]   â†’ æ ‡ç­¾: ['ç«¯ä¾§æ¨ç†', 'æŠ•æœºè§£ç ', 'å¤§å°æ¨¡å‹åä½œ', 'ä»¤ç‰Œæ ‘', 'ç§»åŠ¨ç«¯LLM']
2026-01-18 16:25:40,612 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 16:25:40,613 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºçš„LLMCadç³»ç»Ÿæ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å†…å­˜ä¸­çš„å°æ¨¡å‹ç”Ÿæˆå€™é€‰tokenï¼ˆæ„å»ºtoken treeï¼‰ï¼Œå†ç”±å¤§æ¨¡å‹è¿›è¡ŒéªŒè¯å’Œçº é”™ï¼Œè¿™æ˜¯å…¸å‹çš„æŠ•æœºè§£ç ï¼ˆSpeculative Decodingï¼‰æŠ€æœ¯åœ¨ç«¯ä¾§è®¾å¤‡ä¸Šçš„åº”ç”¨ã€‚
2026-01-18 16:25:40,623 [INFO] å½’æ¡£å®Œæˆ: Llmcad_ Fast and scalable on-device large language model inference -> æŠ•æœºè§£ç /LLMCad_Fast_and_Scalable_On-device_Large_Language_Model_Inference
2026-01-18 16:25:40,623 [INFO]   âœ“ å½’æ¡£è‡³: æŠ•æœºè§£ç /LLMCad_Fast_and_Scalable_On-device_Large_Language_Model_Inference
2026-01-18 16:25:42,124 [INFO] ----------------------------------------
2026-01-18 16:25:42,125 [INFO] [14/17] å¤„ç†: Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper
2026-01-18 16:25:42,127 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper.md
2026-01-18 16:25:42,127 [INFO]   æ ‡é¢˜: BlueLM-V-3B: Algorithm and System Co-Design for Multimodal L...
2026-01-18 16:25:48,153 [INFO] 
ç”¨æˆ·ä¸­æ–­

2026-01-18 16:48:40,935 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 2
2026-01-18 16:48:40,957 [INFO] ============================================================
2026-01-18 16:48:40,957 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:48:40,957 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 16:48:40,958 [INFO] ============================================================
2026-01-18 16:48:40,959 [INFO] å…±æ‰«æåˆ° 11 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:48:40,959 [INFO] å‘ç° 11 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:48:40,959 [INFO] ç°æœ‰ç±»åˆ« (2): ['æŠ•æœºè§£ç ', 'èƒ½æ•ˆä¼˜åŒ–']
2026-01-18 16:48:40,959 [INFO] ----------------------------------------
2026-01-18 16:48:40,959 [INFO] [1/11] å¤„ç†: 4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation
2026-01-18 16:48:40,960 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation\\4-9 AAAI26 Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation.md'
2026-01-18 16:48:42,460 [INFO] ----------------------------------------
2026-01-18 16:48:42,461 [INFO] [2/11] å¤„ç†: A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices
2026-01-18 16:48:42,463 [INFO]   æ ‡é¢˜: Efficient Deployment of Vision-Language Models on Mobile Dev...
2026-01-18 16:48:44,491 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 16:49:21,130 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ†• æ–°å»º)
2026-01-18 16:49:21,131 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯éƒ¨ç½²', 'æ€§èƒ½åŸºå‡†æµ‹è¯•', 'ç¡¬ä»¶åˆ©ç”¨ç‡', 'å¼‚æ„è®¡ç®—', 'æ¨ç†æ¡†æ¶']
2026-01-18 16:49:21,131 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:49:21,131 [INFO]   â†’ ç†ç”±: è®ºæ–‡ä¸“æ³¨äºè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰åœ¨ç§»åŠ¨ç«¯çš„éƒ¨ç½²ä¸è¯„æµ‹ï¼Œåˆ†æäº†è¯¥ç‰¹å®šæ¨¡æ€æ¨¡å‹åœ¨ç«¯ä¾§æ¨ç†æ—¶çš„ç¡¬ä»¶åˆ©ç”¨ç‡ï¼ˆCPU/GPU/NPUï¼‰åŠæ€§èƒ½ç“¶é¢ˆï¼Œç¬¦åˆæ¨èçš„ç»†ç²’åº¦æŠ€æœ¯åˆ†ç±»ã€‚
2026-01-18 16:49:21,142 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: è§†è§‰è¯­è¨€æ¨¡å‹
2026-01-18 16:49:21,143 [INFO] å½’æ¡£å®Œæˆ: A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices -> è§†è§‰è¯­è¨€æ¨¡å‹/A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices
2026-01-18 16:49:21,143 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/A_Comprehensive_Survey_of_Deployment_Frameworks_for_Vision-Language_Models_on_Mobile_Devices
2026-01-18 16:49:22,644 [INFO] ----------------------------------------
2026-01-18 16:49:22,644 [INFO] [3/11] å¤„ç†: Comprehensive_Measurement_Study_of_LLMs_on_Mobile_Devices
2026-01-18 16:49:22,645 [INFO]   æ ‡é¢˜: Large Language Models on Mobile Devices: Measurements, Analy...
2026-01-18 16:49:42,486 [INFO]   â†’ åˆ†ç±»: åŸºå‡†æµ‹è¯• (ğŸ†• æ–°å»º)
2026-01-18 16:49:42,487 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯æ¨ç†', 'æ€§èƒ½è¯„æµ‹', 'å¤§è¯­è¨€æ¨¡å‹', 'å»¶è¿Ÿåˆ†æ', 'å†…å­˜å ç”¨']
2026-01-18 16:49:42,487 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:49:42,487 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡å¹¶éæå‡ºå…·ä½“çš„ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚é‡åŒ–æˆ–å‰ªæï¼‰ï¼Œè€Œæ˜¯å¯¹ç§»åŠ¨ç«¯å¤§æ¨¡å‹çš„æ€§èƒ½ï¼ˆå»¶è¿Ÿã€å†…å­˜ã€ç²¾åº¦ï¼‰è¿›è¡Œäº†å¹¿æ³›çš„å®è¯æµ‹é‡å’Œåˆ†æï¼Œå±äºåŸºå‡†æµ‹è¯•ä¸è¯„ä¼°é¢†åŸŸã€‚
2026-01-18 16:49:42,489 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: åŸºå‡†æµ‹è¯•
2026-01-18 16:49:42,490 [INFO] å½’æ¡£å®Œæˆ: Comprehensive_Measurement_Study_of_LLMs_on_Mobile_Devices -> åŸºå‡†æµ‹è¯•/Mobile_LLM_Inference_Measurement_Study
2026-01-18 16:49:42,490 [INFO]   âœ“ å½’æ¡£è‡³: åŸºå‡†æµ‹è¯•/Mobile_LLM_Inference_Measurement_Study
2026-01-18 16:49:43,990 [INFO] ----------------------------------------
2026-01-18 16:49:43,991 [INFO] [4/11] å¤„ç†: ElastiLM
2026-01-18 16:49:43,993 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Elastic On-Device LLM Service.md
2026-01-18 16:49:43,993 [INFO]   æ ‡é¢˜: Elastic On-Device LLM Service...
2026-01-18 16:50:08,222 [INFO]   â†’ åˆ†ç±»: åŠ¨æ€æ¨ç† (ğŸ†• æ–°å»º)
2026-01-18 16:50:08,223 [INFO]   â†’ æ ‡ç­¾: ['åŠ¨æ€æ¨ç†', 'ç¥ç»å…ƒé‡æ’åº', 'å¼¹æ€§æ¨¡å‹', 'SLOæ„ŸçŸ¥', 'æç¤ºè¯ä¼˜åŒ–']
2026-01-18 16:50:08,223 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:50:08,224 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒæœºåˆ¶æ˜¯'ElastiLM'ï¼Œå®ƒé€šè¿‡ç¥ç»å…ƒé‡æ’åºï¼ˆNeuron Reorderingï¼‰ç”Ÿæˆå¯å˜å¤§å°çš„å­æ¨¡å‹ï¼Œå¹¶æ ¹æ®æœåŠ¡ç­‰çº§ç›®æ ‡ï¼ˆSLOï¼‰åœ¨è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´æ¨¡å‹å¤§å°å’Œæç¤ºè¯é•¿åº¦ã€‚è¿™ç§æ ¹æ®è´Ÿè½½æˆ–çº¦æŸæ¡ä»¶å®æ—¶æ”¹å˜è®¡ç®—å›¾æˆ–è®¡ç®—é‡çš„æŠ€æœ¯å±äºåŠ¨æ€æ¨ç†ï¼ˆDynamic Inferenceï¼‰æˆ–è‡ªé€‚åº”è®¡ç®—é¢†åŸŸï¼ŒåŒºåˆ«äºé™æ€çš„å‰ªææˆ–é‡åŒ–ã€‚
2026-01-18 16:50:08,227 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: åŠ¨æ€æ¨ç†
2026-01-18 16:50:08,227 [INFO] å½’æ¡£å®Œæˆ: ElastiLM -> åŠ¨æ€æ¨ç†/ElastiLM_Elastic_On-Device_LLM_Service
2026-01-18 16:50:08,227 [INFO]   âœ“ å½’æ¡£è‡³: åŠ¨æ€æ¨ç†/ElastiLM_Elastic_On-Device_LLM_Service
2026-01-18 16:50:09,728 [INFO] ----------------------------------------
2026-01-18 16:50:09,729 [INFO] [5/11] å¤„ç†: Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper
2026-01-18 16:50:09,731 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper.md
2026-01-18 16:50:09,732 [INFO]   æ ‡é¢˜: BlueLM-V-3B: Algorithm and System Co-Design for Multimodal L...
2026-01-18 16:50:27,275 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 16:50:27,276 [INFO]   â†’ æ ‡ç­¾: ['ç®—æ³•ç³»ç»ŸååŒè®¾è®¡', 'åŠ¨æ€åˆ†è¾¨ç‡', '4-bité‡åŒ–', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'å¤šæ¨¡æ€å¤§æ¨¡å‹']
2026-01-18 16:50:27,276 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 16:50:27,276 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦ä»‹ç»äº†ä¸€ä¸ªåä¸ºBlueLM-V-3Bçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆMLLMï¼‰ï¼Œå¹¶é’ˆå¯¹ç§»åŠ¨ç«¯è¿›è¡Œäº†ç®—æ³•ï¼ˆå¦‚åŠ¨æ€åˆ†è¾¨ç‡é‡è®¾è®¡ï¼‰ä¸ç³»ç»Ÿï¼ˆå¦‚4-bité‡åŒ–ï¼‰çš„ååŒè®¾è®¡ã€‚è™½ç„¶æ¶‰åŠé‡åŒ–å’Œç³»ç»Ÿä¼˜åŒ–ï¼Œä½†æ ¸å¿ƒè´¡çŒ®åœ¨äºè¯¥è§†è§‰è¯­è¨€æ¨¡å‹çš„æ•´ä½“æ¶æ„ä¸å®ç°ï¼Œç¬¦åˆå·²æœ‰çš„'è§†è§‰è¯­è¨€æ¨¡å‹'åˆ†ç±»ã€‚
2026-01-18 16:50:27,279 [INFO] å½’æ¡£å®Œæˆ: Lu_BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_CVPR_2025_paper -> è§†è§‰è¯­è¨€æ¨¡å‹/BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_on_Mobile_Devices
2026-01-18 16:50:27,279 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/BlueLM-V-3B_Algorithm_and_System_Co-Design_for_Multimodal_Large_Language_Models_on_Mobile_Devices
2026-01-18 16:50:28,780 [INFO] ----------------------------------------
2026-01-18 16:50:28,781 [INFO] [6/11] å¤„ç†: ML_Drift
2026-01-18 16:50:28,783 [INFO]   æ ‡é¢˜: Scaling On-Device GPU Inference for Large Generative Models...
2026-01-18 16:50:51,639 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ†• æ–°å»º)
2026-01-18 16:50:51,640 [INFO]   â†’ æ ‡ç­¾: ['GPUåŠ é€Ÿ', 'æ¨ç†æ¡†æ¶', 'è·¨å¹³å°å…¼å®¹æ€§', 'ç«¯ä¾§ç”Ÿæˆå¼AI', 'å¤§æ¨¡å‹éƒ¨ç½²']
2026-01-18 16:50:51,640 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:50:51,640 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ML Driftæ¡†æ¶ï¼Œæ ¸å¿ƒè´¡çŒ®åœ¨äºè§£å†³è·¨å¹³å°GPU APIå¼€å‘å’Œåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šè¿è¡Œè¶…å¤§å‚æ•°æ¨¡å‹çš„å·¥ç¨‹æŒ‘æˆ˜ï¼Œå±äºç³»ç»Ÿè½¯ä»¶å±‚é¢çš„æ¨ç†å¼•æ“æ¶æ„ä¸ä¼˜åŒ–ï¼Œè€Œéæ¨¡å‹ç®—æ³•æˆ–ç‰¹å®šåº”ç”¨æ¨¡æ€ã€‚
2026-01-18 16:50:51,642 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: æ¨ç†å¼•æ“ä¼˜åŒ–
2026-01-18 16:50:51,642 [INFO] å½’æ¡£å®Œæˆ: ML_Drift -> æ¨ç†å¼•æ“ä¼˜åŒ–/ML_Drift_An_Optimized_Framework_for_On-Device_Generative_AI
2026-01-18 16:50:51,643 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/ML_Drift_An_Optimized_Framework_for_On-Device_Generative_AI
2026-01-18 16:50:53,143 [INFO] ----------------------------------------
2026-01-18 16:50:53,143 [INFO] [7/11] å¤„ç†: MobiEdit_Resource-efficient Knowledge Editing for Personalized On-device LLMs
2026-01-18 16:50:53,144 [INFO]   æ ‡é¢˜: MobiEdit: Resource-efficient Knowledge Editing for Personali...
2026-01-18 16:51:23,007 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘ (ğŸ†• æ–°å»º)
2026-01-18 16:51:23,007 [INFO]   â†’ æ ‡ç­¾: ['å‰å‘æ¢¯åº¦ä¼°è®¡', 'NPUåŠ é€Ÿ', 'é‡åŒ–', 'å‰ç¼€ç¼“å­˜', 'ç«¯ä¾§å­¦ä¹ ']
2026-01-18 16:51:23,007 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:51:23,007 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒä»»åŠ¡æ˜¯'çŸ¥è¯†ç¼–è¾‘'ï¼ˆKnowledge Editingï¼‰ï¼Œå³åœ¨ç«¯ä¾§æ›´æ–°æ¨¡å‹æƒé‡ä»¥ä¿®æ­£å¹»è§‰æˆ–ä¸ªæ€§åŒ–ï¼Œè¿™å±äºç«¯ä¾§å­¦ä¹ /è®­ç»ƒçš„å­é¢†åŸŸï¼ŒåŒºåˆ«äºçº¯ç²¹çš„æ¨ç†ä¼˜åŒ–æˆ–é™æ€æ¨¡å‹å‹ç¼©æŠ€æœ¯ã€‚
2026-01-18 16:51:23,017 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘
2026-01-18 16:51:23,018 [INFO] å½’æ¡£å®Œæˆ: MobiEdit_Resource-efficient Knowledge Editing for Personalized On-device LLMs -> ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘/MobiEdit_The_First_Mobile_Knowledge_Editing_Framework
2026-01-18 16:51:23,018 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘/MobiEdit_The_First_Mobile_Knowledge_Editing_Framework
2026-01-18 16:51:24,519 [INFO] ----------------------------------------
2026-01-18 16:51:24,520 [INFO] [8/11] å¤„ç†: Mobile_Generative_AI_Opportunities_and_Challenges
2026-01-18 16:51:24,521 [INFO]   æ ‡é¢˜: Mobile Generative AI: Opportunities and Challenges...
2026-01-18 16:51:53,070 [INFO]   â†’ åˆ†ç±»: æ¨¡å‹å‹ç¼© (ğŸ†• æ–°å»º)
2026-01-18 16:51:53,071 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç”Ÿæˆå¼AI', 'æ¨¡å‹å‹ç¼©', 'æ¨ç†å»¶è¿Ÿ', 'å†…å­˜æ¶ˆè€—', 'æƒé‡å ç”¨ç­–ç•¥']
2026-01-18 16:51:53,072 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:51:53,073 [INFO]   â†’ ç†ç”±: æ‘˜è¦æ˜ç¡®æåˆ°æå‡ºäº†ç”¨äºæ¨ç†çš„'æƒé‡å ç”¨ç­–ç•¥'ä»¥è¿›è¡Œ'æ¨¡å‹å‹ç¼©'ã€‚è™½ç„¶è®ºæ–‡åŒ…å«åŸºå‡†æµ‹è¯•å†…å®¹ï¼Œä½†å…¶æå‡ºçš„å…·ä½“æŠ€æœ¯è§£å†³æ–¹æ¡ˆå±äºæ¨¡å‹å‹ç¼©é¢†åŸŸã€‚æ¨¡å‹å‹ç¼©ï¼ˆå«é‡åŒ–ã€å‰ªæç­‰ï¼‰æ˜¯ç«¯ä¾§AIçš„æ ¸å¿ƒç»†åˆ†é¢†åŸŸï¼Œå½“å‰åˆ—è¡¨ä¸­ç¼ºå¤±ã€‚
2026-01-18 16:51:53,076 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: æ¨¡å‹å‹ç¼©
2026-01-18 16:51:53,077 [INFO] å½’æ¡£å®Œæˆ: Mobile_Generative_AI_Opportunities_and_Challenges -> æ¨¡å‹å‹ç¼©/Mobile_GenAI_Deploying_Large_Generative_Models_on_Mobile_Devices
2026-01-18 16:51:53,077 [INFO]   âœ“ å½’æ¡£è‡³: æ¨¡å‹å‹ç¼©/Mobile_GenAI_Deploying_Large_Generative_Models_on_Mobile_Devices
2026-01-18 16:51:54,578 [INFO] ----------------------------------------
2026-01-18 16:51:54,578 [INFO] [9/11] å¤„ç†: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones_translated
2026-01-18 16:51:54,581 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones_translated.md
2026-01-18 16:51:54,581 [INFO]   æ ‡é¢˜: åœ¨æ™ºèƒ½æ‰‹æœºä¸Šä½¿ç”¨ç§»åŠ¨NPUæ‰©å±•LLMæµ‹è¯•æ—¶é—´è®¡ç®—...
2026-01-18 16:52:44,205 [INFO]   â†’ åˆ†ç±»: æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾ (ğŸ†• æ–°å»º)
2026-01-18 16:52:44,206 [INFO]   â†’ æ ‡ç­¾: ['æµ‹è¯•æ—¶ç¼©æ”¾', 'ç§»åŠ¨NPU', 'ç“¦ç‰‡é‡åŒ–', 'ç®—å­ä¼˜åŒ–', 'å¼‚æ„è®¡ç®—']
2026-01-18 16:52:44,206 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 16:52:44,206 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾'(Test-time scaling)è¿™ä¸€æ–°èŒƒå¼å¼•å…¥ç§»åŠ¨ç«¯ï¼Œå¹¶é€šè¿‡NPUç¡¬ä»¶æ„ŸçŸ¥ä¼˜åŒ–æ¥å®ç°å®ƒã€‚è™½ç„¶æ¶‰åŠé‡åŒ–å’Œç®—å­ä¼˜åŒ–ï¼Œä½†å…¶ç›®çš„æ˜¯ä¸ºäº†æ”¯æŒåŠ¨æ€å¢åŠ æ¨ç†è®¡ç®—é‡ä»¥æå‡æ¨¡å‹æ€§èƒ½ï¼Œè¿™ä¸ä¼ ç»Ÿçš„é™æ€æ¨¡å‹å‹ç¼©æˆ–é€šç”¨çš„æ¨ç†å¼•æ“ä¼˜åŒ–æœ‰æ˜¾è‘—åŒºåˆ«ï¼Œå±äºå¤§æ¨¡å‹æ¨ç†çš„æ–°å…´å­é¢†åŸŸã€‚
2026-01-18 16:52:44,208 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾
2026-01-18 16:52:44,209 [INFO] å½’æ¡£å®Œæˆ: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones_translated -> æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾/Scaling_LLM_Test-Time_Compute_on_Smartphones_with_Mobile_NPUs
2026-01-18 16:52:44,209 [INFO]   âœ“ å½’æ¡£è‡³: æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾/Scaling_LLM_Test-Time_Compute_on_Smartphones_with_Mobile_NPUs
2026-01-18 16:52:45,709 [INFO] ----------------------------------------
2026-01-18 16:52:45,710 [INFO] [10/11] å¤„ç†: sd.npu_A_Mobile_Inference_Framework_for_Context-Aware_Text_Generation
2026-01-18 16:52:45,712 [INFO]   æ ‡é¢˜: Accelerating Mobile Language Model via Speculative Decoding ...
2026-01-18 16:53:01,955 [INFO]   â†’ åˆ†ç±»: æŠ•æœºè§£ç  (ğŸ“ ç°æœ‰)
2026-01-18 16:53:01,956 [INFO]   â†’ æ ‡ç­¾: ['æŠ•æœºè§£ç ', 'NPUåŠ é€Ÿ', 'åŠ¨æ€ç¡¬ä»¶è°ƒåº¦', 'ä¸Šä¸‹æ–‡æ„ŸçŸ¥', 'ç«¯ä¾§æ¨ç†']
2026-01-18 16:53:01,956 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:53:01,956 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ˜ç¡®æå‡ºäº†åä¸ºsd.npuçš„æ¡†æ¶ï¼Œå…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æŠ•æœºè§£ç ï¼ˆspeculative decodingï¼‰ä¸ç§»åŠ¨ç«¯NPUçš„åŠ¨æ€ç¡¬ä»¶è°ƒåº¦ç›¸ç»“åˆï¼Œä»¥åŠ é€Ÿç«¯ä¾§æ–‡æœ¬ç”Ÿæˆã€‚è™½ç„¶æ¶‰åŠç¡¬ä»¶è°ƒåº¦ï¼Œä½†æ ¸å¿ƒåŠ é€Ÿç®—æ³•å±äºæŠ•æœºè§£ç èŒƒç•´ã€‚
2026-01-18 16:53:01,959 [INFO] å½’æ¡£å®Œæˆ: sd.npu_A_Mobile_Inference_Framework_for_Context-Aware_Text_Generation -> æŠ•æœºè§£ç /sd.npu_Accelerating_Context-Aware_Text_Generation_on_Mobile_Devices
2026-01-18 16:53:01,959 [INFO]   âœ“ å½’æ¡£è‡³: æŠ•æœºè§£ç /sd.npu_Accelerating_Context-Aware_Text_Generation_on_Mobile_Devices
2026-01-18 16:53:03,459 [INFO] ----------------------------------------
2026-01-18 16:53:03,460 [INFO] [11/11] å¤„ç†: shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module
2026-01-18 16:53:03,461 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: (arxiv 25.8)Dynamic Sparse Attention on Mobile SoCs.md
2026-01-18 16:53:03,462 [INFO]   æ ‡é¢˜: Dynamic Sparse Attention on Mobile SoCs...
2026-01-18 16:53:21,724 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ³¨æ„åŠ› (ğŸ†• æ–°å»º)
2026-01-18 16:53:21,724 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ³¨æ„åŠ›', 'NPUåŠ é€Ÿ', 'å¼‚æ„è®¡ç®—', 'ç³»ç»Ÿç®—æ³•ååŒ', 'ç«¯ä¾§å¤§æ¨¡å‹']
2026-01-18 16:53:21,724 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 16:53:21,725 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†shadowAttnï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯é€šè¿‡ç³»ç»Ÿä¸ç®—æ³•ååŒè®¾è®¡çš„ç¨€ç–æ³¨æ„åŠ›ï¼ˆSparse Attentionï¼‰æœºåˆ¶ï¼Œåˆ©ç”¨NPUè¿›è¡Œå…ˆå¯¼è®¡ç®—ä»¥ç­›é€‰é‡è¦Tokenï¼Œä»è€Œå‡å°‘å¯¹CPU/GPUçš„ä¾èµ–å¹¶ä¼˜åŒ–ç«¯ä¾§æ¨ç†æ€§èƒ½ã€‚è¿™å±äºå…·ä½“çš„ç¨€ç–åŒ–æŠ€æœ¯ï¼ŒåŒºåˆ«äºé€šç”¨çš„æ¨ç†å¼•æ“ä¼˜åŒ–ã€‚
2026-01-18 16:53:21,726 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç¨€ç–æ³¨æ„åŠ›
2026-01-18 16:53:21,735 [INFO] å½’æ¡£å®Œæˆ: shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module -> ç¨€ç–æ³¨æ„åŠ›/shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module
2026-01-18 16:53:21,735 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ³¨æ„åŠ›/shadowAttn_A_System-Algorithm_Co-designed_Sparse_Attention_Module
2026-01-18 16:53:21,735 [INFO] ============================================================
2026-01-18 16:53:21,736 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:53:21,736 [INFO]   æˆåŠŸ: 10
2026-01-18 16:53:21,736 [INFO]   å¤±è´¥: 1
2026-01-18 16:53:21,736 [INFO]   è·³è¿‡: 0
2026-01-18 16:53:21,736 [INFO] ============================================================
2026-01-18 16:58:32,373 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 10
2026-01-18 16:58:32,393 [INFO] ============================================================
2026-01-18 16:58:32,393 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 16:58:32,393 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 16:58:32,393 [INFO] ============================================================
2026-01-18 16:58:32,394 [INFO] å…±æ‰«æåˆ° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:58:32,394 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 16:58:32,394 [INFO] ç°æœ‰ç±»åˆ« (10): ['åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'ç¨€ç–æ³¨æ„åŠ›', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹']
2026-01-18 16:58:32,394 [INFO] ----------------------------------------
2026-01-18 16:58:32,394 [INFO] [1/1] å¤„ç†: Mobile-Agent-RAG
2026-01-18 16:58:32,395 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Mobile-Agent-RAG_ Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment.md
2026-01-18 16:58:32,395 [INFO]   æ ‡é¢˜: Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination wit...
2026-01-18 16:58:34,389 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 16:59:07,968 [INFO]   â†’ åˆ†ç±»: ç§»åŠ¨æ™ºèƒ½ä½“ (ğŸ†• æ–°å»º)
2026-01-18 16:59:07,969 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨æ™ºèƒ½ä½“', 'æ£€ç´¢å¢å¼ºç”Ÿæˆ', 'åˆ†å±‚å¤šæ™ºèƒ½ä½“', 'UIè‡ªåŠ¨åŒ–', 'å¤šæ¨¡æ€å¤§æ¨¡å‹']
2026-01-18 16:59:07,969 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 16:59:07,969 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†Mobile-Agent-RAGæ¡†æ¶ï¼Œä¸“é—¨è§£å†³ç§»åŠ¨ç«¯æ™ºèƒ½ä½“åœ¨é•¿åºåˆ—è·¨åº”ç”¨ä»»åŠ¡ä¸­çš„è§„åˆ’å’Œæ‰§è¡Œé—®é¢˜ã€‚è™½ç„¶ä¾èµ–MLLMï¼Œä½†å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºåŸºäºRAGçš„åˆ†å±‚æ™ºèƒ½ä½“æ¶æ„ä¸UIäº¤äº’ç­–ç•¥ï¼Œå±äºç§»åŠ¨æ™ºèƒ½ä½“ï¼ˆMobile Agentï¼‰è¿™ä¸€ç‰¹å®šå­é¢†åŸŸï¼Œè€Œéå•çº¯çš„æ¨¡å‹æ¶æ„æˆ–å‹ç¼©æŠ€æœ¯ã€‚
2026-01-18 16:59:07,973 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç§»åŠ¨æ™ºèƒ½ä½“
2026-01-18 16:59:07,973 [INFO] å½’æ¡£å®Œæˆ: Mobile-Agent-RAG -> ç§»åŠ¨æ™ºèƒ½ä½“/Mobile-Agent-RAG_A_Hierarchical_Multi-Agent_Framework_with_Dual-Level_Retrieval_Augmentation
2026-01-18 16:59:07,974 [INFO]   âœ“ å½’æ¡£è‡³: ç§»åŠ¨æ™ºèƒ½ä½“/Mobile-Agent-RAG_A_Hierarchical_Multi-Agent_Framework_with_Dual-Level_Retrieval_Augmentation
2026-01-18 16:59:07,974 [INFO] ============================================================
2026-01-18 16:59:07,974 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 16:59:07,974 [INFO]   æˆåŠŸ: 1
2026-01-18 16:59:07,974 [INFO]   å¤±è´¥: 0
2026-01-18 16:59:07,974 [INFO]   è·³è¿‡: 0
2026-01-18 16:59:07,975 [INFO] ============================================================
2026-01-18 17:01:11,878 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 11
2026-01-18 17:01:11,899 [INFO] ============================================================
2026-01-18 17:01:11,899 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 17:01:11,900 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 17:01:11,900 [INFO] ============================================================
2026-01-18 17:01:11,901 [INFO] å…±æ‰«æåˆ° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 17:01:11,901 [INFO] å‘ç° 1 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 17:01:11,901 [INFO] ç°æœ‰ç±»åˆ« (11): ['åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹']
2026-01-18 17:01:11,901 [INFO] ----------------------------------------
2026-01-18 17:01:11,901 [INFO] [1/1] å¤„ç†: Fast On-device LLM Inference with NPUs
2026-01-18 17:01:11,904 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Fast On-device LLM Inference with NPUs .md
2026-01-18 17:01:11,904 [INFO]   æ ‡é¢˜: does not enhance the prefilling speed, it effectively reduce...
2026-01-18 17:01:13,873 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 17:01:56,421 [INFO]   â†’ åˆ†ç±»: å¼‚æ„è®¡ç®—è°ƒåº¦ (ğŸ†• æ–°å»º)
2026-01-18 17:01:56,422 [INFO]   â†’ æ ‡ç­¾: ['NPUå¸è½½', 'å¼‚æ„è®¡ç®—', 'é¢„å¡«å……ä¼˜åŒ–', 'ç®—å­è°ƒåº¦', 'ç«¯ä¾§æ¨ç†']
2026-01-18 17:01:56,422 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:01:56,423 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºäº†llm.npuç³»ç»Ÿï¼Œé€šè¿‡åœ¨CPUã€GPUå’ŒNPUä¹‹é—´è¿›è¡Œç»†ç²’åº¦çš„ä»»åŠ¡åˆ†é…ï¼ˆPromptåˆ†å—ã€å¼ é‡çº§ç¦»ç¾¤å€¼åˆ†ç¦»ã€Blockçº§ä¹±åºè°ƒåº¦ï¼‰æ¥å®ç°å¼‚æ„åŠ é€Ÿï¼Œè¿™æ¯”é€šç”¨çš„'æ¨ç†å¼•æ“ä¼˜åŒ–'æ›´ä¸ºå…·ä½“ã€‚
2026-01-18 17:01:56,427 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: å¼‚æ„è®¡ç®—è°ƒåº¦
2026-01-18 17:01:56,428 [INFO] å½’æ¡£å®Œæˆ: Fast On-device LLM Inference with NPUs -> å¼‚æ„è®¡ç®—è°ƒåº¦/llm.npu_Accelerating_On-device_LLM_Inference_via_NPU_Offloading
2026-01-18 17:01:56,429 [INFO]   âœ“ å½’æ¡£è‡³: å¼‚æ„è®¡ç®—è°ƒåº¦/llm.npu_Accelerating_On-device_LLM_Inference_via_NPU_Offloading
2026-01-18 17:01:56,429 [INFO] ============================================================
2026-01-18 17:01:56,429 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 17:01:56,430 [INFO]   æˆåŠŸ: 1
2026-01-18 17:01:56,430 [INFO]   å¤±è´¥: 0
2026-01-18 17:01:56,430 [INFO]   è·³è¿‡: 0
2026-01-18 17:01:56,430 [INFO] ============================================================
2026-01-18 17:20:17,590 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 12
2026-01-18 17:20:17,618 [INFO] ============================================================
2026-01-18 17:20:17,618 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 17:20:17,618 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 17:20:17,618 [INFO] ============================================================
2026-01-18 17:20:17,619 [INFO] å…±æ‰«æåˆ° 10 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 17:20:17,619 [INFO] å‘ç° 10 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 17:20:17,619 [INFO] ç°æœ‰ç±»åˆ« (12): ['åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'å¼‚æ„è®¡ç®—è°ƒåº¦', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹']
2026-01-18 17:20:17,619 [INFO] ----------------------------------------
2026-01-18 17:20:17,620 [INFO] [1/10] å¤„ç†: A system-level abstraction and service for flourishing AI-powered applications
2026-01-18 17:20:17,620 [INFO]   æ ‡é¢˜: A System-level Abstraction and Service for Flourishing AI-po...
2026-01-18 17:20:19,993 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 17:20:42,569 [INFO]   â†’ åˆ†ç±»: å¼‚æ„è®¡ç®—è°ƒåº¦ (ğŸ“ ç°æœ‰)
2026-01-18 17:20:42,570 [INFO]   â†’ æ ‡ç­¾: ['ç³»ç»Ÿçº§æŠ½è±¡', 'å¤šä»»åŠ¡èµ„æºç®¡ç†', 'å¼‚æ„è®¡ç®—', 'ç«¯ä¾§AIæœåŠ¡', 'å¹¶å‘è°ƒåº¦']
2026-01-18 17:20:42,570 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:20:42,570 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†X*Serv*ï¼Œä¸€ç§ç³»ç»Ÿçº§æŠ½è±¡å’Œè™šæ‹Ÿèƒ½åŠ›å±‚ï¼Œæ ¸å¿ƒè§£å†³çš„æ˜¯åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡Œå¤šä¸ªå¹¶å‘AIä»»åŠ¡æ—¶ï¼Œå¦‚ä½•é«˜æ•ˆç®¡ç†å’Œè°ƒåº¦GPUã€NPUç­‰å¼‚æ„ç¡¬ä»¶èµ„æºçš„é—®é¢˜ã€‚
2026-01-18 17:20:42,574 [INFO] å½’æ¡£å®Œæˆ: A system-level abstraction and service for flourishing AI-powered applications -> å¼‚æ„è®¡ç®—è°ƒåº¦/X_Serv_A_System-Level_Abstraction_and_Service_for_AI-Powered_Applications
2026-01-18 17:20:42,574 [INFO]   âœ“ å½’æ¡£è‡³: å¼‚æ„è®¡ç®—è°ƒåº¦/X_Serv_A_System-Level_Abstraction_and_Service_for_AI-Powered_Applications
2026-01-18 17:20:44,074 [INFO] ----------------------------------------
2026-01-18 17:20:44,075 [INFO] [2/10] å¤„ç†: Agent.xpu Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC
2026-01-18 17:20:44,076 [INFO]   æ ‡é¢˜: Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on ...
2026-01-18 17:21:03,038 [INFO]   â†’ åˆ†ç±»: å¼‚æ„è®¡ç®—è°ƒåº¦ (ğŸ“ ç°æœ‰)
2026-01-18 17:21:03,039 [INFO]   â†’ æ ‡ç­¾: ['å¼‚æ„è°ƒåº¦', 'ç®—å­æŠ¢å ', 'SoCèµ„æºç®¡ç†', 'ç«¯ä¾§æ¨ç†æœåŠ¡', 'å¸¦å®½æ„ŸçŸ¥']
2026-01-18 17:21:03,040 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 17:21:03,040 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯Agent.xpuç³»ç»Ÿï¼Œå…¶å…³é”®æŠ€æœ¯åœ¨äºé’ˆå¯¹å†…å­˜ç»Ÿä¸€çš„å¼‚æ„SoCï¼ˆCPU/GPU/NPUï¼‰è¿›è¡Œäº²å’Œæ€§å¼•å¯¼çš„åŠ é€Ÿå™¨æ˜ å°„ã€ç»†ç²’åº¦ç®—å­æŠ¢å è°ƒåº¦ä»¥åŠå¸¦å®½æ„ŸçŸ¥çš„ä»»åŠ¡åˆ†å‘ï¼Œä»¥è§£å†³ç§»åŠ¨æ™ºèƒ½ä½“åœºæ™¯ä¸‹å“åº”å¼å’Œä¸»åŠ¨å¼ä»»åŠ¡çš„èµ„æºå†²çªé—®é¢˜ã€‚è¿™å®Œå…¨ç¬¦åˆå¼‚æ„è®¡ç®—è°ƒåº¦çš„å®šä¹‰ã€‚
2026-01-18 17:21:03,043 [INFO] å½’æ¡£å®Œæˆ: Agent.xpu Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC -> å¼‚æ„è®¡ç®—è°ƒåº¦/Agent.xpu_An_Efficient_Serving_System_for_Agentic_LLM_Workloads_on_Memory-Unified_Heterogeneous_SoCs
2026-01-18 17:21:03,044 [INFO]   âœ“ å½’æ¡£è‡³: å¼‚æ„è®¡ç®—è°ƒåº¦/Agent.xpu_An_Efficient_Serving_System_for_Agentic_LLM_Workloads_on_Memory-Unified_Heterogeneous_SoCs
2026-01-18 17:21:04,545 [INFO] ----------------------------------------
2026-01-18 17:21:04,546 [INFO] [3/10] å¤„ç†: AME An Efficient Heterogeneous Agentic Memory Engine for Smartphones
2026-01-18 17:21:04,549 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: AME An Efficient Heterogeneous Agentic Memory Engine for Smartphones.md
2026-01-18 17:21:04,550 [INFO]   æ ‡é¢˜: 4.3 Hardware- and Workload-Aware Vector Index Design...
2026-01-18 17:21:44,031 [INFO]   â†’ åˆ†ç±»: ç«¯ä¾§å‘é‡æ•°æ®åº“ (ğŸ†• æ–°å»º)
2026-01-18 17:21:44,032 [INFO]   â†’ æ ‡ç­¾: ['å‘é‡æ•°æ®åº“', 'ç§»åŠ¨SoCä¼˜åŒ–', 'ç¡¬ä»¶æ„ŸçŸ¥è°ƒåº¦', 'æ™ºèƒ½ä½“è®°å¿†', 'æµæ°´çº¿å¹¶è¡Œ']
2026-01-18 17:21:44,032 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:21:44,032 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯é’ˆå¯¹ç§»åŠ¨ç«¯SoCç‰¹æ€§è®¾è®¡çš„ä¸“ç”¨å‘é‡æ•°æ®åº“ï¼ˆAMEï¼‰ï¼Œç”¨äºæ”¯æŒæ™ºèƒ½ä½“çš„é•¿æ—¶è®°å¿†æ£€ç´¢ã€‚è™½ç„¶æœåŠ¡äºç§»åŠ¨æ™ºèƒ½ä½“ï¼Œä½†å…¶æŠ€æœ¯æœ¬è´¨æ˜¯è§£å†³å­˜å‚¨ã€å¸¦å®½é™åˆ¶ä¸‹çš„å‘é‡æ£€ç´¢ï¼ˆVector Searchï¼‰å’Œç´¢å¼•ç»´æŠ¤é—®é¢˜ï¼Œå±äºæ£€ç´¢åŸºç¡€è®¾æ–½çš„ç³»ç»Ÿçº§ä¼˜åŒ–ï¼ŒåŒºåˆ«äºé€šç”¨çš„LLMæ¨ç†å¼•æ“ä¼˜åŒ–æˆ–ä¸Šå±‚çš„æ™ºèƒ½ä½“è§„åˆ’ç ”ç©¶ã€‚
2026-01-18 17:21:44,035 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç«¯ä¾§å‘é‡æ•°æ®åº“
2026-01-18 17:21:44,035 [INFO] å½’æ¡£å®Œæˆ: AME An Efficient Heterogeneous Agentic Memory Engine for Smartphones -> ç«¯ä¾§å‘é‡æ•°æ®åº“/AME_An_On-device_Agentic_Memory_Engine_Co-designed_with_Modern_Smartphone_SoCs
2026-01-18 17:21:44,035 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯ä¾§å‘é‡æ•°æ®åº“/AME_An_On-device_Agentic_Memory_Engine_Co-designed_with_Modern_Smartphone_SoCs
2026-01-18 17:21:45,536 [INFO] ----------------------------------------
2026-01-18 17:21:45,537 [INFO] [4/10] å¤„ç†: AutoNeural Co-Designing Vision-Language Models for NPU Inference
2026-01-18 17:21:45,539 [INFO]   æ ‡é¢˜: AutoNeural: Co-Designing Visionâ€“Language Models for NPU Infe...
2026-01-18 17:22:24,661 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 17:22:24,662 [INFO]   â†’ æ ‡ç­¾: ['NPUåŸç”Ÿæ¶æ„', 'çŠ¶æ€ç©ºé—´æ¨¡å‹', 'å…¨æ•´å‹æ¨ç†', 'ç¡¬ä»¶ååŒè®¾è®¡', 'æ··åˆæ¶æ„']
2026-01-18 17:22:24,663 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 17:22:24,663 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºAutoNeuralçš„ç«¯ä¾§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰æ¶æ„ï¼Œä¸“é—¨é’ˆå¯¹NPUç‰¹æ€§è¿›è¡Œäº†CNNä¸SSMçš„æ··åˆæ¶æ„è®¾è®¡ï¼Œä»¥è§£å†³ä¼ ç»ŸViTåœ¨NPUä¸Šçš„é‡åŒ–å’ŒI/Oç“¶é¢ˆã€‚è™½ç„¶æ¶‰åŠé‡åŒ–å’Œæ¶æ„è®¾è®¡ï¼Œä½†å…¶æ ¸å¿ƒäº§å‡ºæ˜¯ä¸€ä¸ªå…·ä½“çš„VLMæ¨¡å‹ï¼Œå› æ­¤å½’å…¥ç°æœ‰çš„'è§†è§‰è¯­è¨€æ¨¡å‹'åˆ†ç±»æœ€ä¸ºç²¾å‡†ã€‚
2026-01-18 17:22:24,666 [INFO] å½’æ¡£å®Œæˆ: AutoNeural Co-Designing Vision-Language Models for NPU Inference -> è§†è§‰è¯­è¨€æ¨¡å‹/AutoNeural_An_NPU-native_VLM_Architecture_Co-designed_for_Integer-only_Inference
2026-01-18 17:22:24,666 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/AutoNeural_An_NPU-native_VLM_Architecture_Co-designed_for_Integer-only_Inference
2026-01-18 17:22:26,166 [INFO] ----------------------------------------
2026-01-18 17:22:26,166 [INFO] [5/10] å¤„ç†: Context-Driven Performance Modeling for Causal Inference Operators on Neural Processing Units
2026-01-18 17:22:26,167 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Context-Driven Performance Modeling for Causal Inference Operators on Neural Processing Units.md
2026-01-18 17:22:26,167 [INFO]   æ ‡é¢˜: Context-Driven Performance Modeling for Causal Inference Ope...
2026-01-18 17:22:53,158 [INFO]   â†’ åˆ†ç±»: åŸºå‡†æµ‹è¯• (ğŸ“ ç°æœ‰)
2026-01-18 17:22:53,158 [INFO]   â†’ æ ‡ç­¾: ['NPU', 'é•¿ä¸Šä¸‹æ–‡æ¨ç†', 'çŠ¶æ€ç©ºé—´æ¨¡å‹', 'ç®—å­æ€§èƒ½åˆ†æ', 'è¾¹ç¼˜è®¡ç®—']
2026-01-18 17:22:53,158 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:22:53,159 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹æ˜¯å¯¹ç°ä»£NPUä¸Šçš„å› æœæ¨ç†ç®—å­ï¼ˆç‰¹åˆ«æ˜¯é’ˆå¯¹é•¿ä¸Šä¸‹æ–‡åœºæ™¯çš„æ ‡å‡†æ³¨æ„åŠ›æœºåˆ¶ä¸SSMç­‰æ¬¡äºŒæ¬¡æ–¹æ›¿ä»£æ–¹æ¡ˆï¼‰è¿›è¡Œå…¨é¢çš„æ€§èƒ½åˆ†æå’Œå¯¹æ¯”åŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨è¯†åˆ«ç¡¬ä»¶æ¶æ„ä¸åŒ¹é…å¯¼è‡´çš„ç“¶é¢ˆã€‚
2026-01-18 17:22:53,161 [INFO] å½’æ¡£å®Œæˆ: Context-Driven Performance Modeling for Causal Inference Operators on Neural Processing Units -> åŸºå‡†æµ‹è¯•/Performance_Analysis_of_Causal_Inference_Operators_on_a_Modern_NPU
2026-01-18 17:22:53,161 [INFO]   âœ“ å½’æ¡£è‡³: åŸºå‡†æµ‹è¯•/Performance_Analysis_of_Causal_Inference_Operators_on_a_Modern_NPU
2026-01-18 17:22:54,661 [INFO] ----------------------------------------
2026-01-18 17:22:54,662 [INFO] [6/10] å¤„ç†: From Principles to Practice A Systematic Study of LLM Serving on Multi-core NPUs
2026-01-18 17:22:54,664 [INFO]   æ ‡é¢˜: 3 NpuSim: a Multi-level Simulation Framework for Multi-core ...
2026-01-18 17:23:31,501 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 17:23:31,502 [INFO]   â†’ æ ‡ç­¾: ['å¤šæ ¸NPU', 'ä»¿çœŸæ¡†æ¶', 'å¼ é‡å¹¶è¡Œ', 'æ ¸å¿ƒæ˜ å°„', 'PDåˆ†ç¦»']
2026-01-18 17:23:31,502 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:23:31,502 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦ç ”ç©¶å¦‚ä½•åœ¨å¤šæ ¸NPUç¡¬ä»¶ä¸Šé€šè¿‡ä»¿çœŸæ¡†æ¶æ¥å¯»æ‰¾æœ€ä½³çš„å¼ é‡å¹¶è¡Œã€æ ¸å¿ƒæ˜ å°„ã€æ˜¾å­˜ç®¡ç†åŠPDï¼ˆPrefill-Decodeï¼‰ç­–ç•¥ï¼Œä»¥æå‡LLMæœåŠ¡çš„æ¨ç†æ€§èƒ½ã€‚è¿™äº›å±äºæ¨ç†å¼•æ“åœ¨ç‰¹å®šç¡¬ä»¶åç«¯ä¸Šçš„ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚
2026-01-18 17:23:31,513 [INFO] å½’æ¡£å®Œæˆ: From Principles to Practice A Systematic Study of LLM Serving on Multi-core NPUs -> æ¨ç†å¼•æ“ä¼˜åŒ–/Optimizing_LLM_Inference_on_Multi-Core_NPUs_via_Multi-Level_Simulation
2026-01-18 17:23:31,513 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/Optimizing_LLM_Inference_on_Multi-Core_NPUs_via_Multi-Level_Simulation
2026-01-18 17:23:33,014 [INFO] ----------------------------------------
2026-01-18 17:23:33,014 [INFO] [7/10] å¤„ç†: Kelle Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing
2026-01-18 17:23:33,016 [INFO]   æ ‡é¢˜: Kelle: Co-design KV Caching and eDRAM for Efficient LLM Serv...
2026-01-18 17:24:00,698 [INFO]   â†’ åˆ†ç±»: KVç¼“å­˜ä¼˜åŒ– (ğŸ†• æ–°å»º)
2026-01-18 17:24:00,699 [INFO]   â†’ æ ‡ç­¾: ['KVç¼“å­˜', 'eDRAM', 'è½¯ç¡¬ä»¶ååŒè®¾è®¡', 'å†…å­˜ç®¡ç†', 'é‡è®¡ç®—']
2026-01-18 17:24:00,699 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:24:00,699 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒç—›ç‚¹æ˜¯è¾¹ç¼˜è®¾å¤‡ä¸ŠLLMæ¨ç†æ—¶KV Cacheéšåºåˆ—é•¿åº¦å¢åŠ å¯¼è‡´çš„å†…å­˜å ç”¨å’Œè®¿é—®å¼€é”€ï¼Œæå‡ºçš„è§£å†³æ–¹æ¡ˆï¼ˆeDRAMåº”ç”¨ã€Kelleè½¯ç¡¬ä»¶ååŒã€é©±é€ä¸é‡è®¡ç®—ç®—æ³•ï¼‰å‡æ˜¯å›´ç»•ä¼˜åŒ–KV Cacheçš„å­˜å‚¨ä¸ç®¡ç†å±•å¼€çš„ã€‚
2026-01-18 17:24:00,713 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: KVç¼“å­˜ä¼˜åŒ–
2026-01-18 17:24:00,714 [INFO] å½’æ¡£å®Œæˆ: Kelle Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing -> KVç¼“å­˜ä¼˜åŒ–/Kelle_A_Software-Hardware_Co-design_Solution_for_LLM_Serving_on_Edge
2026-01-18 17:24:00,715 [INFO]   âœ“ å½’æ¡£è‡³: KVç¼“å­˜ä¼˜åŒ–/Kelle_A_Software-Hardware_Co-design_Solution_for_LLM_Serving_on_Edge
2026-01-18 17:24:02,216 [INFO] ----------------------------------------
2026-01-18 17:24:02,217 [INFO] [8/10] å¤„ç†: LLM-NPU_Towards_Efficient_Foundation_Model_Inference_on_Low-Power_Neural_Processing_Units
2026-01-18 17:24:02,218 [INFO]   æ ‡é¢˜: LLM-NPU: Towards Efficient Foundation Model Inference on Low...
2026-01-18 17:24:38,019 [INFO]   â†’ åˆ†ç±»: NPUæ¶æ„ä¸ä¼˜åŒ– (ğŸ†• æ–°å»º)
2026-01-18 17:24:38,019 [INFO]   â†’ æ ‡ç­¾: ['è½¯ç¡¬ä»¶ååŒ', 'NPU', 'ç®—å­èåˆ', 'é‡åŒ–', 'å­˜å†…è®¡ç®—']
2026-01-18 17:24:38,019 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 17:24:38,019 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†LLM-NPUæ¡†æ¶ï¼Œæ ¸å¿ƒè´¡çŒ®åœ¨äºé’ˆå¯¹NPUç¡¬ä»¶ç‰¹æ€§çš„è½¯ç¡¬ä»¶ååŒè®¾è®¡ï¼ˆCo-designï¼‰ã€‚é™¤äº†è½¯ä»¶å±‚é¢çš„ç®—å­èåˆå’Œé‡åŒ–å¤–ï¼Œè¿˜æ¶‰åŠå…·ä½“çš„ç¡¬ä»¶æ¶æ„æ”¹è¿›ï¼ˆå¦‚å­˜å†…è®¡ç®—ã€GEMMå¼•æ“ä¼˜åŒ–ã€ç»“æ„åŒ–ç¨€ç–åŠ é€Ÿï¼‰ï¼Œç°æœ‰çš„â€œæ¨ç†å¼•æ“ä¼˜åŒ–â€æˆ–â€œæ¨¡å‹å‹ç¼©â€æ— æ³•æ¶µç›–å…¶ç¡¬ä»¶è®¾è®¡å±‚é¢çš„åˆ›æ–°ã€‚
2026-01-18 17:24:38,021 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: NPUæ¶æ„ä¸ä¼˜åŒ–
2026-01-18 17:24:38,021 [INFO] å½’æ¡£å®Œæˆ: LLM-NPU_Towards_Efficient_Foundation_Model_Inference_on_Low-Power_Neural_Processing_Units -> NPUæ¶æ„ä¸ä¼˜åŒ–/LLM-NPU_A_Comprehensive_Software-Hardware_Co-optimization_Framework
2026-01-18 17:24:38,021 [INFO]   âœ“ å½’æ¡£è‡³: NPUæ¶æ„ä¸ä¼˜åŒ–/LLM-NPU_A_Comprehensive_Software-Hardware_Co-optimization_Framework
2026-01-18 17:24:39,522 [INFO] ----------------------------------------
2026-01-18 17:24:39,523 [INFO] [9/10] å¤„ç†: MobileLLM_ Optimizing Sub-billion Parameter Language Models for On-Device Use Cases
2026-01-18 17:24:39,524 [INFO]   æ ‡é¢˜: <span id="page-0-0"></span>MobileVLM: A Fast, Strong and Ope...
2026-01-18 17:24:57,099 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 17:24:57,099 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯å¤šæ¨¡æ€', 'è½»é‡çº§æ¨¡å‹', 'è§†è§‰è¯­è¨€æ¨¡å‹', 'ç«¯ä¾§æ¨ç†', 'é«˜æ•ˆæŠ•å½±å™¨']
2026-01-18 17:24:57,100 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 17:24:57,100 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†MobileVLMï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç§»åŠ¨è®¾å¤‡è®¾è®¡çš„å¤šæ¨¡æ€è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆMMVLMï¼‰ï¼Œæ ¸å¿ƒè´¡çŒ®åœ¨äºé€‚åˆç«¯ä¾§è¿è¡Œçš„è½»é‡çº§æ¨¡å‹æ¶æ„è®¾è®¡ï¼ˆåŒ…æ‹¬è¯­è¨€æ¨¡å‹ã€è§†è§‰ç¼–ç å™¨å’ŒæŠ•å½±å™¨ï¼‰ä»¥åŠåœ¨ç§»åŠ¨ç¡¬ä»¶ä¸Šçš„æ¨ç†æ€§èƒ½éªŒè¯ã€‚
2026-01-18 17:24:57,102 [INFO] å½’æ¡£å®Œæˆ: MobileLLM_ Optimizing Sub-billion Parameter Language Models for On-Device Use Cases -> è§†è§‰è¯­è¨€æ¨¡å‹/MobileVLM_A_Competent_Multimodal_Vision_Language_Model_Targeted_to_Run_on_Mobile_Devices
2026-01-18 17:24:57,102 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/MobileVLM_A_Competent_Multimodal_Vision_Language_Model_Targeted_to_Run_on_Mobile_Devices
2026-01-18 17:24:58,603 [INFO] ----------------------------------------
2026-01-18 17:24:58,603 [INFO] [10/10] å¤„ç†: T-MAN Enabling End-to-End Low-Bit LLM Inference on NPUs via Unified Table Lookup
2026-01-18 17:24:58,605 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: T-MAN Enabling End-to-End Low-Bit LLM Inference on NPUs via Unified Table Lookup.md
2026-01-18 17:24:58,606 [INFO]   æ ‡é¢˜: T-MAN: Enabling End-to-End Low-Bit LLM Inference on NPUs via...
2026-01-18 17:25:21,042 [INFO]   â†’ åˆ†ç±»: NPUæ¶æ„ä¸ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 17:25:21,043 [INFO]   â†’ æ ‡ç­¾: ['NPUåŠ é€Ÿ', 'æŸ¥è¡¨æ³•', 'åé‡åŒ–', 'ç®—å­èåˆ', 'ä½æ¯”ç‰¹æ¨ç†']
2026-01-18 17:25:21,043 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 17:25:21,043 [INFO]   â†’ ç†ç”±: è®ºæ–‡é’ˆå¯¹NPUåœ¨LLMæ¨ç†ä¸­å¤„ç†éGEMMæ“ä½œï¼ˆç‰¹åˆ«æ˜¯åé‡åŒ–ï¼‰æ•ˆç‡ä½ä¸‹çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæŸ¥è¡¨ï¼ˆTable Lookupï¼‰çš„ç®—å­æ˜ å°„ã€èåˆåé‡åŒ–ä»¥åŠé’ˆå¯¹NPUå‘é‡å•å…ƒçš„æµæ°´çº¿ä¼˜åŒ–ï¼Œå±äºå…¸å‹çš„NPUç¡¬ä»¶æ¶æ„é€‚é…ä¸ä¼˜åŒ–å·¥ä½œã€‚
2026-01-18 17:25:21,045 [INFO] å½’æ¡£å®Œæˆ: T-MAN Enabling End-to-End Low-Bit LLM Inference on NPUs via Unified Table Lookup -> NPUæ¶æ„ä¸ä¼˜åŒ–/T-MAN_High-Performance_and_Energy-Efficient_LLM_Inference_on_NPUs_via_Table_Lookup
2026-01-18 17:25:21,046 [INFO]   âœ“ å½’æ¡£è‡³: NPUæ¶æ„ä¸ä¼˜åŒ–/T-MAN_High-Performance_and_Energy-Efficient_LLM_Inference_on_NPUs_via_Table_Lookup
2026-01-18 17:25:21,046 [INFO] ============================================================
2026-01-18 17:25:21,046 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 17:25:21,047 [INFO]   æˆåŠŸ: 10
2026-01-18 17:25:21,047 [INFO]   å¤±è´¥: 0
2026-01-18 17:25:21,047 [INFO]   è·³è¿‡: 0
2026-01-18 17:25:21,047 [INFO] ============================================================
2026-01-18 22:32:53,434 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 15
2026-01-18 22:32:53,466 [INFO] ============================================================
2026-01-18 22:32:53,466 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 22:32:53,466 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 22:32:53,466 [INFO] ============================================================
2026-01-18 22:32:53,468 [INFO] å…±æ‰«æåˆ° 14 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:32:53,468 [INFO] å‘ç° 14 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:32:53,469 [INFO] ç°æœ‰ç±»åˆ« (15): ['KVç¼“å­˜ä¼˜åŒ–', 'NPUæ¶æ„ä¸ä¼˜åŒ–', 'åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'å¼‚æ„è®¡ç®—è°ƒåº¦', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç«¯ä¾§å‘é‡æ•°æ®åº“', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹']
2026-01-18 22:32:53,469 [INFO] ----------------------------------------
2026-01-18 22:32:53,469 [INFO] [1/14] å¤„ç†: Bitnet. cpp Efficient edge inference for ternary llms
2026-01-18 22:32:53,470 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Bitnet. cpp Efficient edge inference for ternary llms.md
2026-01-18 22:32:53,470 [INFO]   æ ‡é¢˜: Bitnet.cpp: Efficient Edge Inference for Ternary LLMs...
2026-01-18 22:32:56,591 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 22:33:28,886 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:33:28,886 [INFO]   â†’ æ ‡ç­¾: ['1-bitå¤§æ¨¡å‹', 'ä¸‰å€¼é‡åŒ–', 'æ¨ç†ç³»ç»Ÿ', 'çŸ©é˜µä¹˜æ³•ä¼˜åŒ–', 'æŸ¥æ‰¾è¡¨']
2026-01-18 22:33:28,887 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:33:28,887 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†Bitnet.cppï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹1-bitå’Œä¸‰å€¼å¤§æ¨¡å‹ï¼ˆTernary LLMsï¼‰è®¾è®¡çš„æ¨ç†ç³»ç»Ÿã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºé€šè¿‡ä¼˜åŒ–çš„æ··åˆç²¾åº¦çŸ©é˜µä¹˜æ³•ï¼ˆmpGEMMï¼‰åº“ã€ä¸‰å€¼æŸ¥æ‰¾è¡¨ï¼ˆTLï¼‰å’ŒInt2ç¼©æ”¾ï¼ˆI2_Sï¼‰æŠ€æœ¯æ¥åŠ é€Ÿç«¯ä¾§æ¨ç†å¹¶ä¿æŒç²¾åº¦ï¼Œå±äºæ¨ç†æ¡†æ¶æ„å»ºä¸åº•å±‚ç®—å­ä¼˜åŒ–ã€‚
2026-01-18 22:33:28,899 [INFO] å½’æ¡£å®Œæˆ: Bitnet. cpp Efficient edge inference for ternary llms -> æ¨ç†å¼•æ“ä¼˜åŒ–/Bitnet.cpp
2026-01-18 22:33:28,899 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/Bitnet.cpp
2026-01-18 22:33:30,399 [INFO] ----------------------------------------
2026-01-18 22:33:30,400 [INFO] [2/14] å¤„ç†: Blockffn Towards end-side acceleration-friendly mixture-of-experts with chunk-level activation sparsity
2026-01-18 22:33:30,401 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Blockffn Towards end-side acceleration-friendly mixture-of-experts with chunk-level activation sparsity.md
2026-01-18 22:33:30,401 [INFO]   æ ‡é¢˜: BlockFFN: Towards End-Side Acceleration-Friendly Mixtureof-E...
2026-01-18 22:34:15,029 [INFO]   â†’ åˆ†ç±»: æ··åˆä¸“å®¶æ¨¡å‹ (ğŸ†• æ–°å»º)
2026-01-18 22:34:15,029 [INFO]   â†’ æ ‡ç­¾: ['æ··åˆä¸“å®¶æ¨¡å‹', 'æ¿€æ´»ç¨€ç–æ€§', 'æŠ•æœºè§£ç ', 'ç®—å­ä¼˜åŒ–', 'ç«¯ä¾§æ¨ç†']
2026-01-18 22:34:15,030 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:34:15,030 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ ¸å¿ƒæå‡ºäº†ä¸€ç§åä¸ºBlockFFNçš„æ–°å‹MoEï¼ˆMixture-of-Expertsï¼‰æ¶æ„ï¼Œé€šè¿‡ä¼˜åŒ–æ¿€æ´»ç¨€ç–æ€§å’Œè·¯ç”±æœºåˆ¶æ¥é€‚åº”ç«¯ä¾§è®¾å¤‡ã€‚è™½ç„¶æ¶‰åŠæŠ•æœºè§£ç å’Œç®—å­ä¼˜åŒ–ï¼Œä½†å…¶æœ¬è´¨æ˜¯MoEæ¶æ„çš„æ”¹è¿›ã€‚ç°æœ‰çš„'ç¨€ç–æ³¨æ„åŠ›'ä»…é’ˆå¯¹Attentionå±‚ï¼Œè€ŒMoEé’ˆå¯¹FFNå±‚ï¼Œä¸”MoEæ˜¯å½“å‰ç«¯ä¾§å¤§æ¨¡å‹ç ”ç©¶çš„ä¸€ä¸ªé‡è¦ç‹¬ç«‹åˆ†æ”¯ï¼Œå€¼å¾—å•ç‹¬åˆ†ç±»ã€‚
2026-01-18 22:34:15,031 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: æ··åˆä¸“å®¶æ¨¡å‹
2026-01-18 22:34:15,032 [INFO] å½’æ¡£å®Œæˆ: Blockffn Towards end-side acceleration-friendly mixture-of-experts with chunk-level activation sparsity -> æ··åˆä¸“å®¶æ¨¡å‹/BlockFFN_High-Efficiency_MoE_Architecture_with_Activation_Sparsity_for_End-Side_Devices
2026-01-18 22:34:15,032 [INFO]   âœ“ å½’æ¡£è‡³: æ··åˆä¸“å®¶æ¨¡å‹/BlockFFN_High-Efficiency_MoE_Architecture_with_Activation_Sparsity_for_End-Side_Devices
2026-01-18 22:34:16,532 [INFO] ----------------------------------------
2026-01-18 22:34:16,533 [INFO] [3/14] å¤„ç†: Cognitive Edge Computing A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment
2026-01-18 22:34:16,534 [INFO]   æ ‡é¢˜: Cognitive Edge Computing: A Comprehensive Survey on Optimizi...
2026-01-18 22:35:26,225 [INFO]   â†’ åˆ†ç±»: ç«¯äº‘ååŒ (ğŸ†• æ–°å»º)
2026-01-18 22:35:26,226 [INFO]   â†’ æ ‡ç­¾: ['è®¤çŸ¥è¾¹ç¼˜è®¡ç®—', 'ç«¯äº‘ååŒ', 'å¼¹æ€§å¸è½½', 'æ¨¡å‹å‹ç¼©', 'ç§»åŠ¨æ™ºèƒ½ä½“']
2026-01-18 22:35:26,226 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:35:26,226 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†åŒ…å«å¼¹æ€§å¸è½½ï¼ˆelastic offloadingï¼‰å’Œç«¯äº‘ååŒçš„ç³»ç»Ÿæ¶æ„ï¼Œä½œä¸ºåœ¨èµ„æºå—é™è®¾å¤‡ä¸Šéƒ¨ç½²æ¨ç†èƒ½åŠ›æ¨¡å‹çš„å…³é”®è·¯å¾„ã€‚è¿™å±äºåˆ†å¸ƒå¼æ¨ç†å’Œè¾¹ç¼˜è®¡ç®—æ¶æ„çš„å…·ä½“æŠ€æœ¯é¢†åŸŸï¼Œç°æœ‰åˆ†ç±»ä¸»è¦é›†ä¸­åœ¨å•è®¾å¤‡ä¾§ä¼˜åŒ–ï¼ˆå¦‚KVç¼“å­˜ã€NPUä¼˜åŒ–ï¼‰ï¼Œç¼ºä¹é’ˆå¯¹è·¨è®¾å¤‡/äº‘è¾¹ååŒæ¶æ„çš„åˆ†ç±»ã€‚
2026-01-18 22:35:26,232 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç«¯äº‘ååŒ
2026-01-18 22:35:26,235 [INFO] å½’æ¡£å®Œæˆ: Cognitive Edge Computing A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment -> ç«¯äº‘ååŒ/Cognitive_Edge_Computing_A_Survey
2026-01-18 22:35:26,236 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯äº‘ååŒ/Cognitive_Edge_Computing_A_Survey
2026-01-18 22:35:27,737 [INFO] ----------------------------------------
2026-01-18 22:35:27,738 [INFO] [4/14] å¤„ç†: Coreinfer Accelerating large language model inference with semantics-inspired adaptive sparse activation
2026-01-18 22:35:27,740 [INFO]   æ ‡é¢˜: COREINFER: ACCELERATING LARGE LANGUAGE MODEL INFERENCE WITH ...
2026-01-18 22:36:08,213 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ¿€æ´» (ğŸ†• æ–°å»º)
2026-01-18 22:36:08,214 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ¿€æ´»', 'æ ¸å¿ƒç¥ç»å…ƒ', 'å¥å­çº§é¢„æµ‹', 'FFNç¨€ç–åŒ–', 'åŠ¨æ€æ¨ç†']
2026-01-18 22:36:08,214 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:36:08,215 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ ¸å¿ƒæŠ€æœ¯æ˜¯'è‡ªé€‚åº”ç¨€ç–æ¿€æ´»æ¨ç†'(Adaptive sparse activation inference)ï¼Œç‰¹æŒ‡åœ¨æ¨ç†è¿‡ç¨‹ä¸­æ ¹æ®è¾“å…¥åŠ¨æ€é€‰æ‹©FFNå±‚çš„éƒ¨åˆ†ç¥ç»å…ƒè¿›è¡Œè®¡ç®—ã€‚è™½ç„¶è¿™å±äºå¹¿ä¹‰çš„'åŠ¨æ€æ¨ç†'ï¼Œä½†é‰´äºç°æœ‰åˆ†ç±»ä¸­å·²å•ç‹¬åˆ—å‡ºé’ˆå¯¹Attentionå±‚çš„'ç¨€ç–æ³¨æ„åŠ›'ï¼Œä¸ºäº†ä¿æŒç´¢å¼•ä½“ç³»çš„ç»†ç²’åº¦ä¸å¯¹ç§°æ€§ï¼Œå»ºè®®æ–°å»º'ç¨€ç–æ¿€æ´»'ä»¥ä¸“é—¨æ¶µç›–é’ˆå¯¹FFN/MLPå±‚çš„åŠ¨æ€ç¨€ç–åŒ–æŠ€æœ¯ã€‚
2026-01-18 22:36:08,217 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: ç¨€ç–æ¿€æ´»
2026-01-18 22:36:08,218 [INFO] å½’æ¡£å®Œæˆ: Coreinfer Accelerating large language model inference with semantics-inspired adaptive sparse activation -> ç¨€ç–æ¿€æ´»/CoreInfer_Accelerating_Large_Language_Model_Inference_with_Sentence-wise_Core_Neurons
2026-01-18 22:36:08,218 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ¿€æ´»/CoreInfer_Accelerating_Large_Language_Model_Inference_with_Sentence-wise_Core_Neurons
2026-01-18 22:36:09,718 [INFO] ----------------------------------------
2026-01-18 22:36:09,718 [INFO] [5/14] å¤„ç†: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching
2026-01-18 22:36:09,719 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching.md'
2026-01-18 22:36:11,219 [INFO] ----------------------------------------
2026-01-18 22:36:11,220 [INFO] [6/14] å¤„ç†: Make Your LVLM KV Cache More Lightweight
2026-01-18 22:36:11,222 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Make Your LVLM KV Cache More Lightweight.md
2026-01-18 22:36:11,222 [INFO]   æ ‡é¢˜: MAKE YOUR LVLM KV CACHE MORE LIGHTWEIGHT...
2026-01-18 22:36:44,065 [INFO]   â†’ åˆ†ç±»: KVç¼“å­˜ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:36:44,065 [INFO]   â†’ æ ‡ç­¾: ['KVç¼“å­˜å‹ç¼©', 'è§†è§‰è¯­è¨€æ¨¡å‹', 'Tokenå‹ç¼©', 'è·¨æ¨¡æ€äº¤äº’', 'æ˜¾å­˜ä¼˜åŒ–']
2026-01-18 22:36:44,066 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:36:44,066 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†LightKVæ–¹æ³•ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯è§£å†³å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰æ¨ç†ä¸­KVç¼“å­˜å ç”¨è¿‡å¤§çš„é—®é¢˜ã€‚é€šè¿‡åˆ©ç”¨æ–‡æœ¬æç¤ºå¼•å¯¼è§†è§‰Tokençš„å‹ç¼©ï¼Œæ˜¾è‘—å‡å°‘äº†KVç¼“å­˜çš„å¤§å°å’Œè®¡ç®—é‡ï¼Œå®Œå…¨ç¬¦åˆKVç¼“å­˜ä¼˜åŒ–çš„å®šä¹‰ã€‚
2026-01-18 22:36:44,073 [INFO] å½’æ¡£å®Œæˆ: Make Your LVLM KV Cache More Lightweight -> KVç¼“å­˜ä¼˜åŒ–/LightKV_Reducing_KV_Cache_Size_in_Large_Vision-Language_Models
2026-01-18 22:36:44,074 [INFO]   âœ“ å½’æ¡£è‡³: KVç¼“å­˜ä¼˜åŒ–/LightKV_Reducing_KV_Cache_Size_in_Large_Vision-Language_Models
2026-01-18 22:36:45,576 [INFO] ----------------------------------------
2026-01-18 22:36:45,577 [INFO] [7/14] å¤„ç†: Minstrel Application-Aware SLM Inference Optimization on Edge Devices
2026-01-18 22:36:45,579 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Minstrel Application-Aware SLM Inference Optimization on Edge Devices.md
2026-01-18 22:36:45,580 [INFO]   æ ‡é¢˜: Minstrel: Application-Aware SLM Inference Optimization on Ed...
2026-01-18 22:37:06,779 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:37:06,781 [INFO]   â†’ æ ‡ç­¾: ['åº”ç”¨æ„ŸçŸ¥ä¼˜åŒ–', 'å»¶è¿Ÿé¢„æµ‹', 'å°è¯­è¨€æ¨¡å‹', 'Prefill/Decodeåˆ†æ', 'è¾¹ç¼˜æ¨ç†']
2026-01-18 22:37:06,781 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:37:06,782 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†Minstrelæ¡†æ¶ï¼Œé€šè¿‡æ··åˆç»éªŒä¸åˆ†ææ¨¡å‹é¢„æµ‹æ¨ç†å»¶è¿Ÿï¼Œå¹¶æ ¹æ®åº”ç”¨ç‰¹æ€§ï¼ˆPrefillä¸Decodeé˜¶æ®µçš„é•¿åº¦åˆ†å¸ƒï¼‰å°†ä»»åŠ¡åˆ’åˆ†ä¸ºä¸åŒåŒºåŸŸï¼ˆP-Zone/D-Zoneï¼‰ä»¥æŒ‡å¯¼ä¼˜åŒ–ç­–ç•¥ï¼Œè¿™å±äºæ¨ç†å¼•æ“å±‚é¢çš„æ€§èƒ½å»ºæ¨¡ä¸æ‰§è¡Œç­–ç•¥ä¼˜åŒ–ã€‚
2026-01-18 22:37:06,786 [INFO] å½’æ¡£å®Œæˆ: Minstrel Application-Aware SLM Inference Optimization on Edge Devices -> æ¨ç†å¼•æ“ä¼˜åŒ–/Minstrel_An_Application-Aware_Optimization_Framework_for_SLM_Inference_on_Edge_Hardware
2026-01-18 22:37:06,786 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/Minstrel_An_Application-Aware_Optimization_Framework_for_SLM_Inference_on_Edge_Hardware
2026-01-18 22:37:08,287 [INFO] ----------------------------------------
2026-01-18 22:37:08,287 [INFO] [8/14] å¤„ç†: Neuralink Fast on-Device LLM Inference with Neuron Co-Activation Linking
2026-01-18 22:37:08,288 [INFO]   æ ‡é¢˜: NEURALINK: Fast LLM Inference on Smartphones with Neuron Co-...
2026-01-18 22:37:17,027 [INFO] 
ç”¨æˆ·ä¸­æ–­
2026-01-18 22:37:21,482 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 18
2026-01-18 22:37:21,509 [INFO] ============================================================
2026-01-18 22:37:21,509 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 22:37:21,510 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 22:37:21,510 [INFO] ============================================================
2026-01-18 22:37:21,513 [INFO] å…±æ‰«æåˆ° 28 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:37:21,513 [INFO] å‘ç° 28 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:37:21,513 [INFO] ç°æœ‰ç±»åˆ« (18): ['KVç¼“å­˜ä¼˜åŒ–', 'NPUæ¶æ„ä¸ä¼˜åŒ–', 'åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'å¼‚æ„è®¡ç®—è°ƒåº¦', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'æ··åˆä¸“å®¶æ¨¡å‹', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç¨€ç–æ¿€æ´»', 'ç«¯äº‘ååŒ', 'ç«¯ä¾§å‘é‡æ•°æ®åº“', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹']
2026-01-18 22:37:21,513 [INFO] ----------------------------------------
2026-01-18 22:37:21,513 [INFO] [1/28] å¤„ç†: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency
2026-01-18 22:37:21,515 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency.md
2026-01-18 22:37:21,515 [INFO]   æ ‡é¢˜: Dissecting the Impact of Mobile DVFS Governors on LLM Infere...
2026-01-18 22:37:23,893 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 22:37:51,034 [INFO]   â†’ åˆ†ç±»: èƒ½æ•ˆä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:37:51,035 [INFO]   â†’ æ ‡ç­¾: ['DVFSä¼˜åŒ–', 'é¢‘ç‡è°ƒèŠ‚å™¨', 'èƒ½æ•ˆç®¡ç†', 'CPU-GPU-å†…å­˜ååŒ', 'ç§»åŠ¨ç«¯æ¨ç†']
2026-01-18 22:37:51,035 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:37:51,035 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†FUSEï¼Œä¸€ç§é’ˆå¯¹ç§»åŠ¨è®¾å¤‡çš„ç»Ÿä¸€èƒ½æºæ„ŸçŸ¥è°ƒèŠ‚å™¨ï¼ˆGovernorï¼‰ï¼Œé€šè¿‡ååŒä¼˜åŒ–CPUã€GPUå’Œå†…å­˜çš„DVFSï¼ˆåŠ¨æ€ç”µå‹é¢‘ç‡è°ƒæ•´ï¼‰ç­–ç•¥ï¼Œè§£å†³ç°æœ‰ç‹¬ç«‹è°ƒèŠ‚å¯¼è‡´çš„èƒ½æ•ˆä½ä¸‹é—®é¢˜ï¼Œæ ¸å¿ƒç›®æ ‡æ˜¯æå‡LLMæ¨ç†çš„èƒ½æ•ˆã€‚
2026-01-18 22:37:51,037 [INFO] å½’æ¡£å®Œæˆ: Dissecting the Impact of Mobile DVFS Governors on LLM Inference Performance and Energy Efficiency -> èƒ½æ•ˆä¼˜åŒ–/FUSE_A_Unified_Energy-Aware_Governor_for_Optimizing_the_Energy_Efficiency_of_LLM_Inference_on_Mobile_1
2026-01-18 22:37:51,037 [INFO]   âœ“ å½’æ¡£è‡³: èƒ½æ•ˆä¼˜åŒ–/FUSE_A_Unified_Energy-Aware_Governor_for_Optimizing_the_Energy_Efficiency_of_LLM_Inference_on_Mobile_1
2026-01-18 22:37:52,537 [INFO] ----------------------------------------
2026-01-18 22:37:52,538 [INFO] [2/28] å¤„ç†: DynaKV Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones
2026-01-18 22:37:52,547 [INFO]   æ ‡é¢˜: DYNAKV: Enabling Accurate and Efficient Long-Sequence LLM De...
2026-01-18 22:38:17,354 [INFO]   â†’ åˆ†ç±»: KVç¼“å­˜ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:38:17,354 [INFO]   â†’ æ ‡ç­¾: ['KVç¼“å­˜', 'é•¿åºåˆ—æ¨ç†', 'é—ªå­˜å¸è½½', 'åŠ¨æ€èšç±»', 'å­˜å‚¨ç®¡ç†']
2026-01-18 22:38:17,355 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:38:17,355 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºçš„DynaKVæ—¨åœ¨è§£å†³æ™ºèƒ½æ‰‹æœºä¸Šé•¿åºåˆ—æ¨ç†æ—¶KV Cacheæ˜¾å­˜å ç”¨è¿‡å¤§çš„é—®é¢˜ï¼Œé€šè¿‡å°†KV Cacheå¸è½½åˆ°Flashå­˜å‚¨å¹¶è¿›è¡ŒåŠ¨æ€èšç±»ç®¡ç†æ¥ä¼˜åŒ–å†…å­˜å ç”¨ï¼Œå±äºå…¸å‹çš„KVç¼“å­˜ä¼˜åŒ–æŠ€æœ¯ã€‚
2026-01-18 22:38:17,357 [INFO] å½’æ¡£å®Œæˆ: DynaKV Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones -> KVç¼“å­˜ä¼˜åŒ–/DynaKV_Adaptive_KVCache_Management_for_Long-Sequence_Decoding_on_Smartphones
2026-01-18 22:38:17,358 [INFO]   âœ“ å½’æ¡£è‡³: KVç¼“å­˜ä¼˜åŒ–/DynaKV_Adaptive_KVCache_Management_for_Long-Sequence_Decoding_on_Smartphones
2026-01-18 22:38:18,859 [INFO] ----------------------------------------
2026-01-18 22:38:18,859 [INFO] [3/28] å¤„ç†: EdgeMoE Empowering Sparse Large Language Models on Mobile Devices
2026-01-18 22:38:18,860 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: EdgeMoE Empowering Sparse Large Language Models on Mobile Devices.md
2026-01-18 22:38:18,861 [INFO]   æ ‡é¢˜: EdgeMoE: Empowering Sparse Large Language Models on Mobile D...
2026-01-18 22:38:42,627 [INFO]   â†’ åˆ†ç±»: æ··åˆä¸“å®¶æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:38:42,627 [INFO]   â†’ æ ‡ç­¾: ['æ··åˆä¸“å®¶æ¨¡å‹', 'å†…å­˜åˆ†å±‚å­˜å‚¨', 'ä¸“å®¶äº¤æ¢', 'æ··åˆç²¾åº¦é‡åŒ–', 'I/Oæµæ°´çº¿ä¼˜åŒ–']
2026-01-18 22:38:42,627 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:38:42,627 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†EdgeMoEï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰è®¾è®¡çš„ç«¯ä¾§æ¨ç†å¼•æ“ã€‚å…¶æ ¸å¿ƒæŠ€æœ¯ï¼ˆå¦‚å°†éä¸“å®¶æƒé‡å’Œä¸“å®¶æƒé‡åˆ†å±‚å­˜å‚¨ã€æŒ‰éœ€åŠ è½½ä¸“å®¶ã€ä¸“å®¶çº§ä½å®½è‡ªé€‚åº”ï¼‰å‡æ˜¯ä¸ºäº†è§£å†³MoEæ¶æ„åœ¨ç§»åŠ¨ç«¯å†…å­˜å—é™ç¯å¢ƒä¸‹çš„éƒ¨ç½²é—®é¢˜ï¼Œå› æ­¤å½’ç±»ä¸ºæ··åˆä¸“å®¶æ¨¡å‹æœ€ä¸ºç²¾å‡†ã€‚
2026-01-18 22:38:42,630 [INFO] å½’æ¡£å®Œæˆ: EdgeMoE Empowering Sparse Large Language Models on Mobile Devices -> æ··åˆä¸“å®¶æ¨¡å‹/EdgeMoE_An_On-Device_Inference_Engine_for_Mixture-of-Expert_LLMs
2026-01-18 22:38:42,630 [INFO]   âœ“ å½’æ¡£è‡³: æ··åˆä¸“å®¶æ¨¡å‹/EdgeMoE_An_On-Device_Inference_Engine_for_Mixture-of-Expert_LLMs
2026-01-18 22:38:44,131 [INFO] ----------------------------------------
2026-01-18 22:38:44,131 [INFO] [4/28] å¤„ç†: Enabling Dynamic Sparsity in Quantized LLM Inference
2026-01-18 22:38:44,131 [INFO]   æ ‡é¢˜: ENABLING DYNAMIC SPARSITY IN QUANTIZED LLM INFERENCE...
2026-01-18 22:39:17,839 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ¿€æ´» (ğŸ“ ç°æœ‰)
2026-01-18 22:39:17,839 [INFO]   â†’ æ ‡ç­¾: ['åŠ¨æ€ç¨€ç–æ€§', 'åˆ†ç»„é‡åŒ–', 'GPUç®—å­ä¼˜åŒ–', 'Zigzagå¸ƒå±€', 'ç«¯ä¾§æ¨ç†']
2026-01-18 22:39:17,839 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:39:17,840 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒåˆ‡å…¥ç‚¹æ˜¯åˆ©ç”¨LLMå†…éƒ¨æ¿€æ´»çš„åŠ¨æ€ç¨€ç–æ€§ï¼ˆDynamic Sparsityï¼‰æ¥å‡å°‘è®¡ç®—é‡ï¼Œå¹¶ä¸“é—¨è§£å†³äº†ç¨€ç–æ¿€æ´»ä¸åˆ†ç»„é‡åŒ–ï¼ˆGroup-wise Quantizationï¼‰åœ¨ç¡¬ä»¶ä¸Šç»“åˆæ—¶çš„æ•ˆç‡é—®é¢˜ã€‚
2026-01-18 22:39:17,947 [INFO] å½’æ¡£å®Œæˆ: Enabling Dynamic Sparsity in Quantized LLM Inference -> ç¨€ç–æ¿€æ´»/Efficient_LLM_Inference_via_Co-design_of_Dynamic_Sparsity_and_Quantization
2026-01-18 22:39:17,948 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ¿€æ´»/Efficient_LLM_Inference_via_Co-design_of_Dynamic_Sparsity_and_Quantization
2026-01-18 22:39:19,448 [INFO] ----------------------------------------
2026-01-18 22:39:19,448 [INFO] [5/28] å¤„ç†: Enabling MoE on the Edge via Importance-Driven Expert Scheduling
2026-01-18 22:39:19,449 [INFO]   æ ‡é¢˜: Enabling MoE on the Edge via Importance-Driven Expert Schedu...
2026-01-18 22:39:42,938 [INFO]   â†’ åˆ†ç±»: æ··åˆä¸“å®¶æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:39:42,938 [INFO]   â†’ æ ‡ç­¾: ['æ··åˆä¸“å®¶æ¨¡å‹', 'åŠ¨æ€å¸è½½', 'æ˜¾å­˜ä¼˜åŒ–', 'ä¸“å®¶ç¼“å­˜', 'è¿‘ä¼¼è®¡ç®—']
2026-01-18 22:39:42,939 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:39:42,939 [INFO]   â†’ ç†ç”±: è®ºæ–‡é’ˆå¯¹æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡æ˜¾å­˜å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºä¸“å®¶é‡è¦æ€§çš„åŠ¨æ€å¸è½½ï¼ˆOffloadingï¼‰å’Œç¼“å­˜æ›¿æ¢ç­–ç•¥ï¼Œå±äºMoEæ¶æ„çš„ç‰¹å®šä¼˜åŒ–ã€‚
2026-01-18 22:39:42,941 [INFO] å½’æ¡£å®Œæˆ: Enabling MoE on the Edge via Importance-Driven Expert Scheduling -> æ··åˆä¸“å®¶æ¨¡å‹/Unknown_Title
2026-01-18 22:39:42,941 [INFO]   âœ“ å½’æ¡£è‡³: æ··åˆä¸“å®¶æ¨¡å‹/Unknown_Title
2026-01-18 22:39:44,441 [INFO] ----------------------------------------
2026-01-18 22:39:44,442 [INFO] [6/28] å¤„ç†: GenieBlue Integrating both Linguistic and Multimodal Capabilities for Large Language Models on Mobile Devices
2026-01-18 22:39:44,443 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: GenieBlue Integrating both Linguistic and Multimodal Capabilities for Large Language Models on Mobile Devices.md
2026-01-18 22:39:44,443 [INFO]   æ ‡é¢˜: <span id="page-0-2"></span>GenieBlue: Integrating both Lingu...
2026-01-18 22:40:08,351 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:40:08,351 [INFO]   â†’ æ ‡ç­¾: ['è§†è§‰è¯­è¨€æ¨¡å‹', 'NPUé€‚é…', 'LoRA', 'ç§»åŠ¨ç«¯éƒ¨ç½²', 'æ¶æ„è®¾è®¡']
2026-01-18 22:40:08,351 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:40:08,352 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†GenieBlueï¼Œä¸€ç§ä¸“ä¸ºç§»åŠ¨è®¾å¤‡è®¾è®¡çš„è½»é‡çº§å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰æ¶æ„ï¼Œæ—¨åœ¨è§£å†³ç«¯ä¾§NPUå¯¹MoEæ¶æ„æ”¯æŒä¸ä½³çš„é—®é¢˜ï¼ŒåŒæ—¶ä¿æŒçº¯è¯­è¨€èƒ½åŠ›ã€‚
2026-01-18 22:40:08,355 [INFO] å½’æ¡£å®Œæˆ: GenieBlue Integrating both Linguistic and Multimodal Capabilities for Large Language Models on Mobile Devices -> è§†è§‰è¯­è¨€æ¨¡å‹/GenieBlue_An_Efficient_MLLM_Structural_Design_for_Mobile_Devices
2026-01-18 22:40:08,355 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/GenieBlue_An_Efficient_MLLM_Structural_Design_for_Mobile_Devices
2026-01-18 22:40:09,855 [INFO] ----------------------------------------
2026-01-18 22:40:09,856 [INFO] [7/28] å¤„ç†: GRATING Low-Latency and Memory-Efficient Semantic Selection on Device
2026-01-18 22:40:09,856 [INFO]   æ ‡é¢˜: GRATING: Low-Latency and Memory-Efficient Semantic Selection...
2026-01-18 22:40:37,348 [INFO]   â†’ åˆ†ç±»: åŠ¨æ€æ¨ç† (ğŸ“ ç°æœ‰)
2026-01-18 22:40:37,348 [INFO]   â†’ æ ‡ç­¾: ['äº¤å‰ç¼–ç å™¨', 'åŠ¨æ€å‰ªæ', 'ç«¯ä¾§RAG', 'é‡æ’åº', 'æ˜¾å­˜ä¼˜åŒ–']
2026-01-18 22:40:37,348 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:40:37,348 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºçš„GRATINGç³»ç»Ÿæ ¸å¿ƒæŠ€æœ¯æ˜¯'æ¸è¿›å¼èšç±»å‰ªæ'ï¼ˆprogressive cluster pruningï¼‰ï¼Œå³åˆ©ç”¨ä¸­é—´å±‚ç»“æœåŠ¨æ€åœ°åœ¨æ¨ç†è¿‡ç¨‹ä¸­å‰”é™¤ä½æ’åçš„å€™é€‰åºåˆ—ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ã€‚è¿™ç§æ ¹æ®è¾“å…¥æ•°æ®åœ¨è¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´è®¡ç®—è·¯å¾„çš„æ–¹æ³•å±äºåŠ¨æ€æ¨ç†èŒƒç•´ã€‚
2026-01-18 22:40:37,350 [INFO] å½’æ¡£å®Œæˆ: GRATING Low-Latency and Memory-Efficient Semantic Selection on Device -> åŠ¨æ€æ¨ç†/GRATING_Semantic_Top-k_Selection_with_Cross-Encoder_Rerankers_for_On-Device_AI
2026-01-18 22:40:37,350 [INFO]   âœ“ å½’æ¡£è‡³: åŠ¨æ€æ¨ç†/GRATING_Semantic_Top-k_Selection_with_Cross-Encoder_Rerankers_for_On-Device_AI
2026-01-18 22:40:38,851 [INFO] ----------------------------------------
2026-01-18 22:40:38,851 [INFO] [8/28] å¤„ç†: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching
2026-01-18 22:40:38,852 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching.md'
2026-01-18 22:40:40,352 [INFO] ----------------------------------------
2026-01-18 22:40:40,353 [INFO] [9/28] å¤„ç†: Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach
2026-01-18 22:40:40,353 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach\\Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach.md'
2026-01-18 22:40:41,853 [INFO] ----------------------------------------
2026-01-18 22:40:41,854 [INFO] [10/28] å¤„ç†: MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning
2026-01-18 22:40:41,854 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning\\MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning.md'
2026-01-18 22:40:43,355 [INFO] ----------------------------------------
2026-01-18 22:40:43,355 [INFO] [11/28] å¤„ç†: MNN-LLM A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices
2026-01-18 22:40:43,357 [INFO]   æ ‡é¢˜: MNN-LLM: A Generic Inference Engine for Fast Large Language ...
2026-01-18 22:41:03,941 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:41:03,941 [INFO]   â†’ æ ‡ç­¾: ['æ¨ç†æ¡†æ¶', 'æ¨¡å‹é‡åŒ–', 'æ··åˆå­˜å‚¨', 'ç®—å­ä¼˜åŒ–', 'å¤šæ ¸è´Ÿè½½å‡è¡¡']
2026-01-18 22:41:03,942 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:41:03,942 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†MNN-LLMæ¡†æ¶ï¼Œé€šè¿‡DRAM-Flashæ··åˆå­˜å‚¨ã€åŸºäºæŒ‡ä»¤é›†çš„æƒé‡é‡æ’ã€å¤šæ ¸è´Ÿè½½å‡è¡¡å’Œæ··åˆç²¾åº¦è®¡ç®—ç­‰ç³»ç»Ÿçº§æŠ€æœ¯æ¥åŠ é€Ÿç§»åŠ¨ç«¯LLMæ¨ç†ï¼Œè¿™å±äºæ¨ç†å¼•æ“çš„æ¶æ„è®¾è®¡ä¸åº•å±‚ä¼˜åŒ–èŒƒç•´ã€‚
2026-01-18 22:41:03,944 [INFO] å½’æ¡£å®Œæˆ: MNN-LLM A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices -> æ¨ç†å¼•æ“ä¼˜åŒ–/MNN-LLM_A_Framework_Specifically_Designed_to_Accelerate_the_Deployment_of_Large_Language_Models_on_M
2026-01-18 22:41:03,944 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/MNN-LLM_A_Framework_Specifically_Designed_to_Accelerate_the_Deployment_of_Large_Language_Models_on_M
2026-01-18 22:41:05,444 [INFO] ----------------------------------------
2026-01-18 22:41:05,445 [INFO] [12/28] å¤„ç†: Mobile Edge Intelligence for Large Language Models A Contemporary Survey
2026-01-18 22:41:05,445 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Mobile Edge Intelligence for Large Language Models A Contemporary Survey.md
2026-01-18 22:41:05,446 [INFO]   æ ‡é¢˜: Mobile Edge Intelligence for Large Language Models: A Contem...
2026-01-18 22:41:31,445 [INFO]   â†’ åˆ†ç±»: ç«¯äº‘ååŒ (ğŸ“ ç°æœ‰)
2026-01-18 22:41:31,446 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨è¾¹ç¼˜æ™ºèƒ½', 'ç§»åŠ¨è¾¹ç¼˜è®¡ç®—', 'æ‹†åˆ†å­¦ä¹ ', 'è¾¹ç¼˜ç¼“å­˜', 'ç»¼è¿°']
2026-01-18 22:41:31,446 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:41:31,446 [INFO]   â†’ ç†ç”±: è®ºæ–‡ç»¼è¿°äº†åˆ©ç”¨ç§»åŠ¨è¾¹ç¼˜æ™ºèƒ½ï¼ˆMEIï¼‰å’Œç§»åŠ¨è¾¹ç¼˜è®¡ç®—ï¼ˆMECï¼‰æ¥æ”¯æŒLLMçš„éƒ¨ç½²ï¼Œæ¶‰åŠç«¯ä¾§ä¸è¾¹ç¼˜ä¾§çš„è®¡ç®—å¸è½½ã€è¾¹ç¼˜ç¼“å­˜ã€ååŒè®­ç»ƒä¸æ¨ç†ï¼ˆå¦‚æ‹†åˆ†å­¦ä¹ ï¼‰ï¼Œè¿™å±äºå…¸å‹çš„ç«¯è¾¹/ç«¯äº‘ååŒæŠ€æœ¯èŒƒç•´ã€‚
2026-01-18 22:41:31,450 [INFO] å½’æ¡£å®Œæˆ: Mobile Edge Intelligence for Large Language Models A Contemporary Survey -> ç«¯äº‘ååŒ/Harnessing_Mobile_Edge_Intelligence_for_Large_Language_Models_A_Contemporary_Survey
2026-01-18 22:41:31,450 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯äº‘ååŒ/Harnessing_Mobile_Edge_Intelligence_for_Large_Language_Models_A_Contemporary_Survey
2026-01-18 22:41:32,951 [INFO] ----------------------------------------
2026-01-18 22:41:32,951 [INFO] [13/28] å¤„ç†: MobileQuant Mobile-friendly Quantization for On-device Language Models
2026-01-18 22:41:32,952 [INFO]   æ ‡é¢˜: 4.1 Challenges for Mobile-friendly Quantization...
2026-01-18 22:42:14,818 [INFO]   â†’ åˆ†ç±»: é‡åŒ– (ğŸ†• æ–°å»º)
2026-01-18 22:42:14,818 [INFO]   â†’ æ ‡ç­¾: ['è®­ç»ƒåé‡åŒ–', 'æ¿€æ´»é‡åŒ–', 'å…¨æ•´æ•°é‡åŒ–', 'æƒé‡ç­‰ä»·å˜æ¢', 'NPUåŠ é€Ÿ']
2026-01-18 22:42:14,818 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:42:14,818 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯æå‡ºMobileQuantï¼Œä¸€ç§é’ˆå¯¹ç§»åŠ¨ç«¯NPUä¼˜åŒ–çš„å…¨æ•´æ•°è®­ç»ƒåé‡åŒ–ï¼ˆPTQï¼‰æ–¹æ³•ï¼Œé‡ç‚¹è§£å†³äº†æ¿€æ´»é‡åŒ–çš„éš¾é¢˜ã€‚è™½ç„¶å±äºæ¨¡å‹å‹ç¼©çš„å¤§èŒƒç•´ï¼Œä½†ä¸ºäº†å»ºç«‹ç»†ç²’åº¦ç´¢å¼•ï¼Œ'é‡åŒ–'ä½œä¸ºç‹¬ç«‹çš„æŠ€æœ¯ç±»åˆ«æ¯”'æ¨¡å‹å‹ç¼©'æ›´ä¸ºç²¾å‡†ä¸”ç¬¦åˆæ¨èç¤ºä¾‹ã€‚
2026-01-18 22:42:14,828 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: é‡åŒ–
2026-01-18 22:42:14,829 [INFO] å½’æ¡£å®Œæˆ: MobileQuant Mobile-friendly Quantization for On-device Language Models -> é‡åŒ–/MobileQuant_Mobile-friendly_Quantization_for_On-device_LLMs
2026-01-18 22:42:14,829 [INFO]   âœ“ å½’æ¡£è‡³: é‡åŒ–/MobileQuant_Mobile-friendly_Quantization_for_On-device_LLMs
2026-01-18 22:42:16,330 [INFO] ----------------------------------------
2026-01-18 22:42:16,330 [INFO] [14/28] å¤„ç†: Neuralink Fast on-Device LLM Inference with Neuron Co-Activation Linking
2026-01-18 22:42:16,331 [INFO]   æ ‡é¢˜: NEURALINK: Fast LLM Inference on Smartphones with Neuron Co-...
2026-01-18 22:42:49,762 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ¿€æ´» (ğŸ“ ç°æœ‰)
2026-01-18 22:42:49,762 [INFO]   â†’ æ ‡ç­¾: ['ç¥ç»å…ƒå…±æ¿€æ´»', 'é—ªå­˜I/Oä¼˜åŒ–', 'å­˜å‚¨å¸ƒå±€', 'ç¨€ç–æ¨ç†', 'ç§»åŠ¨ç«¯å¤§æ¨¡å‹']
2026-01-18 22:42:49,762 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:42:49,763 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒåˆ›æ–°æ˜¯åˆ©ç”¨å¤§æ¨¡å‹æ¨ç†æ—¶çš„ç¥ç»å…ƒå…±æ¿€æ´»ï¼ˆNeuron Co-Activationï¼‰è¿™ä¸€ç¨€ç–ç‰¹æ€§ï¼Œé€šè¿‡ä¼˜åŒ–é—ªå­˜ï¼ˆFlashï¼‰ä¸­çš„ç¥ç»å…ƒå­˜å‚¨å¸ƒå±€æ¥è§£å†³ç¨€ç–è®¿é—®å¯¼è‡´çš„I/Oç“¶é¢ˆï¼Œä»è€ŒåŠ é€Ÿç§»åŠ¨ç«¯æ¨ç†ã€‚
2026-01-18 22:42:49,764 [INFO] å½’æ¡£å®Œæˆ: Neuralink Fast on-Device LLM Inference with Neuron Co-Activation Linking -> ç¨€ç–æ¿€æ´»/Neuralink_Accelerating_LLM_Inference_on_Smartphones_by_Optimizing_Neuron_Placement_in_Flash_Memory
2026-01-18 22:42:49,764 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ¿€æ´»/Neuralink_Accelerating_LLM_Inference_on_Smartphones_by_Optimizing_Neuron_Placement_in_Flash_Memory
2026-01-18 22:42:51,265 [INFO] ----------------------------------------
2026-01-18 22:42:51,265 [INFO] [15/28] å¤„ç†: OD-MoE On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference
2026-01-18 22:42:51,266 [INFO]   æ ‡é¢˜: <span id="page-5-0"></span>3.2 Token and KV Cache Alignments...
2026-01-18 22:43:22,521 [INFO]   â†’ åˆ†ç±»: æ··åˆä¸“å®¶æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:43:22,521 [INFO]   â†’ æ ‡ç­¾: ['æ··åˆä¸“å®¶æ¨¡å‹', 'åˆ†å¸ƒå¼æ¨ç†', 'ä¸“å®¶å¸è½½', 'æ˜¾å­˜ä¼˜åŒ–', 'æ¿€æ´»é¢„æµ‹']
2026-01-18 22:43:22,521 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:43:22,521 [INFO]   â†’ ç†ç”±: è®ºæ–‡ä¸“é—¨é’ˆå¯¹æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šçš„æ˜¾å­˜å—é™é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ¿€æ´»é¢„æµ‹çš„æŒ‰éœ€ä¸“å®¶åŠ è½½å’Œåˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ï¼ˆOD-MoEï¼‰ï¼Œå±äºMoEæ¶æ„ç‰¹å®šçš„æ¨ç†ä¼˜åŒ–ç ”ç©¶ã€‚
2026-01-18 22:43:22,524 [INFO] å½’æ¡£å®Œæˆ: OD-MoE On-Demand Expert Loading for Cacheless Edge-Distributed MoE Inference -> æ··åˆä¸“å®¶æ¨¡å‹/OD-MoE
2026-01-18 22:43:22,524 [INFO]   âœ“ å½’æ¡£è‡³: æ··åˆä¸“å®¶æ¨¡å‹/OD-MoE
2026-01-18 22:43:24,024 [INFO] ----------------------------------------
2026-01-18 22:43:24,025 [INFO] [16/28] å¤„ç†: Ripple Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management
2026-01-18 22:43:24,025 [INFO]   æ ‡é¢˜: Ripple: Accelerating LLM Inference on Smartphones with Corre...
2026-01-18 22:44:13,402 [INFO]   â†’ åˆ†ç±»: å­˜å‚¨ä¸I/Oä¼˜åŒ– (ğŸ†• æ–°å»º)
2026-01-18 22:44:13,402 [INFO]   â†’ æ ‡ç­¾: ['ç¥ç»å…ƒå…±æ¿€æ´»', 'é—ªå­˜å¸ƒå±€ä¼˜åŒ–', 'I/Oå»¶è¿Ÿ', 'ç¨€ç–æ¨ç†', 'ç§»åŠ¨ç«¯æ¨ç†']
2026-01-18 22:44:13,402 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:44:13,403 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ ¸å¿ƒè§£å†³çš„æ˜¯ç§»åŠ¨è®¾å¤‡å†…å­˜å—é™æ—¶ï¼Œåˆ©ç”¨Flashå­˜å‚¨è¿è¡Œå¤§æ¨¡å‹ï¼ˆLLMï¼‰å¸¦æ¥çš„I/Oç“¶é¢ˆé—®é¢˜ã€‚é€šè¿‡'ç¥ç»å…ƒå…±æ¿€æ´»'ä¼˜åŒ–Flashä¸­çš„æ•°æ®å¸ƒå±€ï¼Œå±äºé’ˆå¯¹å­˜å‚¨ä»‹è´¨ç‰¹æ€§å’ŒI/Oæ•ˆç‡çš„ç³»ç»Ÿçº§ä¼˜åŒ–ï¼ŒåŒºåˆ«äºçº¯ç®—æ³•å±‚é¢çš„ç¨€ç–æ¿€æ´»æˆ–é€šç”¨çš„æ¨ç†å¼•æ“ä¼˜åŒ–ã€‚
2026-01-18 22:44:13,406 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: å­˜å‚¨ä¸I/Oä¼˜åŒ–
2026-01-18 22:44:13,407 [INFO] å½’æ¡£å®Œæˆ: Ripple Accelerating LLM Inference on Smartphones with Correlation-Aware Neuron Management -> å­˜å‚¨ä¸I/Oä¼˜åŒ–/Ripple_Accelerating_LLM_Inference_on_Smartphones_by_Optimizing_Neuron_Placement_in_Flash_Memory
2026-01-18 22:44:13,407 [INFO]   âœ“ å½’æ¡£è‡³: å­˜å‚¨ä¸I/Oä¼˜åŒ–/Ripple_Accelerating_LLM_Inference_on_Smartphones_by_Optimizing_Neuron_Placement_in_Flash_Memory
2026-01-18 22:44:14,908 [INFO] ----------------------------------------
2026-01-18 22:44:14,908 [INFO] [17/28] å¤„ç†: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones (2)
2026-01-18 22:44:14,918 [INFO]   æ ‡é¢˜: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones...
2026-01-18 22:44:39,256 [INFO]   â†’ åˆ†ç±»: æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾ (ğŸ“ ç°æœ‰)
2026-01-18 22:44:39,256 [INFO]   â†’ æ ‡ç­¾: ['æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'ç§»åŠ¨ç«¯NPU', 'ç¡¬ä»¶æ„ŸçŸ¥é‡åŒ–', 'ç®—å­ä¼˜åŒ–', 'é«˜é€šéªé¾™']
2026-01-18 22:44:39,256 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:44:39,257 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒç›®æ ‡æ˜¯åˆ©ç”¨ç§»åŠ¨ç«¯NPUçš„é—²ç½®ç®—åŠ›æ¥å®ç°å¹¶è¡Œæµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾ï¼ˆTest-time scalingï¼‰ï¼Œä»è€Œæå‡å°æ¨¡å‹çš„æ€§èƒ½ã€‚è™½ç„¶æ–‡ä¸­æå‡ºäº†ç¡¬ä»¶æ„ŸçŸ¥é‡åŒ–å’ŒLUTç®—å­æ›¿æ¢ç­‰NPUä¼˜åŒ–æŠ€æœ¯ï¼Œä½†è¿™äº›æ˜¯å®ç°æµ‹è¯•æ—¶ç¼©æ”¾çš„æ‰‹æ®µï¼Œè€Œéæœ€ç»ˆç›®çš„ã€‚
2026-01-18 22:44:39,267 [INFO] å½’æ¡£å®Œæˆ: Scaling LLM Test-Time Compute with Mobile NPU on Smartphones (2) -> æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾/Enabling_Parallel_Test-Time_Scaling_on_Mobile_NPUs_for_LLM_Inference
2026-01-18 22:44:39,267 [INFO]   âœ“ å½’æ¡£è‡³: æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾/Enabling_Parallel_Test-Time_Scaling_on_Mobile_NPUs_for_LLM_Inference
2026-01-18 22:44:40,768 [INFO] ----------------------------------------
2026-01-18 22:44:40,768 [INFO] [18/28] å¤„ç†: Scaling Up On-Device LLMs via Active-Weight Swapping Between DRAM and Flash
2026-01-18 22:44:40,768 [INFO]   æ ‡é¢˜: Scaling Up On-Device LLMs via Active-Weight Swapping Between...
2026-01-18 22:45:06,368 [INFO]   â†’ åˆ†ç±»: å­˜å‚¨ä¸I/Oä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:45:06,369 [INFO]   â†’ æ ‡ç­¾: ['DRAM-Flashäº¤æ¢', 'æ´»è·ƒæƒé‡é¢„æµ‹', 'ä¸Šä¸‹æ–‡ç¨€ç–æ€§', 'å†…å­˜ç®¡ç†', 'è‡ªè’¸é¦']
2026-01-18 22:45:06,369 [INFO]   â†’ ç½®ä¿¡åº¦: 98%
2026-01-18 22:45:06,369 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†ActiveFlowæ¡†æ¶ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯'æ´»è·ƒæƒé‡DRAM-Flashäº¤æ¢'ï¼ˆActive weight DRAM-flash swappingï¼‰ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä¸Šä¸‹æ–‡ç¨€ç–æ€§é¢„æµ‹æ´»è·ƒæƒé‡ï¼Œå¹¶ç®¡ç†DRAMä¸Flashå­˜å‚¨ä¹‹é—´çš„æ•°æ®ä¼ è¾“ï¼ˆI/Oï¼‰ï¼Œä»¥è§£å†³ç§»åŠ¨è®¾å¤‡DRAMå®¹é‡å—é™çš„é—®é¢˜ã€‚è¿™å®Œå…¨ç¬¦åˆå­˜å‚¨ä¸I/Oä¼˜åŒ–çš„å®šä¹‰ã€‚
2026-01-18 22:45:06,371 [INFO] å½’æ¡£å®Œæˆ: Scaling Up On-Device LLMs via Active-Weight Swapping Between DRAM and Flash -> å­˜å‚¨ä¸I/Oä¼˜åŒ–/ActiveFlow_LLM_inference_framework_for_adaptive_DRAM_usage
2026-01-18 22:45:06,371 [INFO]   âœ“ å½’æ¡£è‡³: å­˜å‚¨ä¸I/Oä¼˜åŒ–/ActiveFlow_LLM_inference_framework_for_adaptive_DRAM_usage
2026-01-18 22:45:07,872 [INFO] ----------------------------------------
2026-01-18 22:45:07,872 [INFO] [19/28] å¤„ç†: SecNPU Securing LLM Inference on NPU
2026-01-18 22:45:07,881 [INFO]   æ ‡é¢˜: SecNPU: Securing LLM Inference on NPU...
2026-01-18 22:46:21,967 [INFO]   â†’ åˆ†ç±»: NPUæ¶æ„ä¸ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:46:21,968 [INFO]   â†’ æ ‡ç­¾: ['å¯ä¿¡æ‰§è¡Œç¯å¢ƒ', 'NPUå®‰å…¨', 'éšç§ä¿æŠ¤', 'å®‰å…¨å¯åŠ¨', 'CPUè§£è€¦']
2026-01-18 22:46:21,968 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:46:21,968 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†ä¸€ç§åä¸ºSecNPUçš„NPUæ¶æ„è®¾è®¡ï¼Œé€šè¿‡é›†æˆTEEåŠŸèƒ½å¹¶é‡‡ç”¨CPUè§£è€¦æ¶æ„ï¼Œè§£å†³äº†NPUæ¨ç†ä¸­çš„å®‰å…¨ä¸é€šä¿¡å¼€é”€é—®é¢˜ï¼Œå±äºNPUç¡¬ä»¶æ¶æ„å±‚é¢çš„æ”¹è¿›ä¸ä¼˜åŒ–ã€‚
2026-01-18 22:46:21,972 [INFO] å½’æ¡£å®Œæˆ: SecNPU Securing LLM Inference on NPU -> NPUæ¶æ„ä¸ä¼˜åŒ–/SecNPU_A_CPU-decoupled_and_LLM-inference-optimized_NPU_TEE
2026-01-18 22:46:21,973 [INFO]   âœ“ å½’æ¡£è‡³: NPUæ¶æ„ä¸ä¼˜åŒ–/SecNPU_A_CPU-decoupled_and_LLM-inference-optimized_NPU_TEE
2026-01-18 22:46:23,473 [INFO] ----------------------------------------
2026-01-18 22:46:23,474 [INFO] [20/28] å¤„ç†: Small language models Survey, measurements, and insights
2026-01-18 22:46:23,475 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Small language models Survey, measurements, and insights.md
2026-01-18 22:46:23,475 [INFO]   æ ‡é¢˜: SMALL LANGUAGE MODELS: SURVEY, MEASUREMENTS, AND INSIGHTS...
2026-01-18 22:46:48,560 [INFO]   â†’ åˆ†ç±»: åŸºå‡†æµ‹è¯• (ğŸ“ ç°æœ‰)
2026-01-18 22:46:48,561 [INFO]   â†’ æ ‡ç­¾: ['å°è¯­è¨€æ¨¡å‹', 'ç«¯ä¾§æ¨ç†', 'æ€§èƒ½è¯„ä¼°', 'å†…å­˜å ç”¨', 'æ¨¡å‹æ¶æ„']
2026-01-18 22:46:48,561 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:46:48,561 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡ä¸»è¦å¯¹70ä¸ªå¼€æºå°è¯­è¨€æ¨¡å‹ï¼ˆSLMï¼‰è¿›è¡Œäº†ç»¼è¿°ï¼Œå¹¶é’ˆå¯¹å…¶åœ¨ç«¯ä¾§è®¾å¤‡çš„æ¨ç†å»¶è¿Ÿã€å†…å­˜å ç”¨ä»¥åŠå¤šé¢†åŸŸèƒ½åŠ›è¿›è¡Œäº†ç³»ç»Ÿçš„åŸºå‡†æµ‹è¯•å’Œè¯„ä¼°ï¼Œå±äºå…¸å‹çš„è¯„æµ‹ä¸åˆ†æç±»å·¥ä½œã€‚
2026-01-18 22:46:48,565 [INFO] å½’æ¡£å®Œæˆ: Small language models Survey, measurements, and insights -> åŸºå‡†æµ‹è¯•/A_Survey_on_Small_Language_Models
2026-01-18 22:46:48,565 [INFO]   âœ“ å½’æ¡£è‡³: åŸºå‡†æµ‹è¯•/A_Survey_on_Small_Language_Models
2026-01-18 22:46:50,066 [INFO] ----------------------------------------
2026-01-18 22:46:50,067 [INFO] [21/28] å¤„ç†: SPARSEINFER FRAMEWORK LEVERAGING SEMANTIC PATTERNS FOR ADAPTIVE SPARSE LLM INFERENCE
2026-01-18 22:46:50,068 [INFO]   æ ‡é¢˜: SPARSEINFER FRAMEWORK: LEVERAGING SEMANTIC PATTERNS FOR ADAP...
2026-01-18 22:47:09,327 [INFO]   â†’ åˆ†ç±»: ç¨€ç–æ¿€æ´» (ğŸ“ ç°æœ‰)
2026-01-18 22:47:09,328 [INFO]   â†’ æ ‡ç­¾: ['ç¨€ç–æ¿€æ´»', 'å¥å­çº§é¢„æµ‹', 'æ ¸å¿ƒç¥ç»å…ƒ', 'è‡ªé€‚åº”æ¨ç†', 'MLP-free']
2026-01-18 22:47:09,328 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:47:09,328 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†SparseInferæ–¹æ³•ï¼Œæ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡è¯†åˆ«'å¥å­çº§æ ¸å¿ƒç¥ç»å…ƒ'ï¼ˆsentence-wise core neuronsï¼‰æ¥å®ç°è‡ªé€‚åº”çš„ç¨€ç–æ¿€æ´»ï¼ˆAdaptive sparse activationï¼‰ï¼Œä»è€Œåœ¨ä¸æŸå¤±æ€§èƒ½çš„æƒ…å†µä¸‹å‡å°‘è®¡ç®—é‡ã€‚è¿™å®Œå…¨ç¬¦åˆç¨€ç–æ¿€æ´»çš„æŠ€æœ¯å®šä¹‰ã€‚
2026-01-18 22:47:09,332 [INFO] å½’æ¡£å®Œæˆ: SPARSEINFER FRAMEWORK LEVERAGING SEMANTIC PATTERNS FOR ADAPTIVE SPARSE LLM INFERENCE -> ç¨€ç–æ¿€æ´»/SparseInfer_MLP-free_Adaptive_Sparse_Inference_Method
2026-01-18 22:47:09,332 [INFO]   âœ“ å½’æ¡£è‡³: ç¨€ç–æ¿€æ´»/SparseInfer_MLP-free_Adaptive_Sparse_Inference_Method
2026-01-18 22:47:10,833 [INFO] ----------------------------------------
2026-01-18 22:47:10,833 [INFO] [22/28] å¤„ç†: SparseLoRA Accelerating LLM Fine-Tuning with Contextual Sparsity
2026-01-18 22:47:10,834 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: SparseLoRA Accelerating LLM Fine-Tuning with Contextual Sparsity.md
2026-01-18 22:47:10,834 [INFO]   æ ‡é¢˜: <span id="page-0-1"></span>SparseLoRA: Accelerating LLM Fine...
2026-01-18 22:47:47,459 [INFO] 
ç”¨æˆ·ä¸­æ–­
2026-01-18 22:47:50,647 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 20
2026-01-18 22:47:50,670 [INFO] ============================================================
2026-01-18 22:47:50,671 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 22:47:50,671 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 22:47:50,671 [INFO] ============================================================
2026-01-18 22:47:50,672 [INFO] å…±æ‰«æåˆ° 10 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:47:50,672 [INFO] å‘ç° 10 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:47:50,672 [INFO] ç°æœ‰ç±»åˆ« (20): ['KVç¼“å­˜ä¼˜åŒ–', 'NPUæ¶æ„ä¸ä¼˜åŒ–', 'åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'å­˜å‚¨ä¸I', 'å¼‚æ„è®¡ç®—è°ƒåº¦', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'æ··åˆä¸“å®¶æ¨¡å‹', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç¨€ç–æ¿€æ´»', 'ç«¯äº‘ååŒ', 'ç«¯ä¾§å‘é‡æ•°æ®åº“', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹', 'é‡åŒ–']
2026-01-18 22:47:50,673 [INFO] ----------------------------------------
2026-01-18 22:47:50,673 [INFO] [1/10] å¤„ç†: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching
2026-01-18 22:47:50,673 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching\\Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching.md'
2026-01-18 22:47:52,173 [INFO] ----------------------------------------
2026-01-18 22:47:52,174 [INFO] [2/10] å¤„ç†: Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach
2026-01-18 22:47:52,174 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach\\Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing_An_Active_Inference_Approach.md'
2026-01-18 22:47:53,675 [INFO] ----------------------------------------
2026-01-18 22:47:53,675 [INFO] [3/10] å¤„ç†: MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning
2026-01-18 22:47:53,675 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning\\MagicVL-2B Empowering Vision-Language Models on Mobile Devices with Lightweight Visual Encoders via Curriculum Learning.md'
2026-01-18 22:47:55,176 [INFO] ----------------------------------------
2026-01-18 22:47:55,176 [INFO] [4/10] å¤„ç†: SparseLoRA Accelerating LLM Fine-Tuning with Contextual Sparsity
2026-01-18 22:47:55,177 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: SparseLoRA Accelerating LLM Fine-Tuning with Contextual Sparsity.md
2026-01-18 22:47:55,177 [INFO]   æ ‡é¢˜: <span id="page-0-1"></span>SparseLoRA: Accelerating LLM Fine...
2026-01-18 22:47:57,449 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 22:48:30,918 [INFO]   â†’ åˆ†ç±»: é«˜æ•ˆå¾®è°ƒ (ğŸ†• æ–°å»º)
2026-01-18 22:48:30,918 [INFO]   â†’ æ ‡ç­¾: ['å‚æ•°é«˜æ•ˆå¾®è°ƒ', 'ä¸Šä¸‹æ–‡ç¨€ç–', 'SVDä¼°ç®—', 'è®­ç»ƒåŠ é€Ÿ', 'åŠ¨æ€æƒé‡é€‰æ‹©']
2026-01-18 22:48:30,918 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:48:30,918 [INFO]   â†’ ç†ç”±: è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®æ˜¯SparseLoRAï¼Œä¸€ç§é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰æ–¹æ³•ã€‚è™½ç„¶æ¶‰åŠç¨€ç–æ€§ï¼Œä½†å…¶åº”ç”¨åœºæ™¯æ˜¯è®­ç»ƒ/å¾®è°ƒé˜¶æ®µçš„è®¡ç®—åŠ é€Ÿï¼Œè€Œéæ¨ç†é˜¶æ®µã€‚ç°æœ‰åˆ†ç±»ä¸»è¦é›†ä¸­åœ¨æ¨ç†ä¼˜åŒ–ï¼ˆå¦‚KVç¼“å­˜ã€æŠ•æœºè§£ç ã€é‡åŒ–ï¼‰ï¼Œç¼ºä¹é’ˆå¯¹ç«¯ä¾§æˆ–é«˜æ•ˆå¾®è°ƒï¼ˆOn-device/Efficient Fine-tuningï¼‰çš„ä¸“é—¨åˆ†ç±»ã€‚
2026-01-18 22:48:30,921 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: é«˜æ•ˆå¾®è°ƒ
2026-01-18 22:48:30,922 [INFO] å½’æ¡£å®Œæˆ: SparseLoRA Accelerating LLM Fine-Tuning with Contextual Sparsity -> é«˜æ•ˆå¾®è°ƒ/SparseLoRA
2026-01-18 22:48:30,922 [INFO]   âœ“ å½’æ¡£è‡³: é«˜æ•ˆå¾®è°ƒ/SparseLoRA
2026-01-18 22:48:32,422 [INFO] ----------------------------------------
2026-01-18 22:48:32,422 [INFO] [5/10] å¤„ç†: Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_
2026-01-18 22:48:32,431 [INFO]   æ ‡é¢˜: SPOKEN STEREOSET: ON EVALUATING SOCIAL BIAS TOWARD SPEAKER I...
2026-01-18 22:49:11,781 [INFO]   â†’ åˆ†ç±»: è¯­éŸ³è¯­è¨€æ¨¡å‹ (ğŸ†• æ–°å»º)
2026-01-18 22:49:11,782 [INFO]   â†’ æ ‡ç­¾: ['è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹', 'ç¤¾ä¼šåè§è¯„ä¼°', 'æ•°æ®é›†æ„å»º', 'SLLM', 'å¤šæ¨¡æ€']
2026-01-18 22:49:11,782 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:49:11,782 [INFO]   â†’ ç†ç”±: è®ºæ–‡é’ˆå¯¹è¯­éŸ³å¤§è¯­è¨€æ¨¡å‹ï¼ˆSLLMsï¼‰æå‡ºäº†ä¸€ç§è¯„ä¼°ç¤¾ä¼šåè§çš„æ•°æ®é›†ã€‚é‰´äºç°æœ‰åˆ†ç±»ä¸­å·²æœ‰â€œè§†è§‰è¯­è¨€æ¨¡å‹â€ï¼Œæ–°å»ºâ€œè¯­éŸ³è¯­è¨€æ¨¡å‹â€èƒ½æ›´ç²¾å‡†åœ°è¦†ç›–ç§»åŠ¨ç«¯/è¾¹ç¼˜ä¾§é‡è¦çš„è¯­éŸ³äº¤äº’æ¨¡æ€æŠ€æœ¯ï¼ŒåŒºåˆ«äºé€šç”¨çš„æ€§èƒ½åŸºå‡†æµ‹è¯•ã€‚
2026-01-18 22:49:11,792 [INFO] åˆ›å»ºæ–°ç±»åˆ«ç›®å½•: è¯­éŸ³è¯­è¨€æ¨¡å‹
2026-01-18 22:49:11,793 [INFO] å½’æ¡£å®Œæˆ: Spoken_Stereoset_On_Evaluating_Social_Bias_Toward_ -> è¯­éŸ³è¯­è¨€æ¨¡å‹/Spoken_Stereoset_A_Dataset_for_Evaluating_Social_Biases_in_Speech_Large_Language_Models
2026-01-18 22:49:11,793 [INFO]   âœ“ å½’æ¡£è‡³: è¯­éŸ³è¯­è¨€æ¨¡å‹/Spoken_Stereoset_A_Dataset_for_Evaluating_Social_Biases_in_Speech_Large_Language_Models
2026-01-18 22:49:13,294 [INFO] ----------------------------------------
2026-01-18 22:49:13,294 [INFO] [6/10] å¤„ç†: Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices
2026-01-18 22:49:13,295 [ERROR] å¤„ç†å¤±è´¥: [Errno 2] No such file or directory: 'D:\\code\\ç»ˆç«¯æ¨ç†\\10_References\\Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices\\Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices.md'
2026-01-18 22:49:14,795 [INFO] ----------------------------------------
2026-01-18 22:49:14,795 [INFO] [7/10] å¤„ç†: Token Level Routing Inference System for Edge Devices
2026-01-18 22:49:14,796 [INFO]   æ ‡é¢˜: Token Level Routing Inference System for Edge Devices\...
2026-01-18 22:49:39,965 [INFO]   â†’ åˆ†ç±»: ç«¯äº‘ååŒ (ğŸ“ ç°æœ‰)
2026-01-18 22:49:39,965 [INFO]   â†’ æ ‡ç­¾: ['ç«¯äº‘ååŒ', 'ååŒè§£ç ', 'æ··åˆæ¨ç†', 'å…³é”®Tokenè¯†åˆ«', 'è®¡ç®—å¸è½½']
2026-01-18 22:49:39,965 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:49:39,965 [INFO]   â†’ ç†ç”±: è®ºæ–‡æ˜ç¡®æå‡ºäº†ä¸€ç§'ååŒè§£ç 'ï¼ˆcollaborative decodingï¼‰æ¨ç†ç³»ç»Ÿï¼Œè¯¥ç³»ç»Ÿè®©å°æ¨¡å‹åœ¨ç«¯ä¾§è¿è¡Œï¼ŒåŒæ—¶é€‰æ‹©æ€§åœ°å’¨è¯¢äº‘ç«¯çš„å¤§æ¨¡å‹æ¥ç”Ÿæˆå…³é”®Tokenã€‚è¿™ç§æ¶æ„é€šè¿‡è”åˆåˆ©ç”¨ç«¯ä¾§èµ„æºå’Œäº‘ç«¯ç®—åŠ›æ¥å¹³è¡¡æ¨ç†é€Ÿåº¦ä¸è´¨é‡ï¼Œå®Œå…¨ç¬¦åˆ'ç«¯äº‘ååŒ'çš„æŠ€æœ¯å®šä¹‰ã€‚
2026-01-18 22:49:39,967 [INFO] å½’æ¡£å®Œæˆ: Token Level Routing Inference System for Edge Devices -> ç«¯äº‘ååŒ/Collaborative_Decoding_Inference_System_for_Edge_Devices
2026-01-18 22:49:39,967 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯äº‘ååŒ/Collaborative_Decoding_Inference_System_for_Edge_Devices
2026-01-18 22:49:41,468 [INFO] ----------------------------------------
2026-01-18 22:49:41,468 [INFO] [8/10] å¤„ç†: Transformer-Lite High-efficiency Deployment of Large Language Models on Mobile Phone GP
2026-01-18 22:49:41,469 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Transformer-Lite High-efficiency Deployment of Large Language Models on Mobile Phone GP.md
2026-01-18 22:49:41,469 [INFO]   æ ‡é¢˜: Abstract...
2026-01-18 22:50:05,593 [INFO]   â†’ åˆ†ç±»: æ¨ç†å¼•æ“ä¼˜åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:50:05,594 [INFO]   â†’ æ ‡ç­¾: ['ç§»åŠ¨ç«¯æ¨ç†å¼•æ“', 'FP4é‡åŒ–', 'KVç¼“å­˜ä¼˜åŒ–', 'ç®—å­ä¼˜åŒ–', 'ç§»åŠ¨ç«¯GPU']
2026-01-18 22:50:05,594 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:50:05,594 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡æå‡ºäº†ä¸€ä¸ªåä¸ºTransformer-Liteçš„ç§»åŠ¨ç«¯æ¨ç†å¼•æ“ï¼Œé›†æˆäº†åŠ¨æ€å½¢çŠ¶æ¨ç†ã€ç®—å­ä¼˜åŒ–ã€FP4é‡åŒ–ï¼ˆE0M4ï¼‰å’ŒKVç¼“å­˜ä¼˜åŒ–ï¼ˆå­å¼ é‡æŠ€æœ¯ï¼‰ç­‰å¤šç§æŠ€æœ¯ï¼Œæ—¨åœ¨æå‡ç§»åŠ¨GPUä¸Šçš„LLMéƒ¨ç½²æ•ˆç‡ï¼Œå±äºå…¸å‹çš„æ¨ç†å¼•æ“ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚
2026-01-18 22:50:05,596 [INFO] å½’æ¡£å®Œæˆ: Transformer-Lite High-efficiency Deployment of Large Language Models on Mobile Phone GP -> æ¨ç†å¼•æ“ä¼˜åŒ–/Transformer-Lite_High-efficiency_LLM_Deployment_on_Mobile_Phone_GPUs
2026-01-18 22:50:05,596 [INFO]   âœ“ å½’æ¡£è‡³: æ¨ç†å¼•æ“ä¼˜åŒ–/Transformer-Lite_High-efficiency_LLM_Deployment_on_Mobile_Phone_GPUs
2026-01-18 22:50:07,096 [INFO] ----------------------------------------
2026-01-18 22:50:07,097 [INFO] [9/10] å¤„ç†: Trol Traversal of layers for large language and vision models
2026-01-18 22:50:07,106 [INFO]   æ ‡é¢˜: 3 TroL: Traversal of Layers...
2026-01-18 22:50:48,421 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:50:48,421 [INFO]   â†’ æ ‡ç­¾: ['è§†è§‰è¯­è¨€æ¨¡å‹', 'å±‚éå†', 'å±‚é‡ç”¨', 'å‚æ•°æ•ˆç‡', 'å¤šæ¨¡æ€']
2026-01-18 22:50:48,421 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:50:48,421 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†TroLï¼ˆTraversal of Layersï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°çš„é«˜æ•ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLLVMï¼‰å®¶æ—ã€‚è™½ç„¶å…¶æ ¸å¿ƒæŠ€æœ¯æ¶‰åŠå±‚é‡ç”¨ä»¥æé«˜æ•ˆç‡ï¼Œä½†å…¶ä¸»è¦è´¡çŒ®å’Œåº”ç”¨é¢†åŸŸæ˜ç¡®å±äºè§†è§‰è¯­è¨€æ¨¡å‹ã€‚
2026-01-18 22:50:48,423 [INFO] å½’æ¡£å®Œæˆ: Trol Traversal of layers for large language and vision models -> è§†è§‰è¯­è¨€æ¨¡å‹/TroL_Traversal_of_Layers_for_Efficient_Large_Language_and_Vision_Models
2026-01-18 22:50:48,423 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/TroL_Traversal_of_Layers_for_Efficient_Large_Language_and_Vision_Models
2026-01-18 22:50:49,924 [INFO] ----------------------------------------
2026-01-18 22:50:49,924 [INFO] [10/10] å¤„ç†: Understanding Large Language Models in Your Pockets Performance Study on COTS Mobile Devices
2026-01-18 22:50:49,925 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Understanding Large Language Models in Your Pockets Performance Study on COTS Mobile Devices.md
2026-01-18 22:50:49,925 [INFO]   æ ‡é¢˜: Understanding Large Language Models in Your Pockets: Perform...
2026-01-18 22:51:16,257 [INFO]   â†’ åˆ†ç±»: åŸºå‡†æµ‹è¯• (ğŸ“ ç°æœ‰)
2026-01-18 22:51:16,257 [INFO]   â†’ æ ‡ç­¾: ['æ€§èƒ½è¯„æµ‹', 'èƒ½è€—åˆ†æ', 'ç§»åŠ¨ç«¯æ¨ç†', 'SoCå¯¹æ¯”', 'æ¨ç†å¼•æ“']
2026-01-18 22:51:16,258 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:51:16,258 [INFO]   â†’ ç†ç”±: è¯¥è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹æ˜¯å¯¹ç§»åŠ¨ç«¯å¤§æ¨¡å‹ï¼ˆå¦‚Gemini Nano, Llama2 7Bï¼‰åœ¨å•†ç”¨æ™ºèƒ½æ‰‹æœºä¸Šçš„æ€§èƒ½è¿›è¡Œå…¨é¢çš„æµ‹é‡ç ”ç©¶ï¼ˆMeasurement Studyï¼‰ã€‚å®ƒè¯„ä¼°äº†ååé‡ã€å»¶è¿Ÿã€ç”µæ± æ¶ˆè€—ç­‰æŒ‡æ ‡ï¼Œå¹¶å¯¹æ¯”äº†ä¸åŒSoCå’Œæ¨ç†å¼•æ“çš„è¡¨ç°ï¼Œæ—¨åœ¨æ­ç¤ºå½“å‰ç§»åŠ¨ç«¯LLMéƒ¨ç½²çš„ç°çŠ¶å’Œç“¶é¢ˆï¼Œå®Œå…¨ç¬¦åˆåŸºå‡†æµ‹è¯•ä¸å®è¯ç ”ç©¶çš„å®šä¹‰ã€‚
2026-01-18 22:51:16,259 [INFO] å½’æ¡£å®Œæˆ: Understanding Large Language Models in Your Pockets Performance Study on COTS Mobile Devices -> åŸºå‡†æµ‹è¯•/A_Comprehensive_Measurement_Study_of_Large_Language_Models_on_Mobile_Devices
2026-01-18 22:51:16,259 [INFO]   âœ“ å½’æ¡£è‡³: åŸºå‡†æµ‹è¯•/A_Comprehensive_Measurement_Study_of_Large_Language_Models_on_Mobile_Devices
2026-01-18 22:51:16,260 [INFO] ============================================================
2026-01-18 22:51:16,260 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 22:51:16,260 [INFO]   æˆåŠŸ: 6
2026-01-18 22:51:16,260 [INFO]   å¤±è´¥: 4
2026-01-18 22:51:16,260 [INFO]   è·³è¿‡: 0
2026-01-18 22:51:16,260 [INFO] ============================================================
2026-01-18 22:52:14,007 [INFO] å½“å‰ç±»åˆ«æ•°é‡: 22
2026-01-18 22:52:14,031 [INFO] ============================================================
2026-01-18 22:52:14,032 [INFO] Librarian Agent å¯åŠ¨
2026-01-18 22:52:14,032 [INFO] æ¨¡å¼: æ­£å¸¸æ¨¡å¼
2026-01-18 22:52:14,032 [INFO] ============================================================
2026-01-18 22:52:14,033 [INFO] å…±æ‰«æåˆ° 4 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:52:14,033 [INFO] å‘ç° 4 ç¯‡å¾…å¤„ç†è®ºæ–‡
2026-01-18 22:52:14,033 [INFO] ç°æœ‰ç±»åˆ« (22): ['KVç¼“å­˜ä¼˜åŒ–', 'NPUæ¶æ„ä¸ä¼˜åŒ–', 'åŠ¨æ€æ¨ç†', 'åŸºå‡†æµ‹è¯•', 'å­˜å‚¨ä¸I', 'å¼‚æ„è®¡ç®—è°ƒåº¦', 'æŠ•æœºè§£ç ', 'æ¨ç†å¼•æ“ä¼˜åŒ–', 'æ¨¡å‹å‹ç¼©', 'æµ‹è¯•æ—¶è®¡ç®—ç¼©æ”¾', 'æ··åˆä¸“å®¶æ¨¡å‹', 'ç§»åŠ¨æ™ºèƒ½ä½“', 'ç¨€ç–æ³¨æ„åŠ›', 'ç¨€ç–æ¿€æ´»', 'ç«¯äº‘ååŒ', 'ç«¯ä¾§å‘é‡æ•°æ®åº“', 'ç«¯ä¾§çŸ¥è¯†ç¼–è¾‘', 'èƒ½æ•ˆä¼˜åŒ–', 'è§†è§‰è¯­è¨€æ¨¡å‹', 'è¯­éŸ³è¯­è¨€æ¨¡å‹', 'é‡åŒ–', 'é«˜æ•ˆå¾®è°ƒ']
2026-01-18 22:52:14,033 [INFO] ----------------------------------------
2026-01-18 22:52:14,034 [INFO] [1/4] å¤„ç†: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference
2026-01-18 22:52:14,036 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference with Mixed-Precision and Multi-level Caching.md
2026-01-18 22:52:14,036 [INFO]   æ ‡é¢˜: Harnessing Your DRAM and SSD for Sustainable and Accessible ...
2026-01-18 22:52:16,264 [INFO] Gemini åˆ†ç±»å™¨åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: gemini-3-pro-preview
2026-01-18 22:53:11,120 [INFO]   â†’ åˆ†ç±»: é‡åŒ– (ğŸ“ ç°æœ‰)
2026-01-18 22:53:11,121 [INFO]   â†’ æ ‡ç­¾: ['æ··åˆç²¾åº¦é‡åŒ–', 'å¤šçº§ç¼“å­˜', 'åŠ¨æ€ç¨€ç–', 'ç»¿è‰²AI', 'ç¥ç»å…ƒæ¨¡å—åŒ–']
2026-01-18 22:53:11,121 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:53:11,121 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºçš„æ ¸å¿ƒæŠ€æœ¯M2Cacheé‡‡ç”¨'åŠ¨æ€ç¨€ç–æ··åˆç²¾åº¦é‡åŒ–æœºåˆ¶'ï¼ˆdynamic sparse mixed-precision quantizationï¼‰æ¥é™ä½è®¡ç®—éœ€æ±‚å’Œæ˜¾å­˜å ç”¨ï¼Œè™½ç„¶æ¶‰åŠå¤šçº§ç¼“å­˜ï¼Œä½†å…¶å®ç°æ¨¡å‹åœ¨å—é™ç¡¬ä»¶ä¸Šè¿è¡Œçš„å…³é”®æ‰‹æ®µæ˜¯é‡åŒ–ä¸ç¨€ç–åŒ–ç­–ç•¥ã€‚
2026-01-18 22:53:11,125 [INFO] å½’æ¡£å®Œæˆ: Harnessing Your DRAM and SSD for Sustainable and Accessible LLM Inference -> é‡åŒ–/M2Cache_Mixed-Precision_and_Multi-Level_Caching_for_Carbon-Sustainable_LLM_Serving
2026-01-18 22:53:11,125 [INFO]   âœ“ å½’æ¡£è‡³: é‡åŒ–/M2Cache_Mixed-Precision_and_Multi-Level_Caching_for_Carbon-Sustainable_LLM_Serving
2026-01-18 22:53:12,626 [INFO] ----------------------------------------
2026-01-18 22:53:12,626 [INFO] [2/4] å¤„ç†: Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing
2026-01-18 22:53:12,627 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing.md
2026-01-18 22:53:12,627 [INFO]   æ ‡é¢˜: Large Language Models (LLMs) Inference Offloading and Resour...
2026-01-18 22:53:34,501 [INFO]   â†’ åˆ†ç±»: ç«¯äº‘ååŒ (ğŸ“ ç°æœ‰)
2026-01-18 22:53:34,501 [INFO]   â†’ æ ‡ç­¾: ['ä»»åŠ¡å¸è½½', 'ä¸»åŠ¨æ¨ç†', 'èµ„æºåˆ†é…', 'äº‘è¾¹è®¡ç®—', 'æ·±åº¦å¼ºåŒ–å­¦ä¹ ']
2026-01-18 22:53:34,502 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:53:34,502 [INFO]   â†’ ç†ç”±: è®ºæ–‡ä¸»è¦ç ”ç©¶åœ¨äº‘è¾¹è®¡ç®—ï¼ˆCloud-Edge Computingï¼‰ç¯å¢ƒä¸‹ï¼Œåˆ©ç”¨ä¸»åŠ¨æ¨ç†ï¼ˆActive Inferenceï¼‰ç®—æ³•è§£å†³å¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„ä»»åŠ¡å¸è½½ï¼ˆTask Offloadingï¼‰å’Œèµ„æºåˆ†é…é—®é¢˜ï¼Œæ—¨åœ¨è§£å†³ç§»åŠ¨ç«¯èµ„æºå—é™æ— æ³•é«˜æ•ˆè¿è¡Œå¤§æ¨¡å‹çš„é—®é¢˜ï¼Œå±äºå…¸å‹çš„ç«¯äº‘ååŒæŠ€æœ¯èŒƒç•´ã€‚
2026-01-18 22:53:34,504 [INFO] å½’æ¡£å®Œæˆ: Large_Language_Models_LLMs_Inference_Offloading_and_Resource_Allocation_in_Cloud-Edge_Computing -> ç«¯äº‘ååŒ/Active_Inference-Based_Task_Offloading_and_Resource_Allocation_for_Large_Language_Models_in_Cloud-Ed
2026-01-18 22:53:34,504 [INFO]   âœ“ å½’æ¡£è‡³: ç«¯äº‘ååŒ/Active_Inference-Based_Task_Offloading_and_Resource_Allocation_for_Large_Language_Models_in_Cloud-Ed
2026-01-18 22:53:36,005 [INFO] ----------------------------------------
2026-01-18 22:53:36,005 [INFO] [3/4] å¤„ç†: MagicVL-2B Empowering Vision-Language Models on Mobile Devices
2026-01-18 22:53:36,006 [INFO]   æ ‡é¢˜: MagicVL-2B: Empowering Vision-Language Models on Mobile Devi...
2026-01-18 22:53:58,491 [INFO]   â†’ åˆ†ç±»: è§†è§‰è¯­è¨€æ¨¡å‹ (ğŸ“ ç°æœ‰)
2026-01-18 22:53:58,491 [INFO]   â†’ æ ‡ç­¾: ['è§†è§‰è¯­è¨€æ¨¡å‹', 'åŠ¨æ€åˆ†è¾¨ç‡', 'å¤šæ¨¡æ€è¯¾ç¨‹å­¦ä¹ ', 'è½»é‡çº§è§†è§‰ç¼–ç å™¨', 'ç«¯ä¾§æ¨ç†']
2026-01-18 22:53:58,492 [INFO]   â†’ ç½®ä¿¡åº¦: 100%
2026-01-18 22:53:58,492 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†MagicVL-2Bï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹ç§»åŠ¨è®¾å¤‡ä¼˜åŒ–çš„è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVLMï¼‰ã€‚å…¶æ ¸å¿ƒè´¡çŒ®åœ¨äºæ¨¡å‹æ¶æ„çš„è®¾è®¡ï¼ˆè½»é‡çº§è§†è§‰ç¼–ç å™¨ã€åŠ¨æ€åˆ†è¾¨ç‡æœºåˆ¶ï¼‰ä»¥åŠè®­ç»ƒç­–ç•¥ï¼ˆå¤šæ¨¡æ€è¯¾ç¨‹å­¦ä¹ ï¼‰ï¼Œå®Œå…¨ç¬¦åˆâ€œè§†è§‰è¯­è¨€æ¨¡å‹â€è¿™ä¸€åˆ†ç±»çš„å®šä¹‰ã€‚
2026-01-18 22:53:58,494 [INFO] å½’æ¡£å®Œæˆ: MagicVL-2B Empowering Vision-Language Models on Mobile Devices -> è§†è§‰è¯­è¨€æ¨¡å‹/MagicVL-2B_A_Novel_VLM_Optimized_for_Flagship_Smartphones
2026-01-18 22:53:58,495 [INFO]   âœ“ å½’æ¡£è‡³: è§†è§‰è¯­è¨€æ¨¡å‹/MagicVL-2B_A_Novel_VLM_Optimized_for_Flagship_Smartphones
2026-01-18 22:53:59,995 [INFO] ----------------------------------------
2026-01-18 22:53:59,995 [INFO] [4/4] å¤„ç†: Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference
2026-01-18 22:53:59,996 [WARNING] æœªæ‰¾åˆ°æ˜ç¡®æ‘˜è¦ï¼Œä½¿ç”¨å‰æ–‡æ›¿ä»£: Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference.md
2026-01-18 22:53:59,996 [INFO]   æ ‡é¢˜: TINY BUT MIGHTY: A SOFTWARE-HARDWARE CO-DESIGN APPROACH FOR ...
2026-01-18 22:54:21,546 [INFO]   â†’ åˆ†ç±»: å¼‚æ„è®¡ç®—è°ƒåº¦ (ğŸ“ ç°æœ‰)
2026-01-18 22:54:21,547 [INFO]   â†’ æ ‡ç­¾: ['å¼‚æ„è®¡ç®—', 'è½¯ç¡¬ä»¶ååŒè®¾è®¡', 'å¤šæ¨¡æ€å¤§æ¨¡å‹', 'ç«¯ä¾§æ¨ç†', 'èƒ½æ•ˆä¼˜åŒ–']
2026-01-18 22:54:21,547 [INFO]   â†’ ç½®ä¿¡åº¦: 95%
2026-01-18 22:54:21,547 [INFO]   â†’ ç†ç”±: è®ºæ–‡æå‡ºäº†NANOMINDæ¡†æ¶ï¼Œæ ¸å¿ƒæŠ€æœ¯æ˜¯å°†å¤§å‹å¤šæ¨¡æ€æ¨¡å‹ï¼ˆLMMsï¼‰åˆ†è§£ä¸ºæ¨¡å—ï¼ˆè§†è§‰ã€è¯­è¨€ã€éŸ³é¢‘ç­‰ï¼‰ï¼Œå¹¶æ ¹æ®SoCä¸­ä¸åŒç¡¬ä»¶åŠ é€Ÿå™¨ï¼ˆNPUã€GPUã€DSPï¼‰çš„ç‰¹æ€§è¿›è¡ŒåŠ¨æ€è°ƒåº¦å’Œæ˜ å°„ï¼Œä»¥ä¼˜åŒ–ç«¯ä¾§æ¨ç†çš„å»¶è¿Ÿå’Œèƒ½æ•ˆã€‚è¿™å®Œå…¨ç¬¦åˆå¼‚æ„è®¡ç®—è°ƒåº¦çš„å®šä¹‰ã€‚
2026-01-18 22:54:21,549 [INFO] å½’æ¡£å®Œæˆ: Tiny but Mighty A Software-Hardware Co-Design Approach for Efficient Multimodal Inference -> å¼‚æ„è®¡ç®—è°ƒåº¦/NANOMIND_A_Hardwareâ€“Software_Co-design_Inference_Framework_for_Large_Multimodal_Models
2026-01-18 22:54:21,549 [INFO]   âœ“ å½’æ¡£è‡³: å¼‚æ„è®¡ç®—è°ƒåº¦/NANOMIND_A_Hardwareâ€“Software_Co-design_Inference_Framework_for_Large_Multimodal_Models
2026-01-18 22:54:21,549 [INFO] ============================================================
2026-01-18 22:54:21,549 [INFO] å¤„ç†å®Œæˆ!
2026-01-18 22:54:21,549 [INFO]   æˆåŠŸ: 4
2026-01-18 22:54:21,550 [INFO]   å¤±è´¥: 0
2026-01-18 22:54:21,550 [INFO]   è·³è¿‡: 0
2026-01-18 22:54:21,550 [INFO] ============================================================
