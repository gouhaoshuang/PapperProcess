#!/usr/bin/env python3
"""
Librarian Agent - æ™ºèƒ½è®ºæ–‡åˆ†ç±»ä¸å…ƒæ•°æ®ç®¡ç†
============================================================================

ç”¨æ³•:
    python librarian.py              # å¤„ç†æ‰€æœ‰å¾…åˆ†ç±»è®ºæ–‡
    python librarian.py --dry-run    # ä»…é¢„è§ˆï¼Œä¸æ‰§è¡Œå®é™…æ“ä½œ
    python librarian.py --limit 3    # ä»…å¤„ç†å‰ 3 ç¯‡

åŠŸèƒ½:
    1. æ‰«æ 10_References ç›®å½•ä¸­çš„ Markdown è®ºæ–‡
    2. ä½¿ç”¨ Gemini API åˆ†ææ‘˜è¦å¹¶åˆ†ç±»
    3. æ³¨å…¥ YAML Frontmatter å…ƒæ•°æ®
    4. å°†è®ºæ–‡ç§»åŠ¨åˆ° 20_Classification å¯¹åº”åˆ†ç±»ç›®å½•
"""

# åœ¨ä»»ä½•å…¶ä»–å¯¼å…¥ä¹‹å‰è®¾ç½®è­¦å‘Šè¿‡æ»¤ï¼ŒæŠ‘åˆ¶ google.generativeai çš„ FutureWarning
import warnings

warnings.filterwarnings("ignore", category=FutureWarning)

import os
import sys
import time
import logging
from pathlib import Path
from argparse import ArgumentParser
from typing import Optional

# æ·»åŠ æ¨¡å—è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
sys.path.insert(0, str(SCRIPT_DIR))

from config import CONFIG
from librarian.scanner import Scanner
from librarian.category_manager import CategoryManager
from librarian.content_extractor import ContentExtractor
from librarian.gemini_classifier import GeminiClassifier, ClassificationResult
from librarian.metadata_injector import MetadataInjector
from librarian.archivist import Archivist

# æ—¥å¿—é…ç½®
LOG_DIR = SCRIPT_DIR.parent / "logs"
LOG_DIR.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(LOG_DIR / "librarian.log", encoding="utf-8"),
        logging.StreamHandler(),
    ],
)
logger = logging.getLogger(__name__)


class LibrarianAgent:
    """å›¾ä¹¦ç®¡ç†å‘˜æ™ºèƒ½ä½“ - è®ºæ–‡åˆ†ç±»ä¸ç®¡ç†"""

    def __init__(self, dry_run: bool = False):
        """
        åˆå§‹åŒ– Librarian Agent

        Args:
            dry_run: æ˜¯å¦ä¸ºé¢„è§ˆæ¨¡å¼ (ä¸æ‰§è¡Œå®é™…æ“ä½œ)
        """
        self.dry_run = dry_run
        self.cfg = CONFIG["librarian"]
        self.gemini_cfg = CONFIG["gemini"]

        # åˆå§‹åŒ–ç»„ä»¶
        self.scanner = Scanner(
            Path(self.cfg["staging_dir"]), self.cfg["min_filename_length"]
        )
        self.category_mgr = CategoryManager(Path(self.cfg["target_dir"]))
        self.extractor = ContentExtractor(self.cfg["abstract_max_chars"])
        self.injector = MetadataInjector()
        self.archivist = Archivist(Path(self.cfg["target_dir"]))

        # Gemini åˆ†ç±»å™¨ (å»¶è¿Ÿåˆå§‹åŒ–)
        self._classifier: Optional[GeminiClassifier] = None

    @property
    def classifier(self) -> GeminiClassifier:
        """å»¶è¿Ÿåˆå§‹åŒ– Gemini åˆ†ç±»å™¨"""
        if self._classifier is None:
            api_key = os.environ.get(self.gemini_cfg["api_key_env"])
            if not api_key:
                raise RuntimeError(
                    f"æœªè®¾ç½®ç¯å¢ƒå˜é‡: {self.gemini_cfg['api_key_env']}\n"
                    f"è¯·è®¾ç½®: set {self.gemini_cfg['api_key_env']}=your_api_key"
                )
            self._classifier = GeminiClassifier(
                api_key=api_key,
                model=self.gemini_cfg["model"],
                temperature=self.gemini_cfg["temperature"],
                max_retries=self.gemini_cfg["max_retries"],
            )
        return self._classifier

    def run(self, limit: Optional[int] = None) -> dict:
        """
        æ‰§è¡Œåˆ†ç±»å¤„ç†

        Args:
            limit: å¤„ç†æ•°é‡é™åˆ¶ (None è¡¨ç¤ºå…¨éƒ¨å¤„ç†)

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        logger.info("=" * 60)
        logger.info("Librarian Agent å¯åŠ¨")
        logger.info(f"æ¨¡å¼: {'é¢„è§ˆæ¨¡å¼ (Dry Run)' if self.dry_run else 'æ­£å¸¸æ¨¡å¼'}")
        logger.info("=" * 60)

        # æ‰«æå¾…å¤„ç†æ–‡ä»¶
        papers = self.scanner.scan()
        if limit:
            papers = papers[:limit]

        if not papers:
            logger.info("æ²¡æœ‰å‘ç°å¾…å¤„ç†çš„è®ºæ–‡")
            return {"total": 0, "success": 0, "failed": 0, "skipped": 0}

        logger.info(f"å‘ç° {len(papers)} ç¯‡å¾…å¤„ç†è®ºæ–‡")

        # æ˜¾ç¤ºå½“å‰ç±»åˆ«
        categories = self.category_mgr.get_categories()
        logger.info(f"ç°æœ‰ç±»åˆ« ({len(categories)}): {categories}")

        # å¤„ç†æ¯ç¯‡è®ºæ–‡
        stats = {"total": len(papers), "success": 0, "failed": 0, "skipped": 0}

        for i, paper_path in enumerate(papers, 1):
            paper_dir = paper_path.parent
            logger.info("-" * 40)
            logger.info(f"[{i}/{len(papers)}] å¤„ç†: {paper_dir.name}")

            try:
                result = self._process_paper(paper_path)
                if result:
                    stats["success"] += 1
                else:
                    stats["skipped"] += 1
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {e}")
                stats["failed"] += 1

            # API è°ƒç”¨é—´éš”
            if i < len(papers) and not self.dry_run:
                time.sleep(self.cfg["api_delay_seconds"])

        # è¾“å‡ºç»Ÿè®¡
        logger.info("=" * 60)
        logger.info("å¤„ç†å®Œæˆ!")
        logger.info(f"  æˆåŠŸ: {stats['success']}")
        logger.info(f"  å¤±è´¥: {stats['failed']}")
        logger.info(f"  è·³è¿‡: {stats['skipped']}")
        logger.info("=" * 60)

        return stats

    def _process_paper(self, paper_path: Path) -> bool:
        """
        å¤„ç†å•ç¯‡è®ºæ–‡

        Args:
            paper_path: è®ºæ–‡ MD æ–‡ä»¶è·¯å¾„

        Returns:
            æ˜¯å¦æˆåŠŸå¤„ç†
        """
        paper_dir = paper_path.parent

        # Step 1: æå–å†…å®¹
        content = self.extractor.extract(paper_path)
        logger.info(f"  æ ‡é¢˜: {content.title[:60]}...")
        logger.debug(f"  æ‘˜è¦é•¿åº¦: {len(content.abstract)} å­—ç¬¦")

        # Step 2: è·å–å½“å‰ç±»åˆ«å¹¶åˆ†ç±»
        categories = self.category_mgr.get_categories()
        result = self.classifier.classify(content.abstract, categories)

        self._log_classification_result(result)

        if self.dry_run:
            logger.info("  [DRY RUN] è·³è¿‡å®é™…æ“ä½œ")
            return True

        # Step 3: æ³¨å…¥å…ƒæ•°æ®
        self.injector.inject(
            file_path=paper_path,
            title=result.clean_title or content.title,
            category=result.category,
            tags=result.tags,
            year=result.publication_year,
            reason=result.reason,
        )

        # Step 4: ç¡®ä¿ç±»åˆ«ç›®å½•å­˜åœ¨
        if result.is_new:
            self.category_mgr.ensure_category(result.category)

        # Step 5: ç§»åŠ¨åˆ°åˆ†ç±»ç›®å½•
        archived_path = self.archivist.archive(
            source_dir=paper_dir,
            category=result.category,
            clean_title=result.clean_title,
        )

        logger.info(f"  âœ“ å½’æ¡£è‡³: {result.category}/{archived_path.name}")
        return True

    def _log_classification_result(self, result: ClassificationResult) -> None:
        """è®°å½•åˆ†ç±»ç»“æœ"""
        status = "ğŸ†• æ–°å»º" if result.is_new else "ğŸ“ ç°æœ‰"
        logger.info(f"  â†’ åˆ†ç±»: {result.category} ({status})")
        logger.info(f"  â†’ æ ‡ç­¾: {result.tags}")
        logger.info(f"  â†’ ç½®ä¿¡åº¦: {result.confidence:.0%}")
        logger.info(f"  â†’ ç†ç”±: {result.reason}")


def main():
    """ä¸»å…¥å£"""
    parser = ArgumentParser(description="Librarian Agent - æ™ºèƒ½è®ºæ–‡åˆ†ç±»ä¸å…ƒæ•°æ®ç®¡ç†")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="é¢„è§ˆæ¨¡å¼ï¼Œä¸æ‰§è¡Œå®é™…æ“ä½œ",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶å¤„ç†çš„è®ºæ–‡æ•°é‡",
    )
    parser.add_argument(
        "--debug",
        action="store_true",
        help="å¯ç”¨è°ƒè¯•æ—¥å¿—",
    )

    args = parser.parse_args()

    if args.debug:
        logging.getLogger().setLevel(logging.DEBUG)

    try:
        agent = LibrarianAgent(dry_run=args.dry_run)
        agent.run(limit=args.limit)
    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ·ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        logger.error(f"è¿è¡Œå¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
